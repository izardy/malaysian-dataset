{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBP PDF Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the downloadable links\n",
    "# pip install duckduckgo-search\n",
    "# pip install google-api-python-client\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data=[]\n",
    "\n",
    "# Search query\n",
    "#query = \"pemacudbp.dbp.gov.my/fm/\"\n",
    "query= \"site:news.google.com russia df=d\"\n",
    "\n",
    "# Search results\n",
    "results = DDGS().text(query, max_results=10)\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "'''\n",
    "    data.append(result['href'])\n",
    "    \n",
    "# Drop duplicates in data list\n",
    "data = list(dict.fromkeys(data))\n",
    "\n",
    "pd.DataFrame(data,columns=['href']).to_csv('duckduckgo_results.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pemacudbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "try:\n",
    "    from googlesearch import search\n",
    "except ImportError: \n",
    "    print(\"No module named 'google' found\")\n",
    "\n",
    "data=[]\n",
    "\n",
    "# to search\n",
    "\n",
    "#query = \"site:pemacudbp.dbp.gov.my/fm/ filetype:pdf\"\n",
    "query = \"site:bnm.gov.my notice source=lnt tbs=qdr:h\"\n",
    "\n",
    "links=search(query, num=25, stop=300, pause=randint(10,20))\n",
    "\n",
    "for link in links:\n",
    "    print(link)\n",
    "    #pd.DataFrame(data,columns=['url']).to_csv('google_results_pemacudbp.csv', index=False)\n",
    "    #data.append(link)\n",
    "    \n",
    "\n",
    "# Drop duplicates in data list\n",
    "# data = list(dict.fromkeys(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eseminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "try:\n",
    "    from googlesearch import search\n",
    "except ImportError: \n",
    "    print(\"No module named 'google' found\")\n",
    "\n",
    "data=[]\n",
    "\n",
    "# to search\n",
    "query = \"site:eseminar.dbp.gov.my filetype:pdf\"\n",
    "\n",
    "links=search(query, num=25, stop=300, pause=randint(10,20))\n",
    "\n",
    "for link in links:\n",
    "    pd.DataFrame(data,columns=['url']).to_csv('google_results_eseminar.csv', index=False)\n",
    "    data.append(link)\n",
    "    \n",
    "\n",
    "# Drop duplicates in data list\n",
    "# data = list(dict.fromkeys(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bukuteks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "try:\n",
    "    from googlesearch import search\n",
    "except ImportError: \n",
    "    print(\"No module named 'google' found\")\n",
    "\n",
    "data=[]\n",
    "\n",
    "# to search\n",
    "query = \"site:bukuteks.dbp.gov.my filetype:pdf\"\n",
    "\n",
    "links=search(query, num=25, stop=300, pause=randint(10,20))\n",
    "\n",
    "for link in links:\n",
    "    pd.DataFrame(data,columns=['url']).to_csv('google_results_bukuteks.csv', index=False)\n",
    "    data.append(link)\n",
    "    \n",
    "\n",
    "# Drop duplicates in data list\n",
    "# data = list(dict.fromkeys(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rujukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "try:\n",
    "    from googlesearch import search\n",
    "except ImportError: \n",
    "    print(\"No module named 'google' found\")\n",
    "\n",
    "data=[]\n",
    "\n",
    "# to search\n",
    "query = \"site:rujukan.dbp.gov.my filetype:pdf\"\n",
    "\n",
    "links=search(query, num=25, stop=300, pause=randint(10,20))\n",
    "\n",
    "for link in links:\n",
    "    pd.DataFrame(data,columns=['url']).to_csv('google_results_rujukan.csv', index=False)\n",
    "    data.append(link)\n",
    "    \n",
    "\n",
    "# Drop duplicates in data list\n",
    "# data = list(dict.fromkeys(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pemacudbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from random import randint\n",
    " \n",
    "links=pd.read_csv(\"google_results_pemacudbp.csv\")#['url'].to_list()\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"../.../../../../../\")\n",
    "os.getcwd()\n",
    "#os.mkdir('tmp')\n",
    "os.chdir('tmp/pemacudbp')\n",
    "os.listdir()\n",
    "\n",
    "links['id']=links['url'].str.extract(r'ti=([\\w]+)&')\n",
    "links\n",
    "\n",
    "# remove \".pdf\" \n",
    "compare_table=pd.DataFrame(os.listdir(),columns=['id'])\n",
    "compare_table['id']=compare_table['id'].str.replace('.pdf','')\n",
    "compare_table['status']='downloaded'\n",
    "\n",
    "links=pd.merge(links,compare_table,how='left',on=\"id\")\n",
    "links=links[links['status'].isnull()]\n",
    "links=links['url'].to_list()\n",
    "\n",
    "pattern = r'ti=([\\w]+)&'\n",
    "\n",
    "for link in links:\n",
    "    # timeout to avoid blocking\n",
    "    time.sleep(randint(10,20))\n",
    "    \n",
    "    print(link)\n",
    "    try:\n",
    "        match = re.search(pattern, link)\n",
    "        r=requests.get(link,allow_redirects=True)\n",
    "        \n",
    "        #if no respond continue\n",
    "        if r.status_code != 200:\n",
    "            print(r.status_code)\n",
    "            pass\n",
    "        else:\n",
    "            print(r.status_code)\n",
    "            open(str(match.group(1))+'.pdf', 'wb').write(r.content)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bukuteks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from random import randint\n",
    " \n",
    "links=pd.read_csv(\"google_results_bukuteks.csv\")#['url'].to_list()\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"../.../../../../../\")\n",
    "os.getcwd()\n",
    "#os.mkdir('tmp/bukuteks')\n",
    "os.chdir('tmp/bukuteks')\n",
    "os.listdir()\n",
    "\n",
    "'''\n",
    "links['id']=links['url'].str.extract(r'ti=([\\w]+)&')\n",
    "\n",
    "\n",
    "# remove \".pdf\" \n",
    "compare_table=pd.DataFrame(os.listdir(),columns=['id'])\n",
    "compare_table['id']=compare_table['id'].str.replace('.pdf','')\n",
    "compare_table['status']='downloaded'\n",
    "\n",
    "links=pd.merge(links,compare_table,how='left',on=\"id\")\n",
    "links=links[links['status'].isnull()]\n",
    "links=links['url'].to_list()\n",
    "\n",
    "pattern = r'ti=([\\w]+)&'\n",
    "'''\n",
    "\n",
    "i=0\n",
    "\n",
    "for link in links['url'].to_list():\n",
    "    # timeout to avoid blocking\n",
    "    time.sleep(randint(10,20))\n",
    "    \n",
    "    i=i+1\n",
    "    print(link)\n",
    "    try:\n",
    "        r=requests.get(link,allow_redirects=True)\n",
    "        \n",
    "        #if no respond continue\n",
    "        if r.status_code != 200:\n",
    "            print(r.status_code)\n",
    "            pass\n",
    "        else:\n",
    "            print(r.status_code)\n",
    "            open('bukuteks-'+str(i)+'.pdf', 'wb').write(r.content)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eseminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from random import randint\n",
    " \n",
    "links=pd.read_csv(\"google_results_eseminar.csv\")#['url'].to_list()\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"../.../../../../../\")\n",
    "os.getcwd()\n",
    "os.mkdir('tmp/eseminar')\n",
    "os.chdir('tmp/eseminar')\n",
    "os.listdir()\n",
    "\n",
    "'''\n",
    "links['id']=links['url'].str.extract(r'ti=([\\w]+)&')\n",
    "\n",
    "\n",
    "# remove \".pdf\" \n",
    "compare_table=pd.DataFrame(os.listdir(),columns=['id'])\n",
    "compare_table['id']=compare_table['id'].str.replace('.pdf','')\n",
    "compare_table['status']='downloaded'\n",
    "\n",
    "links=pd.merge(links,compare_table,how='left',on=\"id\")\n",
    "links=links[links['status'].isnull()]\n",
    "links=links['url'].to_list()\n",
    "\n",
    "pattern = r'ti=([\\w]+)&'\n",
    "'''\n",
    "\n",
    "i=0\n",
    "\n",
    "for link in links['url'].to_list():\n",
    "    # timeout to avoid blocking\n",
    "    time.sleep(randint(10,20))\n",
    "    \n",
    "    i=i+1\n",
    "    print(link)\n",
    "    try:\n",
    "        r=requests.get(link,allow_redirects=True)\n",
    "        \n",
    "        #if no respond continue\n",
    "        if r.status_code != 200:\n",
    "            print(r.status_code)\n",
    "            pass\n",
    "        else:\n",
    "            print(r.status_code)\n",
    "            open('eseminar-'+str(i)+'.pdf', 'wb').write(r.content)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rujukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from random import randint\n",
    " \n",
    "links=pd.read_csv(\"google_results_rujukan.csv\")#['url'].to_list()\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"../.../../../../../\")\n",
    "os.getcwd()\n",
    "os.mkdir('tmp/rujukan')\n",
    "os.chdir('tmp/rujukan')\n",
    "os.listdir()\n",
    "\n",
    "'''\n",
    "links['id']=links['url'].str.extract(r'ti=([\\w]+)&')\n",
    "\n",
    "\n",
    "# remove \".pdf\" \n",
    "compare_table=pd.DataFrame(os.listdir(),columns=['id'])\n",
    "compare_table['id']=compare_table['id'].str.replace('.pdf','')\n",
    "compare_table['status']='downloaded'\n",
    "\n",
    "links=pd.merge(links,compare_table,how='left',on=\"id\")\n",
    "links=links[links['status'].isnull()]\n",
    "links=links['url'].to_list()\n",
    "\n",
    "pattern = r'ti=([\\w]+)&'\n",
    "'''\n",
    "\n",
    "i=0\n",
    "\n",
    "for link in links['url'].to_list():\n",
    "    # timeout to avoid blocking\n",
    "    time.sleep(randint(10,20))\n",
    "    \n",
    "    i=i+1\n",
    "    print(link)\n",
    "    try:\n",
    "        r=requests.get(link,allow_redirects=True)\n",
    "        \n",
    "        #if no respond continue\n",
    "        if r.status_code != 200:\n",
    "            print(r.status_code)\n",
    "            pass\n",
    "        else:\n",
    "            print(r.status_code)\n",
    "            open('rujukan-'+str(i)+'.pdf', 'wb').write(r.content)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text extract pemacudbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from random import randint\n",
    " \n",
    "links=pd.read_csv(\"google_results_pemacudbp.csv\")#['url'].to_list()\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"../.../../../../../\")\n",
    "os.getcwd()\n",
    "#os.mkdir('tmp')\n",
    "os.chdir('tmp/pemacudbp')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links['filename']=links['url'].str.extract(r'ti=([\\w]+)&')+'.pdf'\n",
    "data_pemacudbp=pd.merge(links,pd.DataFrame(os.listdir(),columns=['filename']),how='left',on='filename')#.iloc[0,0]\n",
    "data_pemacudbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain to parse pdf to text\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    ttl_page=0\n",
    "    text=''\n",
    "    \n",
    "    while ttl_page<len(loader.load()):\n",
    "        for document in documents:\n",
    "            text+=' '+document.page_content\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply lambda load_pdf function\n",
    "\n",
    "data_pemacudbp['extracted_text']=data_pemacudbp['filename'].apply(lambda x: load_pdf(x))\n",
    "data_pemacudbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pemacudbp=data_pemacudbp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pemacudbp['len'] = data_pemacudbp['extracted_text'].astype(str).map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../')\n",
    "os.chdir('Github/malaysian-dataset/crawl/dbp')\n",
    "data_pemacudbp.to_csv('data_pemacudbp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = 'AIzaSyALyn_98P0FifLwkY8xqy3Xy7_mWB6c828'\n",
    "SEARCH_ENGINE_ID = '55ec5be566cda4188'\n",
    "QUERY = 'site:malaysiakini.com najib razak'\n",
    "\n",
    "url = f'https://www.googleapis.com/customsearch/v1?key={API_KEY}&cx={SEARCH_ENGINE_ID}&q={QUERY}'\n",
    "response = requests.get(url)\n",
    "results = response.json()['items']\n",
    "\n",
    "for result in results:\n",
    "    print(result['title'])\n",
    "    print(result['link'])\n",
    "    print(result['snippet'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "#https://developers.google.com/custom-search/v1/overview\n",
    "#https://programmablesearchengine.google.com/controlpanel/overview?cx=55ec5be566cda4188\n",
    "\n",
    "# For Windows Command Prompt\n",
    "set GOOGLE_API_KEY=AIzaSyALyn_98P0FifLwkY8xqy3Xy7_mWB6c828\n",
    "set SEARCH_ENGINE_ID=55ec5be566cda4188\n",
    "\n",
    "# For PowerShell\n",
    "$env:GOOGLE_API_KEY=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "$env:SEARCH_ENGINE_ID=\"55ec5be566cda4188\"\n",
    "\n",
    "# For Linux/Mac terminal\n",
    "export GOOGLE_API_KEY=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "export SEARCH_ENGINE_ID=55ec5be566cda4188\n",
    "'''\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get credentials from environment variables\n",
    "API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "SEARCH_ENGINE_ID = os.environ.get('SEARCH_ENGINE_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Najib Razak's\n",
      "Link: https://news.google.com/gn/news/explore/section/q/Najib%20Razak/Najib%20Razak?ned=us\n",
      "Snippet: Malaysian court acquits wife of ex-PM Najib of money laundering and tax evasion · Malaysian Prosecutors Challenge Acquittal of Najib Razak's Wife · Najib Razak's ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: [PODCAST] The People v Najib Razak EP 70: I put my trust in you ...\n",
      "Link: https://news.google.com/articles/CCAiCy1CZm81NEhkMDBnmAEB?hl=en-MY&gl=MY&ceid=MY%3Aen\n",
      "Snippet: Jan 21, 2020 ... Najib Razak told the court that he trusted SRC's board of directors -- a statement he made more than once -- as it comprised of ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: [PODCAST] The People v Najib Razak EP 74: Royal money used ...\n",
      "Link: https://news.google.com/articles/CCAiC3RfaW9vRnNlcEE4mAEB?hl=en-MY&gl=MY&ceid=MY%3Aen\n",
      "Snippet: Feb 4, 2020 ... Najib Razak relied on Jho Low because he had confirmed that the businessman had a special relationship with the Saudi royalty.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Former Malaysian prime minister Najib Razak found guilty of ...\n",
      "Link: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9SUJ2MGs1cTlwZmvSAQA?oc=5\n",
      "Snippet: Jul 28, 2020 ... Former Malaysian prime minister Najib Razak has been found guilty on all seven corruption charges in his first trial linked to a ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Former Malaysian PM Najib Razak charged: All you need to know ...\n",
      "Link: https://news.google.com/articles/CCAiC183VnlWcUFuRHk0mAEB?hl=en-TZ&gl=TZ&ceid=TZ%3Aen\n",
      "Snippet: Jul 3, 2018 ... Former Malaysian prime minister Najib Razak was charged in court on Wednesday (Jul 4), following a probe into how billions of dollars went ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: [PODCAST] The Najib Razak 1MDB Trial EP 47: Pent-up Frustration ...\n",
      "Link: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9MjVvRWhpdkxKR2_SAQA?oc=5\n",
      "Snippet: Feb 8, 2021 ... February 8, 2021 – It is an unspoken culture in the 1MDB workplace to be a follower rather than a leader or find your career jeopardised, ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Former Malaysian PM Najib Razak to learn fate in 1MDB trial in July ...\n",
      "Link: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9SjU1cG4wYkQxNWfSAQA?oc=5\n",
      "Snippet: Jun 5, 2020 ... Malaysia's high court is to deliver its first verdict on former premier Najib Razak at the end of July. Najib is accused of misappropriating ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Malaysia: Bags of cash, jewellery seized from Najib's properties | Al ...\n",
      "Link: https://news.google.com/articles/CCAiC3I1QlR3bjFacW1JmAEB?hl=en-US&gl=US&ceid=US%3Aen\n",
      "Snippet: May 18, 2018 ... Anti-corruption investigators in Malaysia have summoned former Prime Minister Najib Razak for questioning after almost 300 bags of cash, ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Former Malaysian PM Najib Razak appeals corruption conviction in ...\n",
      "Link: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9RHJ5S0RKQlRuRnPSAQA?oc=5\n",
      "Snippet: Apr 5, 2021 ... Former Malaysian Prime Minister Najib Razak has appeared in court at the start of an appeal over his conviction on corruption charges linked ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Former Malaysian prime minister Najib Razak pleads not guilty to ...\n",
      "Link: https://news.google.com/articles/CAIiEIJCAh6SwqX2OP3QLDyJpNcqFwgEKg4IACoGCAow3vI9MPeaCDD7kIkG\n",
      "Snippet: Aug 7, 2018 ... Najib Razak pleads not guilty to three new counts of money laundering related to the alleged multibillion-dollar looting of a state ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "# Get credentials from environment variables\n",
    "API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "SEARCH_ENGINE_ID = os.environ.get('SEARCH_ENGINE_ID')\n",
    "QUERY = 'najib razak'\n",
    "\n",
    "def search_articles(query: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Search for articles using Google Custom Search API\n",
    "    \"\"\"\n",
    "    if not API_KEY or not SEARCH_ENGINE_ID:\n",
    "        raise ValueError(\"API_KEY and SEARCH_ENGINE_ID must be set in environment variables\")\n",
    "    \n",
    "    url = 'https://www.googleapis.com/customsearch/v1'\n",
    "    params = {\n",
    "        'key': API_KEY,\n",
    "        'cx': SEARCH_ENGINE_ID,\n",
    "        'q': query\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "        \n",
    "        data = response.json()\n",
    "        return data.get('items', [])\n",
    "        \n",
    "    except RequestException as e:\n",
    "        print(f\"Error making request: {e}\")\n",
    "        return []\n",
    "\n",
    "def display_results(results: List[Dict]) -> None:\n",
    "    \"\"\"\n",
    "    Display search results in a formatted way\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "        \n",
    "    for result in results:\n",
    "        print(f\"Title: {result.get('title', 'N/A')}\")\n",
    "        print(f\"Link: {result.get('link', 'N/A')}\")\n",
    "        print(f\"Snippet: {result.get('snippet', 'N/A')}\")\n",
    "        print(\"-\" * 80)\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        results = search_articles(QUERY)\n",
    "        display_results(results)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Concerns remain despite insurance premium hike limits | The Star\n",
      "Link: https://www.thestar.com.my/news/nation/2024/12/22/concerns-remain-despite-insurance-premium-hike-limits\n",
      "Snippet: 13 hours ago ... PETALING JAYA: Despite Bank Negara capping insurance premium hikes at 10% per annum, there is lingering concern among medical insurance policyholders on ...\n",
      "Published Date: N/A\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Most read this week\n",
      "Link: https://theedgemalaysia.com/microsite/weekly-mostread\n",
      "Snippet: 4 hours ago ... The proposed abolition of the Rule of 78 by Bank Negara Malaysia could “pave the way” for similar reforms in other financing products, including hire ...\n",
      "Published Date: N/A\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Insurance Industry In Limelight Due To Public Outcry ... - BERNAMA\n",
      "Link: https://www.bernama.com/misc/rss/news.php?id=2376013\n",
      "Snippet: 11 hours ago ... In the Financial Stability Review First Half 2024 released by Bank Negara Malaysia (BNM), it was reported that the overall profitability of life insurance and ...\n",
      "Published Date: 22/12/2024 10:29 AM\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Private hospitals group committed to finding solutions to rising ...\n",
      "Link: https://www.nst.com.my/news/nation/2024/12/1151673/private-hospitals-group-committed-finding-solutions-rising-healthcare\n",
      "Snippet: 5 hours ago ... Its president, Datuk Dr Kuljit Singh, said Bank Negara ... He said this in response to recent revelations by Bank Negara and the Health Ministry about ...\n",
      "Published Date: 2024-12-22T16:15:39+08:00\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Highlight | The Edge Malaysia\n",
      "Link: https://theedgemalaysia.com/flash-categories/Highlight\n",
      "Snippet: 3 hours ago ... Medical insurance premium hike to be staggered and kept below 10% yearly, says BNMBank Negara Malaysia (BNM) has announced a series of interim measures to ...\n",
      "Published Date: N/A\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: FPAM Welcomes BNM Premium Cap - Urges Long ... - BERNAMA\n",
      "Link: https://www.bernama.com/en/business/news.php/news.php?id=2375955\n",
      "Snippet: 19 hours ago ... KUALA LUMPUR, Dec 21 (Bernama) -- The Financial Planning Association of Malaysia (FPAM) has welcomed Bank Negara Malaysia's (BNM) move to cap annual premium ...\n",
      "Published Date: 21/12/2024 06:10 PM\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: theedgemalaysia.com | The Edge Malaysia\n",
      "Link: https://theedgemalaysia.com/author/theedgemalaysia.com?page=1\n",
      "Snippet: 4 hours ago ... Bank Negara Malaysia (BNM) announced on Friday evening several temporary measures to address the uproar over the sizeable medical insurance premium hikes ...\n",
      "Published Date: N/A\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Parliament | The Edge Malaysia\n",
      "Link: https://theedgemalaysia.com/flash-categories/parliament\n",
      "Snippet: 5 hours ago ... ... Bank Negara Malaysia (BNM). More from Parliament. Parliament. 18 Dec 2024, 05:53 pm. Ten new ETS trains to be operational by 1Q2025, 50 more on the way, Senate ...\n",
      "Published Date: N/A\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Pertubuhan Berita Nasional Malaysia - BERNAMA\n",
      "Link: https://www.bernama.com/bm/ekonomi/?id=2374792\n",
      "Snippet: 23 hours ago ... ... Bank Negara Malaysia (BNM) untuk mengehadkan kenaikan premium tahunan bagi insurans perubatan dan takaful pada 10 peratus. [ baca lagi ]. 4jam lalu. LAGI ...\n",
      "Published Date: 21/12/2024 22:41:43\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Title: Bernama - Malaysiakini\n",
      "Link: https://www.malaysiakini.com/en/author/Bernama\n",
      "Snippet: 7 hours ago ... This comes after Bank Negara intervened on the matter. Bernama. ⋅. 1 d ago. Insurers announce interim steps to support those affected by repricing · Eight plead ...\n",
      "Published Date: N/A\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "# Get credentials from environment variables\n",
    "API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "SEARCH_ENGINE_ID = os.environ.get('SEARCH_ENGINE_ID')\n",
    "QUERY = '\"bank negara\"'\n",
    "\n",
    "def search_articles(query: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Search for articles using Google Custom Search API\n",
    "    Restricts results to the last 24 hours\n",
    "    \"\"\"\n",
    "    if not API_KEY or not SEARCH_ENGINE_ID:\n",
    "        raise ValueError(\"API_KEY and SEARCH_ENGINE_ID must be set in environment variables\")\n",
    "    \n",
    "    url = 'https://www.googleapis.com/customsearch/v1'\n",
    "    params = {\n",
    "        'key': API_KEY,\n",
    "        'cx': SEARCH_ENGINE_ID,\n",
    "        'q': query,\n",
    "        'dateRestrict': 'd1'  # Restrict to last 24 hours (d1 means 1 day)\n",
    "        # Alternative options:\n",
    "        # 'h[number]' for hours (e.g., 'h12' for last 12 hours)\n",
    "        # 'd[number]' for days\n",
    "        # 'w[number]' for weeks\n",
    "        # 'm[number]' for months\n",
    "        # 'y[number]' for years\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        results = data.get('items', [])\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No results found in the last 24 hours.\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except RequestException as e:\n",
    "        print(f\"Error making request: {e}\")\n",
    "        return []\n",
    "\n",
    "def display_results(results: List[Dict]) -> None:\n",
    "    \"\"\"\n",
    "    Display search results in a formatted way\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "        \n",
    "    for result in results:\n",
    "        print(f\"Title: {result.get('title', 'N/A')}\")\n",
    "        print(f\"Link: {result.get('link', 'N/A')}\")\n",
    "        print(f\"Snippet: {result.get('snippet', 'N/A')}\")\n",
    "        # Try to get the date if available\n",
    "        if 'pagemap' in result and 'metatags' in result['pagemap']:\n",
    "            date = result['pagemap']['metatags'][0].get('article:published_time', 'N/A')\n",
    "            print(f\"Published Date: {date}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        results = search_articles(QUERY)\n",
    "        display_results(results)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'customsearch#result',\n",
       " 'title': 'Bloomberg Asia',\n",
       " 'htmlTitle': 'Bloomberg Asia',\n",
       " 'link': 'https://www.bloomberg.com/asia',\n",
       " 'displayLink': 'www.bloomberg.com',\n",
       " 'snippet': \"3 hours ago ... A View to 2025: Enough With the Central Bank Hawks and Doves. By Daniel Moss, Columnist. Apple's $1 Billion Investment May Be Fleeting Win for Indonesia\\xa0...\",\n",
       " 'htmlSnippet': '3 hours ago <b>...</b> A View to 2025: Enough With the Central <b>Bank</b> Hawks and Doves. By Daniel Moss, Columnist. Apple&#39;s $1 Billion Investment May Be Fleeting Win for Indonesia&nbsp;...',\n",
       " 'formattedUrl': 'https://www.bloomberg.com/asia',\n",
       " 'htmlFormattedUrl': 'https://www.bloomberg.com/asia',\n",
       " 'pagemap': {'cse_thumbnail': [{'src': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTGL3hoIDcquIf9ZI83HOfVWsygot6DGmLC7kQ_-No5XJgRZAiso5bw6cI&s',\n",
       "    'width': '310',\n",
       "    'height': '163'}],\n",
       "  'metatags': [{'apple-itunes-app': 'app-id=281941097',\n",
       "    'og:image': 'https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i5PGsA7G0NRA/v0/1200x630.png',\n",
       "    'og:type': 'website',\n",
       "    'og:site_name': 'Bloomberg.com',\n",
       "    'og:title': 'Bloomberg Asia',\n",
       "    'parsely-title': 'Bloomberg Asia',\n",
       "    'og:description': 'Bloomberg delivers business and markets news, data, analysis, and video to the world, featuring stories from Businessweek and Bloomberg News',\n",
       "    'next-head-count': '2',\n",
       "    'parsely-type': 'sectionpage',\n",
       "    'viewport': 'width=device-width',\n",
       "    'parsely-link': 'https://www.bloomberg.com/asia',\n",
       "    'parsely-image-url': 'https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i5PGsA7G0NRA/v0/1200x630.png',\n",
       "    'og:url': 'https://www.bloomberg.com/asia',\n",
       "    'format-detection': 'telephone=no'}],\n",
       "  'cse_image': [{'src': 'https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i5PGsA7G0NRA/v0/1200x630.png'}]}}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results[0]#.metatags\n",
    "results[2]#.get('pagemap').get('metatags')[0]#.get('og:description')\n",
    "# get dict element\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local media reported on Saturday that senior executive of RHB Bank Bhd Datuk Fad'l Mohamed will replace Bursa Malaysia Bhd's Chief Executive Officer Datuk Muhamad Umar Swift. The 60-year-old Muhamad Umar has helmed the exchange company since Feb 11, 2019, and is reportedly not considering an extension of his service…\n",
      "--------------------------------------------------------------------------------\n",
      "The Financial Planning Association of Malaysia (FPAM) welcomed Bank Negara Malaysia's (BNM) move to cap annual premium increases for medical insurance and takaful at 10%, noting that the rising medical costs and healthcare utilisation rate must be addressed to prevent significant premium hikes in the future, reported Bernama on Dec…\n",
      "--------------------------------------------------------------------------------\n",
      "Bloomberg delivers business and markets news, data, analysis, and video to the world, featuring stories from Businessweek and Bloomberg News\n",
      "--------------------------------------------------------------------------------\n",
      "Find the latest stock market news from every corner of the globe at Reuters.com, your online source for breaking international market and finance news\n",
      "--------------------------------------------------------------------------------\n",
      "Reuters.com is your online source for the latest Asia news stories and current events, ensuring our readers up to date with any breaking news developments\n",
      "--------------------------------------------------------------------------------\n",
      "The latest international Ariba Shahid news and views from Reuters - one of the world's largest news agencies\n",
      "--------------------------------------------------------------------------------\n",
      "As part of Apple’s latest offer, one of its suppliers will set up a plant producing AirTags on the island of Batam and employ around 1,000 workers.\n",
      "--------------------------------------------------------------------------------\n",
      "ASEAN Taxonomy Version 3 with updated technical screening criteria for the construction and transportation sectors was released on Friday, incorporating feedback and suggestions from stakeholders up to October 2024 to further sustainability goals across the region, according to a press statement dated Dec 20 released by the ASEAN Taxonomy Board…\n",
      "--------------------------------------------------------------------------------\n",
      "Discover the latest breaking news, in-depth stories, and updates from East & West Malaysia, including Sabah and Sarawak, on Free Malaysia Today. Stay informed with comprehensive coverage of local events, politics, and more.\n",
      "--------------------------------------------------------------------------------\n",
      "Bloomberg delivers business and markets news, data, analysis, and video to the world, featuring stories from Businessweek and Bloomberg News\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for result in results:\n",
    "    print(result.get('pagemap').get('metatags')[0].get('og:description'))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# langchain to parse pdf to text\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(os.listdir()[0])\n",
    "documents = loader.load()\n",
    "\n",
    "# pdf to text\n",
    "ttl_page=0\n",
    "\n",
    "text=''\n",
    "\n",
    "while ttl_page<len(loader.load()):\n",
    "    for document in documents:\n",
    "        text+=' '+document.page_content\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
