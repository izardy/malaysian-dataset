{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd68fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset, Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import linecache\n",
    "import json\n",
    "import mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb46ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open('locations.txt', 'r')\n",
    "lines = text_file.readlines()\n",
    "keyword_list = list(dict.fromkeys(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c47d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for no, keyword in enumerate(keyword_list):\n",
    "    filename = f'data/generated-location/{no}.jsonl'\n",
    "    results.append((keyword, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da895094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def loop(files):\n",
    "    files, _ = files\n",
    "    results = []\n",
    "    for file in tqdm(files):\n",
    "        keyword, file = file\n",
    "        if not os.path.exists(file):\n",
    "            continue\n",
    "        keyword = keyword.strip()\n",
    "        index = file.split('/')[-1].replace('.jsonl', '')\n",
    "        with open(file) as fopen:\n",
    "            i = 0\n",
    "            for l in fopen:\n",
    "                try:\n",
    "                    l = json.loads(l)\n",
    "                except:\n",
    "                    i += 1\n",
    "                    continue\n",
    "                filename = os.path.join('image-location', f'{index}-{i}.jpeg')\n",
    "                if not os.path.exists(filename):\n",
    "                    i += 1\n",
    "                    continue\n",
    "                    \n",
    "                l.pop('image_base64', None)\n",
    "                    \n",
    "                l['filename'] = filename\n",
    "                l['image'] = filename\n",
    "                l['keyword'] = keyword\n",
    "                    \n",
    "                results.append(l)\n",
    "                \n",
    "                i += 1\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d06dc5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1806/1806 [00:23<00:00, 77.83it/s] \n",
      "100%|██████████| 6/6 [00:02<00:00,  2.99it/s]t/s]]\n",
      " 36%|███▌      | 651/1806 [03:20<04:04,  4.71it/s]]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = mp.multiprocessing(results, loop, cores = 30, returned = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6075889",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4496a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(r)\n",
    "dataset = dataset.cast_column(\"image\", Image())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f564e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef77dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b26bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de67b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[-1]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ebcd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[100001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2248d007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[100001]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8007b2c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         dataset.push_to_hub(repo_id = 'malaysia-ai/crawl-google-image-malaysia-location')\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         pass\n",
    "    \n",
    "#     time.sleep(60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36b122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from io import BytesIO\n",
    "from datasets.table import embed_table_storage\n",
    "\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e882c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def shards_with_embedded_external_files(shard):\n",
    "    format = shard.format\n",
    "    shard = shard.with_format(\"arrow\")\n",
    "    shard = shard.map(\n",
    "        embed_table_storage,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        keep_in_memory=True,\n",
    "    )\n",
    "    shard = shard.with_format(**format)\n",
    "    return shard\n",
    "\n",
    "# shards = shards_with_embedded_external_files(shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72488d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir done-shard\n",
    "# !rm -rf done-shard/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d8b75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        num_shards = 1000\n",
    "        shards = (dataset.shard(num_shards=num_shards, index=i, contiguous=True) for i in range(num_shards))\n",
    "        for no, shard in tqdm(enumerate(shards)):\n",
    "            checkpoint = os.path.join('done-shard', f'{no}')\n",
    "            if os.path.exists(checkpoint):\n",
    "                continue\n",
    "\n",
    "            shard = shards_with_embedded_external_files(shard)\n",
    "\n",
    "            shard_path_in_repo = f\"data/train-{no:05d}-of-{num_shards:05d}.parquet\"\n",
    "            buffer = BytesIO()\n",
    "            shard.to_parquet(buffer)\n",
    "\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=buffer,\n",
    "                path_in_repo=shard_path_in_repo,\n",
    "                repo_id='malaysia-ai/crawl-google-image-malaysia-location',\n",
    "                repo_type='dataset',\n",
    "            )\n",
    "\n",
    "            with open(checkpoint, 'w') as fopen:\n",
    "                fopen.write('done')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb3abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
