{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f8c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/huseinzol05/98974ae8c6c7a65d4bc0af9f5003786a/raw/2e06e71ef7349a57bc58cc9913ae6bae1f9f8447/mp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65857f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "timestamps = [i * 0.02 for i in range(1500 + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fc2611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510940"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('prepare-force-alignment.json') as fopen:\n",
    "    d = json.load(fopen)\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2201a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = d[0]\n",
    "f = r['audio_filename']\n",
    "new_f = f.replace('/', '_').replace('.mp3', '.json').replace('.wav', '.json')\n",
    "filename = os.path.join('force_alignment', new_f)\n",
    "\n",
    "with open(filename) as fopen:\n",
    "    d_ = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da38a502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|0.06|> Bagaimanakah kita boleh mengendalikan ralat<|2.46|>',\n",
       " '<|2.84|> pada laman web menggunakan JavaScript?<|4.88|>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments, temp = [], [d_['word_timestamps'][0]]\n",
    "last_t = d_['word_timestamps'][0]['end']\n",
    "for c in d_['word_timestamps'][1:]:\n",
    "    if (c['start'] - last_t) > 0.2:\n",
    "        segments.append(temp)\n",
    "        temp = []\n",
    "        \n",
    "    last_t = c['end']\n",
    "    temp.append(c)\n",
    "    \n",
    "if len(temp):\n",
    "    segments.append(temp)\n",
    "    \n",
    "ts = []\n",
    "for s in segments:\n",
    "    start = min(timestamps, key=lambda t: abs(t - s[0]['start']))\n",
    "    end = min(timestamps, key=lambda t: abs(t - s[-1]['end']))\n",
    "    w = ' '.join([c['text'] for c in s])\n",
    "    t = f\"<|{start:.2f}|> {w}<|{end:.2f}|>\"\n",
    "    ts.append(t)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8436b779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.84, 4.88)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]['start'], s[-1]['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c075a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(rows):\n",
    "    rows, _ = rows\n",
    "    result = []\n",
    "    for r in tqdm(rows):\n",
    "        f = r['audio_filename']\n",
    "        new_f = f.replace('/', '_').replace('.mp3', '.json').replace('.wav', '.json')\n",
    "        filename = os.path.join('force_alignment', new_f)\n",
    "        if not os.path.exists(filename):\n",
    "            continue\n",
    "        \n",
    "        with open(filename) as fopen:\n",
    "            d_ = json.load(fopen)\n",
    "            \n",
    "        segments, temp = [], [d_['word_timestamps'][0]]\n",
    "        last_t = d_['word_timestamps'][0]['end']\n",
    "        for c in d_['word_timestamps'][1:]:\n",
    "            if (c['start'] - last_t) > 0.25:\n",
    "                segments.append(temp)\n",
    "                temp = []\n",
    "\n",
    "            last_t = c['end']\n",
    "            temp.append(c)\n",
    "\n",
    "        if len(temp):\n",
    "            segments.append(temp)\n",
    "\n",
    "        ts = []\n",
    "        for s in segments:\n",
    "            start = min(timestamps, key=lambda t: abs(t - s[0]['start']))\n",
    "            end = min(timestamps, key=lambda t: abs(t - s[-1]['end']))\n",
    "            w = ' '.join([c['text'] for c in s])\n",
    "            t = f\"<|{start:.2f}|> {w}<|{end:.2f}|>\"\n",
    "            ts.append(t)\n",
    "\n",
    "        ts = ''.join(ts)\n",
    "        new_text = text = f\"<|startoftranscript|><|ms|><|transcribe|>{ts}<|endoftext|>\"\n",
    "        \n",
    "        result.append({\n",
    "            'new_text': new_text,\n",
    "            'audio_filename': f.split('speech-instructions/')[1]\n",
    "        })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2633eda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3048.01it/s]\n"
     ]
    }
   ],
   "source": [
    "r = loop((d[:100], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4f2c8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new_text': '<|startoftranscript|><|ms|><|transcribe|><|0.06|> Bagaimanakah kita boleh mengendalikan ralat<|2.46|><|2.84|> pada laman web menggunakan JavaScript?<|4.88|><|endoftext|>',\n",
       " 'audio_filename': 'short-coding-2/0.mp3'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da41928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 14%|██████████▉                                                                     | 6964/51094 [00:04<00:28, 1526.16it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      " 18%|██████████████                                                                  | 8982/51094 [00:05<00:33, 1258.66it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:20<00:00, 2435.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:23<00:00, 2178.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:25<00:00, 2025.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:24<00:00, 2050.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:25<00:00, 1991.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:31<00:00, 1610.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:26<00:00, 1900.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:25<00:00, 2038.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:30<00:00, 1696.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 51094/51094 [00:38<00:00, 1336.10it/s]\n"
     ]
    }
   ],
   "source": [
    "r = mp.multiprocessing(d, loop, cores = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cfb5d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510940"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "840bf89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new_text': '<|startoftranscript|><|ms|><|transcribe|><|1.08|> Mengapa terdapat<|2.28|><|2.66|> tuduhan kronisme<|3.70|><|4.82|> dan nepotisme<|5.64|><|6.14|> terhadap kerajaan Malaysia,<|7.48|><|8.20|> terutamanya<|8.90|><|9.48|> berkaitan dengan<|10.32|><|10.62|> pelantikan politik peringkat tinggi?<|13.08|><|endoftext|>',\n",
       " 'audio_filename': 'partition-instructions-part-12/28940.mp3'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[-1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b56795b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(r).to_parquet('gather-force-alignment-segment-timestamps.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81bdda9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39de52bba7be48f690246f7f5eb8aea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gather-force-alignment-segment-timestamps.parquet:   0%|          | 0.00/40.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/malaysia-ai/STT-Whisper/commit/040aecb0ef60bea32a1c43655127b38e92098afd', commit_message='Upload data/malaysian_speech_instructions_segment_timestamp-00000-of-00001.parquet with huggingface_hub', commit_description='', oid='040aecb0ef60bea32a1c43655127b38e92098afd', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/malaysia-ai/STT-Whisper', endpoint='https://huggingface.co', repo_type='dataset', repo_id='malaysia-ai/STT-Whisper'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"gather-force-alignment-segment-timestamps.parquet\",\n",
    "    path_in_repo=\"data/malaysian_speech_instructions_segment_timestamp-00000-of-00001.parquet\",\n",
    "    repo_id=\"malaysia-ai/STT-Whisper\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
