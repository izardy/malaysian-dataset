# Toxicity Large

Original website, https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification

Added a few local toxicity keywords using lexicon, all steps in [notebook](notebook).

## download

url, https://f000.backblazeb2.com/file/malay-dataset/toxicity/

1. translated-0.json
2. translated-1000000.json
3. translated-1050000.json
4. translated-1100000.json
5. translated-1150000.json
6. translated-1200000.json
7. translated-1450000.json
8. translated-150000.json
9. translated-1500000.json
10. translated-1550000.json
11. translated-1600000.json
12. translated-1650000.json
13. translated-1700000.json
14. translated-1750000.json
15. translated-1800000.json
16. translated-250000.json
17. translated-300000.json
18. translated-350000.json
19. translated-400000.json
20. translated-450000.json
21. translated-50000.json
22. translated-500000.json
23. translated-550000.json
24. translated-600000.json
25. translated-650000.json
26. translated-700000.json
27. translated-750000.json
28. translated-850000.json
29. translated-900000.json
30. translated-950000.json

chinese, malay and indian labels from local tweets, https://huggingface.co/datasets/mesolitica/semisupervised-corpus/resolve/main/toxicity/kaum.json

Weak learning score using BERT Base for chinese, malay and indian labels, https://huggingface.co/datasets/mesolitica/semisupervised-corpus/resolve/main/toxicity/weak-learning-toxicity.json

## Citation

```bibtex
@misc{kaggle, title={Jigsaw Multilingual Toxic Comment Classification}, url={https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification}, journal={Kaggle}}
```