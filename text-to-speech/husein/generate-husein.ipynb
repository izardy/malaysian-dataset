{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b240a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0cc44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamicbatch_ttspipeline.f5_tts.load import (\n",
    "    load_f5_tts,\n",
    "    load_vocoder,\n",
    "    target_sample_rate,\n",
    "    hop_length,\n",
    "    nfe_step,\n",
    "    cfg_strength,\n",
    "    sway_sampling_coef,\n",
    ")\n",
    "from dynamicbatch_ttspipeline.f5_tts.utils import (\n",
    "    chunk_text,\n",
    "    convert_char_to_pinyin,\n",
    ")\n",
    "from pydub import AudioSegment, silence\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06f555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctc_forced_aligner import (\n",
    "    load_audio,\n",
    "    load_alignment_model,\n",
    "    generate_emissions,\n",
    "    preprocess_text,\n",
    "    get_alignments,\n",
    "    get_spans,\n",
    "    postprocess_results,\n",
    ")\n",
    "\n",
    "language = \"ms\" # ISO-639-3 Language code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 16\n",
    "\n",
    "alignment_model, alignment_tokenizer = load_alignment_model(\n",
    "    device,\n",
    "    dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78159e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272785"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "\n",
    "with open('chatbot-conversation-politics.json') as fopen:\n",
    "    text = json.load(fopen)\n",
    "        \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bad11c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': 'Untuk menangani isu rasuah dan akauntabiliti dalam politik Malaysia, pelbagai pembaharuan dan langkah boleh diambil.',\n",
       " 'normalized': 'Untuk menangani isu rasuah dan akauntabiliti dalam politik Malaysia , pelbagai pembaharuan dan langkah boleh diambil .'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03b71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = 'Hi, saya adalah pembantu AI anda, selamat berkenalan! apa yang saya boleh tolong untuk buatkan hari anda lebih ceria.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c865b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dtype = torch.bfloat16\n",
    "device = 'cuda'\n",
    "\n",
    "model_name = 'mesolitica/Malaysian-F5-TTS-v2'\n",
    "model = load_f5_tts(model_name = model_name, device = device, dtype = torch.float16)\n",
    "vocoder = load_vocoder(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e728299",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69961d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_input = 'husein-enhanced-v2.wav'\n",
    "dwav, sr_ = torchaudio.load(audio_input)\n",
    "dwav = dwav.mean(dim=0).numpy()\n",
    "target_rms = 0.1\n",
    "audio = dwav\n",
    "rms = np.sqrt(np.mean(np.square(audio)))\n",
    "if rms < target_rms:\n",
    "    audio = audio * target_rms / rms\n",
    "\n",
    "if sr_ != target_sample_rate:\n",
    "    audio = librosa.resample(audio, orig_sr = sr_, target_sr = target_sample_rate)\n",
    "    \n",
    "audios = torch.tensor(audio)[None].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6086f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi, saya adalah pembantu AI anda, selamat berkenalan! apa yang saya boleh tolong untuk buatkan hari anda lebih ceria. '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_text = original_text\n",
    "if not ref_text.endswith(\". \") and not ref_text.endswith(\"。\"):\n",
    "    if ref_text.endswith(\".\"):\n",
    "        ref_text += \" \"\n",
    "    else:\n",
    "        ref_text += \". \"\n",
    "    \n",
    "ref_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c083b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chars = int(len(ref_text.encode(\"utf-8\")) / (audios.shape[-1] / sr_) * (25 - audios.shape[-1] / sr_))\n",
    "ref_audio_len = audios.shape[-1] // hop_length\n",
    "speed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57da7262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘husein-chatbot-politics-normalized-v2’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# !rm -rf husein-chatbot-normalized-v2\n",
    "!mkdir husein-chatbot-politics-normalized-v2 husein-chatbot-politics-normalized-v2-failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec2ea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████                                                                        | 5944/90928 [11:30:17<163:25:47,  6.92s/it]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 13%|█████████▋                                                                  | 11536/90928 [22:39:49<108:42:03,  4.93s/it]"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "index = 1\n",
    "for i in tqdm(range((len(text) // 3) * index, (len(text) // 3) * (index + 1), 1)):\n",
    "    new_filename = os.path.join('husein-chatbot-politics-normalized-v2', f'{i}.mp3')\n",
    "    if os.path.exists(new_filename):\n",
    "        continue\n",
    "    \n",
    "    failed_filename = os.path.join('husein-chatbot-politics-normalized-v2-failed', f'{i}.mp3')\n",
    "    if os.path.exists(failed_filename):\n",
    "        continue\n",
    "\n",
    "    gen_text = text[i]['normalized'].replace('\\'', '').replace('\"', '')\n",
    "    gen_text = re.sub(r'[ ]+', ' ', gen_text).strip()\n",
    "    if len(gen_text) < 3:\n",
    "        continue\n",
    "    final_text_lists, durations, after_durations = [], [], []\n",
    "    text_list = [ref_text + gen_text]\n",
    "    final_text_list = convert_char_to_pinyin(text_list)\n",
    "    ref_text_len = len(ref_text.encode(\"utf-8\"))\n",
    "    gen_text_len = len(gen_text.encode(\"utf-8\"))\n",
    "    after_duration = int(ref_audio_len / ref_text_len * gen_text_len / speed)\n",
    "    final_text_lists = [final_text_list[0]]\n",
    "    durations = [ref_audio_len + after_duration]\n",
    "    after_durations = [after_duration]\n",
    "    \n",
    "    failed = True\n",
    "\n",
    "    for _ in range(5):\n",
    "        with torch.no_grad():\n",
    "            generated, _ = model.sample(\n",
    "                cond=audios.repeat(len(final_text_lists), 1),\n",
    "                text=final_text_lists,\n",
    "                duration=torch.Tensor(durations).to(device).type(torch.long),\n",
    "                steps=nfe_step,\n",
    "                cfg_strength=2,\n",
    "                sway_sampling_coef=-1.0,\n",
    "            )\n",
    "            generated_mel_spec = generated.to(torch.float32)[:, ref_audio_len:, :].permute(0, 2, 1)\n",
    "            generated_wave = vocoder.decode(generated_mel_spec)\n",
    "            if rms < target_rms:\n",
    "                generated_wave = generated_wave * rms / target_rms\n",
    "            actual_after_durations = [d * hop_length for d in after_durations]\n",
    "            new_wav = generated_wave[0, :actual_after_durations[0]]\n",
    "            audio_waveform = torchaudio.functional.resample(\n",
    "                new_wav, orig_freq=24000, new_freq=16000\n",
    "            ).type(torch.float16)\n",
    "            emissions, stride = generate_emissions(\n",
    "                alignment_model, audio_waveform, batch_size=1\n",
    "            )\n",
    "            tokens_starred, text_starred = preprocess_text(\n",
    "                gen_text,\n",
    "                romanize=True,\n",
    "                language=language,\n",
    "            )\n",
    "            segments, scores, blank_token = get_alignments(\n",
    "                emissions,\n",
    "                tokens_starred,\n",
    "                alignment_tokenizer,\n",
    "            )\n",
    "            spans = get_spans(tokens_starred, segments, blank_token)\n",
    "            word_timestamps = postprocess_results(text_starred, spans, stride, scores)\n",
    "            scores = [w['score'] for w in word_timestamps if w['score'] <= -15]\n",
    "            if not len(scores):\n",
    "                a = new_wav.cpu().numpy()\n",
    "                sf.write(new_filename, a, 24000)\n",
    "                failed = False\n",
    "                break\n",
    "    \n",
    "    if failed:\n",
    "        with open(failed_filename, 'w') as fopen:\n",
    "            fopen.write('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdeae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
