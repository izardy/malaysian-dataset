{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da01b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e12c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = {\n",
    "    'A': ('Bunga', 0, 'female'),\n",
    "    'B': ('Ariff', 1, 'male'),\n",
    "    'C': ('Ayu', 2, 'female'),\n",
    "    'D': ('Kamarul', 3, 'male'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio('../output-gtts/ms-MY-Wavenet-A_23851.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268b16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob('../output-gtts/*.mp3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1c25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from dataspeech import rate_apply, pitch_apply, snr_apply, squim_apply\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import DatasetDict\n",
    "from multiprocess import set_start_method\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f58ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../gtts-text.json') as fopen:\n",
    "    t = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff4c177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ketika perang Aceh meletus pada tahun seribu lapan ratus tujuh puluh tiga , Teuku Ibrahim Lamnga aktif berjuang di garisan depan .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4bd9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in files:\n",
    "    splitted = f.split('-')[-1].split('_')\n",
    "    speaker = splitted[0]\n",
    "    row = int(splitted[1].split('.')[0])\n",
    "    \n",
    "    speaker_id = speakers[speaker]\n",
    "    \n",
    "    data.append({\n",
    "        'audio': f,\n",
    "        'transcription': t[row],\n",
    "        'speaker': speaker_id[0],\n",
    "        'speaker_id': speaker_id[1],\n",
    "        'gender': speaker_id[2]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129ee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c9ba85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124276"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb651064",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate = 22050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "768e947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_column_name = 'audio'\n",
    "text_column_name = 'transcription'\n",
    "num_workers_per_gpu_for_squim = 4\n",
    "cpu_num_workers = 5\n",
    "penn_batch_size = 512\n",
    "num_workers_per_gpu_for_pitch = 4\n",
    "num_workers_per_gpu_for_snr = 1\n",
    "cpu_writer_batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8704a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "squim_dataset = dataset.map(\n",
    "    squim_apply,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    with_rank=True if torch.cuda.device_count()>0 else False,\n",
    "    num_proc=torch.cuda.device_count()*num_workers_per_gpu_for_squim if torch.cuda.device_count()>0 else cpu_num_workers,\n",
    "    remove_columns=[audio_column_name], # tricks to avoid rewritting audio\n",
    "    fn_kwargs={\"audio_column_name\": audio_column_name,},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce0eae9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "squim_dataset.save_to_disk('gtts-squim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f26630",
   "metadata": {},
   "outputs": [],
   "source": [
    "squim_dataset = load_from_disk('gtts-squim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_dataset = dataset.cast_column(audio_column_name, Audio(sampling_rate=16_000)).map(\n",
    "    pitch_apply,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    with_rank=True if torch.cuda.device_count()>0 else False,\n",
    "    num_proc=torch.cuda.device_count()*num_workers_per_gpu_for_pitch if torch.cuda.device_count()>0 else cpu_num_workers,\n",
    "    remove_columns=[audio_column_name], # tricks to avoid rewritting audio\n",
    "    fn_kwargs={\"audio_column_name\": audio_column_name, \"penn_batch_size\": penn_batch_size},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c3bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_dataset.save_to_disk('gtts-pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b41bc236",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_dataset = load_from_disk('gtts-pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_dataset = dataset.map(\n",
    "    snr_apply,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    with_rank=True if torch.cuda.device_count()>0 else False,\n",
    "    num_proc=torch.cuda.device_count()*num_workers_per_gpu_for_snr if torch.cuda.device_count()>0 else cpu_num_workers,\n",
    "    remove_columns=[audio_column_name], # tricks to avoid rewritting audio\n",
    "    fn_kwargs={\"audio_column_name\": audio_column_name},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3eae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_dataset.save_to_disk('gtts-snr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "109a6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_dataset = load_from_disk('gtts-snr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a9eff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column('utterance_pitch_mean', pitch_dataset['utterance_pitch_mean']).add_column(\n",
    "    'utterance_pitch_std', pitch_dataset['utterance_pitch_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b138edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column(\"snr\", snr_dataset[\"snr\"]).add_column(\"c50\", snr_dataset[\"c50\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07e1f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column(\"speech_duration\", snr_dataset[\"speech_duration\"])\n",
    "dataset = dataset.add_column(\"stoi\", squim_dataset[\"stoi\"]).add_column(\"si-sdr\", squim_dataset[\"sdr\"]).add_column(\"pesq\", squim_dataset[\"pesq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d31b366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a516768c5a44028bcc1121eaebbbbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/124276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda row: not np.isnan(row[\"snr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ab869e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    'train': dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93d21c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEAKER_RATE_BINS = [\"very slowly\", \"quite slowly\", \"slightly slowly\", \"moderate speed\", \"slightly fast\", \"quite fast\", \"very fast\"]\n",
    "SNR_BINS = [\"very noisy\", \"quite noisy\", \"slightly noisy\", \"moderate ambient sound\", \"slightly clear\", \"quite clear\", \"very clear\"]\n",
    "REVERBERATION_BINS = [\"very roomy sounding\", \"quite roomy sounding\", \"slightly roomy sounding\", \"moderate reverberation\", \"slightly confined sounding\", \"quite confined sounding\", \"very confined sounding\"]\n",
    "UTTERANCE_LEVEL_STD = [\"very monotone\", \"quite monotone\", \"slightly monotone\", \"moderate intonation\", \"slightly expressive\", \"quite expressive\", \"very expressive\"]\n",
    "\n",
    "# this one is supposed to be apply to speaker-level mean pitch, and relative to gender\n",
    "SPEAKER_LEVEL_PITCH_BINS = [\"very low pitch\", \"quite low pitch\", \"slightly low pitch\", \"moderate pitch\", \"slightly high pitch\", \"quite high pitch\", \"very high pitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8e1ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bins_dict = {}\n",
    "bin_edges_dict = {}\n",
    "\n",
    "speaker_level_pitch_bins = text_bins_dict.get(\"speaker_level_pitch_bins\", SPEAKER_LEVEL_PITCH_BINS)\n",
    "speaker_rate_bins = text_bins_dict.get(\"speaker_rate_bins\", SPEAKER_RATE_BINS)\n",
    "snr_bins = text_bins_dict.get(\"snr_bins\", SNR_BINS)\n",
    "reverberation_bins = text_bins_dict.get(\"reverberation_bins\", REVERBERATION_BINS)\n",
    "utterance_level_std = text_bins_dict.get(\"utterance_level_std\", UTTERANCE_LEVEL_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0422079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_to_text(dataset, text_bins, column_name, output_column_name, leading_split_for_bins=\"train\", batch_size = 4, num_workers = 1, std_tolerance=5, save_dir=None, only_save_plot=False, lower_range=None, bin_edges=None):\n",
    "    '''\n",
    "    Compute bins of `column_name` from the splits `leading_split_for_bins` and apply text bins to every split.\n",
    "    `leading_split_for_bins` can be a string or a list.\n",
    "    '''\n",
    "    if bin_edges is None:\n",
    "        values = []\n",
    "        for df in dataset:\n",
    "            for split in df:\n",
    "                if leading_split_for_bins is None or leading_split_for_bins in split:\n",
    "                    values.extend(df[split][column_name])\n",
    "        \n",
    "        # filter out outliers\n",
    "        values = np.array(values)\n",
    "        if std_tolerance is not None:\n",
    "            filtered_values = values[np.abs(values - np.mean(values)) < std_tolerance * np.std(values)]\n",
    "        else:\n",
    "            filtered_values = values\n",
    "\n",
    "        if save_dir is not None:\n",
    "            visualize_bins_to_text(values, filtered_values, \"Before filtering\", \"After filtering\", text_bins, save_dir, output_column_name, lower_range=lower_range)\n",
    "            \n",
    "        # speaking_rate can easily have outliers\n",
    "        if save_dir is not None and output_column_name==\"speaking_rate\":\n",
    "            visualize_bins_to_text(filtered_values, filtered_values, \"After filtering\", \"After filtering\", text_bins, save_dir, f\"{output_column_name}_after_filtering\", lower_range=lower_range)\n",
    "        \n",
    "        values = filtered_values\n",
    "        hist, bin_edges = np.histogram(values, bins = len(text_bins), range=(lower_range, values.max()) if lower_range else None)\n",
    "        \n",
    "        if only_save_plot:\n",
    "            return dataset, bin_edges\n",
    "    else:\n",
    "        print(f\"Already computed bin edges have been passed for {output_column_name}. Will use: {bin_edges}.\")\n",
    "\n",
    "    def batch_association(batch):\n",
    "        index_bins = np.searchsorted(bin_edges, batch, side=\"left\")\n",
    "        # do min(max(...)) when values are outside of the main bins\n",
    "        # it happens when value = min or max or have been filtered out from bins computation\n",
    "        batch_bins = [text_bins[min(max(i-1, 0), len(text_bins)-1)] for i in index_bins]\n",
    "        return {\n",
    "            output_column_name: batch_bins\n",
    "        }\n",
    "    \n",
    "    dataset = [df.map(batch_association, batched=True, batch_size=batch_size, input_columns=[column_name], num_proc=num_workers) for df in dataset]\n",
    "    return dataset, bin_edges\n",
    "\n",
    "def speaker_level_relative_to_gender(dataset, text_bins, speaker_column_name, gender_column_name, column_name, output_column_name, batch_size = 4, num_workers=1, std_tolerance=None, save_dir=None, only_save_plot=False, bin_edges=None):\n",
    "    '''\n",
    "    Computes mean values on a speaker level and computes bins on top relative to the gender column name.\n",
    "    Then associate a text bin to the column.\n",
    "    This time, doesn't use leading_split_for_bins, computes it for all. Could probably be optimized\n",
    "    '''\n",
    "    list_data = []\n",
    "    for df in dataset:\n",
    "        for split in df:\n",
    "            panda_data = df[split].remove_columns([col for col in df[split].column_names if col not in {speaker_column_name, column_name, gender_column_name}]).to_pandas()\n",
    "            list_data.append(panda_data)\n",
    "        \n",
    "    dataframe = pd.concat(list_data, ignore_index=True)\n",
    "    dataframe = dataframe.groupby(speaker_column_name).agg({column_name: \"mean\", gender_column_name: \"first\"})\n",
    "    if bin_edges is None:\n",
    "        bin_edges = {}\n",
    "        if save_dir is not None:\n",
    "            save_dict = {}\n",
    "            save_dict_afer_filtering = {}\n",
    "        for category in [\"male\", \"female\"]:\n",
    "            values = dataframe[dataframe[gender_column_name] == category][column_name]\n",
    "            values = np.array(values)\n",
    "            if save_dir is not None:\n",
    "                save_dict[category] = values\n",
    "            if std_tolerance is not None:\n",
    "                # filter out outliers\n",
    "                values = values[np.abs(values - np.mean(values)) < std_tolerance * np.std(values)]\n",
    "                if save_dir is not None:\n",
    "                    save_dict_afer_filtering[category] = values\n",
    "            bin_edges[category] = np.histogram(values, len(text_bins))[1]\n",
    "        \n",
    "        if save_dir is not None:\n",
    "            visualize_bins_to_text(save_dict[\"male\"], save_dict[\"female\"], \"Male distribution\", \"Female distribution\", text_bins, save_dir, output_column_name)\n",
    "            if std_tolerance is not None:\n",
    "                visualize_bins_to_text(save_dict_afer_filtering[\"male\"], save_dict_afer_filtering[\"female\"], \"Male distribution\", \"Female distribution\", text_bins, save_dir, f\"{output_column_name}_after_filtering\")\n",
    "\n",
    "        if only_save_plot:\n",
    "            return dataset, bin_edges\n",
    "     \n",
    "    speaker_id_to_bins = dataframe.apply(lambda x: np.searchsorted(bin_edges[x[gender_column_name]], x[column_name]), axis=1).to_dict()\n",
    "        \n",
    "    def batch_association(batch):\n",
    "        index_bins = [speaker_id_to_bins[speaker] for speaker in batch]\n",
    "        # do min(max(...)) when values are outside of the main bins\n",
    "        # it happens when value = min or max or have been filtered out from bins computation\n",
    "        batch_bins = [text_bins[min(max(i-1, 0), len(text_bins)-1)] for i in index_bins]\n",
    "        return {\n",
    "            output_column_name: batch_bins\n",
    "        }\n",
    "        \n",
    "    \n",
    "    dataset = [df.map(batch_association, batched=True, input_columns=[speaker_column_name], batch_size=batch_size, num_proc=num_workers) for df in dataset]\n",
    "    return dataset, bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efb62587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ba8cb01af14035a890918227f62a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=5):   0%|          | 0/124276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_edges = None\n",
    "pitch_std_tolerance = 5.\n",
    "dataset, pitch_bin_edges = speaker_level_relative_to_gender(\n",
    "    [dataset_dict], speaker_level_pitch_bins, 'speaker_id', \n",
    "    'gender', \"utterance_pitch_mean\", \"pitch\", \n",
    "    batch_size=100, num_workers=5, std_tolerance=None, \n",
    "    save_dir=None, only_save_plot=False, bin_edges=bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8df5f57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a265a2e72a834d45be4dfe18d17b69e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=5):   0%|          | 0/124276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, speaking_rate_bin_edges = bins_to_text(\n",
    "    dataset, \n",
    "    speaker_rate_bins, \"speech_duration\", \"speaking_rate\", \n",
    "    batch_size=100, num_workers=5, \n",
    "    leading_split_for_bins=None, \n",
    "    std_tolerance=None, save_dir=None, \n",
    "    only_save_plot=False, bin_edges=bin_edges_dict.get(\"speaking_rate\",None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb2263c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5caed921324d2bbc823b4aac63a2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=5):   0%|          | 0/124276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, noise_bin_edges = bins_to_text(\n",
    "    dataset, snr_bins, \"snr\", \"noise\", \n",
    "    batch_size=100, num_workers=5, \n",
    "    leading_split_for_bins=None, \n",
    "    std_tolerance=None, save_dir=None, only_save_plot=False, bin_edges=bin_edges_dict.get(\"noise\",None), \n",
    "                                        lower_range=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "013a8270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fba76e54a94f1f9a9a8c5ffbd73e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=5):   0%|          | 0/124276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, reverberation_bin_edges = bins_to_text(\n",
    "    dataset, reverberation_bins, \"c50\", \"reverberation\", \n",
    "    batch_size=100, num_workers=5, \n",
    "    leading_split_for_bins=None, \n",
    "    std_tolerance=None, \n",
    "    save_dir=None, only_save_plot=False, \n",
    "    bin_edges=bin_edges_dict.get(\"reverberation\",None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfba2fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b9e0622466461081fabb8db4c52c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=5):   0%|          | 0/124276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, speech_monotony_bin_edges = bins_to_text(\n",
    "    dataset, utterance_level_std, \n",
    "    \"utterance_pitch_std\", \n",
    "    \"speech_monotony\", \n",
    "    batch_size=100, \n",
    "    num_workers=5, \n",
    "    leading_split_for_bins=None, \n",
    "    std_tolerance=None, \n",
    "    save_dir=None, only_save_plot=False, bin_edges=bin_edges_dict.get(\"speech_monotony\",None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "993b5256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0159c4dbd6164a31ae612974fd4793bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/17 shards):   0%|          | 0/124276 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[0].save_to_disk('gtts-metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8573b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8G\tgtts-metadata\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs gtts-metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86856e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '../output-gtts/ms-MY-Wavenet-A_0.mp3',\n",
       "  'array': array([-0.00083028, -0.00129574, -0.00129971, ...,  0.00044667,\n",
       "          0.00043588,  0.0003486 ]),\n",
       "  'sampling_rate': 22050},\n",
       " 'transcription': 'Ketika perang Aceh meletus pada tahun seribu lapan ratus tujuh puluh tiga , Teuku Ibrahim Lamnga aktif berjuang di garisan depan .',\n",
       " 'speaker': 'Bunga',\n",
       " 'speaker_id': 0,\n",
       " 'gender': 'female',\n",
       " 'utterance_pitch_mean': 220.41683959960938,\n",
       " 'utterance_pitch_std': 42.64897537231445,\n",
       " 'snr': 62.63203430175781,\n",
       " 'c50': 59.670066833496094,\n",
       " 'speech_duration': 8.133750000000003,\n",
       " 'stoi': 0.9968859553337097,\n",
       " 'si-sdr': 25.412067413330078,\n",
       " 'pesq': 3.9492032527923584,\n",
       " 'pitch': 'very low pitch',\n",
       " 'speaking_rate': 'quite slowly',\n",
       " 'noise': 'quite clear',\n",
       " 'reverberation': 'very confined sounding',\n",
       " 'speech_monotony': 'quite monotone'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1aafe0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You will be given 6 descriptive keywords related to an audio sample of [speaker_name]'s speech. These keywords include:\n",
    "1. The gender (e.g., male, female)\n",
    "2. The level of reverberation (e.g., very distant-sounding, quite distant-sounding, slightly distant-sounding, moderately balanced reverberation, slightly close-sounding, quite close-sounding, very close-sounding)\n",
    "3. The amount of noise the sample (e.g., very noisy, quite noisy, slightly noisy, balanced in clarity, slightly clean, quite clean, very clean)\n",
    "4. The tone of the speaker's voice (e.g., very monotone, quite monotone, slightly monotone, moderately dynamic, slightly expressive and animated, quite expressive and animated, very expressive and animated)\n",
    "5. The pace of the speaker's delivery (e.g., very slowly, quite slowly, slightly slowly, moderate speed, slightly fast, quite fast, very fast)\n",
    "6. The pitch of the speaker's voice (e.g., very low-pitch, quite low-pitch, slightly low-pitch, moderate pitch, slightly high-pitch, quite high-pitch, very high-pitch)\n",
    "\n",
    "Your task is to create a text description using these keywords that accurately describes the speech sample. Ensure that the generated description is grammatically correct, easy to understand, and most importantly, concise. \n",
    "You can optionally change the order of keywords, and replace synonymous terms. You can also optionally omit the following terms, as they are default terms: 'moderately balanced reverberation', 'balanced in clarity', 'moderately dynamic', 'moderate speed' and 'moderate pitch'.\n",
    "If the amount of noise is 'very noisy' and the level of reverberation is 'distant-sounding', you must include words such as 'very poor recording' in the description. Likewise, if the amount of noise is 'very clear' and the level of reverberation is 'very close-sounding', you must include terms like 'very good recording' in the description. \n",
    "Otherwise, do not add extra details beyond what has been provided, and only return the generated description.\n",
    "\n",
    "For example, given the following keywords: 'female', 'slightly distant-sounding', 'slightly noisy', 'very expressive', 'moderate pitch', 'very slowly', a valid description would be: '[speaker_name], a woman with a moderately pitched voice speaks very slowly but has an animated delivery in an echoey room with some background noise.'.\n",
    "Another valid description would be: '[speaker_name] in a room with slight background noise, a female speaker delivers an animated and expressive speech,at a very slow pace.'\n",
    "Another valid description would be: '[speaker_name], with female voice enunciates an animated and expressive speech. Her voice is slightly distant-sounding, with some background noise present. She speaks very slowly with a moderate pitch but a very expressive tone.'\n",
    "For the keywords: '[gender]', '[reverberation]', '[noise]', '[speech_monotony]', '[pitch]', '[speaking_rate]', return the corresponding description in JSON {'result'}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0df9fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_COLUMNS = {\"gender\", \"pitch\", \"noise\", \"reverberation\", \"speech_monotony\", \"speaking_rate\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a66f3502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'transcription', 'speaker', 'speaker_id', 'gender', 'utterance_pitch_mean', 'utterance_pitch_std', 'snr', 'c50', 'speech_duration', 'stoi', 'si-sdr', 'pesq', 'pitch', 'speaking_rate', 'noise', 'reverberation', 'speech_monotony'],\n",
       "    num_rows: 124276\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e92523b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a962dcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '../output-gtts/ms-MY-Wavenet-A_0.mp3',\n",
       "  'array': array([-0.00083028, -0.00129574, -0.00129971, ...,  0.00044667,\n",
       "          0.00043588,  0.0003486 ]),\n",
       "  'sampling_rate': 22050},\n",
       " 'transcription': 'Ketika perang Aceh meletus pada tahun seribu lapan ratus tujuh puluh tiga , Teuku Ibrahim Lamnga aktif berjuang di garisan depan .',\n",
       " 'speaker': 'Bunga',\n",
       " 'speaker_id': 0,\n",
       " 'gender': 'female',\n",
       " 'utterance_pitch_mean': 220.41683959960938,\n",
       " 'utterance_pitch_std': 42.64897537231445,\n",
       " 'snr': 62.63203430175781,\n",
       " 'c50': 59.670066833496094,\n",
       " 'speech_duration': 8.133750000000003,\n",
       " 'stoi': 0.9968859553337097,\n",
       " 'si-sdr': 25.412067413330078,\n",
       " 'pesq': 3.9492032527923584,\n",
       " 'pitch': 'very low pitch',\n",
       " 'speaking_rate': 'quite slowly',\n",
       " 'noise': 'quite clear',\n",
       " 'reverberation': 'very confined sounding',\n",
       " 'speech_monotony': 'quite monotone'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset[0]['train'][0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c33e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▌                                                                                          | 9625/124276 [3:48:53<45:19:54,  1.42s/it]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 63%|████████████████████████████████████████████████████████████▊                                   | 78747/124276 [27:00:20<14:48:26,  1.17s/it]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 124276/124276 [41:42:44<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "prompts = []\n",
    "for i in tqdm(range(len(dataset[0]['train']))):\n",
    "    sample = dataset[0]['train'][i]\n",
    "    sample_prompt = PROMPT\n",
    "    for key in EXPECTED_COLUMNS:\n",
    "        sample_prompt = sample_prompt.replace(f\"[{key}]\", sample[key])\n",
    "    \n",
    "    sample_prompt = sample_prompt.replace(\"[speaker_name]\", sample['speaker'])\n",
    "\n",
    "    sample_prompt = [{\"role\": \"user\", \"content\": sample_prompt}]\n",
    "    \n",
    "    while True:\n",
    "        r = requests.post('http://localhost:7860/v1/chat/completions',\n",
    "                 json = {'messages': sample_prompt, 'model': 'mallam-small', \n",
    "                         'temperature': 0.6, 'max_tokens': 256}).json()\n",
    "\n",
    "        try:\n",
    "            r = json.loads(r['choices'][0]['message']['content'])['result']\n",
    "            if isinstance(r, str):\n",
    "                prompts.append(r)\n",
    "                break\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e0771aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gtts-prompts.json', 'w') as fopen:\n",
    "    json.dump(prompts, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8009e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(prompts)):\n",
    "    if not isinstance(prompts[i], str):\n",
    "        prompts[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "138534b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]['train'] = dataset[0]['train'].add_column('prompt', prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f29caa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '../output-gtts/ms-MY-Wavenet-D_9999.mp3',\n",
       "  'array': array([-0.00089931, -0.00147248, -0.0015128 , ...,  0.00062253,\n",
       "          0.00067943,  0.00061922]),\n",
       "  'sampling_rate': 22050},\n",
       " 'transcription': 'Di Grup A , tiket babak enam belas besar masih diperebutkan oleh Prancis , Norwegia , dan Nigeria .',\n",
       " 'speaker': 'Kamarul',\n",
       " 'speaker_id': 3,\n",
       " 'gender': 'male',\n",
       " 'utterance_pitch_mean': 155.5963592529297,\n",
       " 'utterance_pitch_std': 39.80721664428711,\n",
       " 'snr': 61.4404182434082,\n",
       " 'c50': 59.63848876953125,\n",
       " 'speech_duration': 6.4799999999999995,\n",
       " 'stoi': 0.9979360103607178,\n",
       " 'si-sdr': 22.45107078552246,\n",
       " 'pesq': 3.5210366249084473,\n",
       " 'pitch': 'very high pitch',\n",
       " 'speaking_rate': 'quite slowly',\n",
       " 'noise': 'quite clear',\n",
       " 'reverberation': 'very confined sounding',\n",
       " 'speech_monotony': 'quite monotone',\n",
       " 'prompt': 'Kamarul, a male speaker with a very high-pitched voice delivers a monotonous speech in a very confined-sounding room with minimal background noise. He speaks at a very slow pace, conveying an emotionless and subtle tone.'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['train'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1b8fd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948958337ca641f4a5f58d08268cb3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf17d6430bd649e4a4b2d11c298a9942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f855589ed0b43869e473ef84a1f6015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d70935287d4b52ad4ad51de111119d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28540f14f944ae489a19cad9bfce5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28dca640b7f40bbb52429e83c8f5889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae23fbb46cc845c5be2206d65bb9ad83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62f4a60f62b4d979577d0fc9af4af56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da8964f770844cc8610a29a79255f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48757862312a449aa3fe1fc4e7c261fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283e6135ef1c4678bc7bbf0b8560181b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998239cb0a304abbabb03e5c7c7cbd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565b4ca8cf3842ada5c8aed08cd9cf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ad34d46f4640bcb2605411eea4026c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b643f01e15f34006b16efcdac39d5141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916b89ee75444491bdff0599504b2339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7b82b858c44ba78d2172f4f319e47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d187f053f649519f5926281bee10db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68deb263cce4a0aba2544389c4325f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e26ea17e6e4ac08604b852461eed5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1040e22ef045b28386929c076a0674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4001607aa63a4ba1831d81bcfe26cbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdfd84031a446bab12cc1f4fd6299ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127ed6e0a0e2460ebcc184756c8fd2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66803789cc4432bbe3b7a299c65ffed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3710f4373f64b148616155c45217ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97a04291d0245958e5f4f3b0693a67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec09e4697537413ba9d3eb6864d0be20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e07528dedd44fb1b3d72932f0da34c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee01c89ff4f481c974371b5b4bfaecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5e61fcb24b4f3f89ada73969657670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a4609f76f1406f880e7385bd08d140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24514301d4c3436e853d66b2c853afbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05bbddedaf84257a6d8a1878e42b5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fcfb4302484745804ee40ef6f7c19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/gtts-annotated/commit/eefc6884a70f25cb820fcc8a5cebcdbd96ddbd68', commit_message='Upload dataset', commit_description='', oid='eefc6884a70f25cb820fcc8a5cebcdbd96ddbd68', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['train'].push_to_hub('mesolitica/gtts-annotated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee26a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
