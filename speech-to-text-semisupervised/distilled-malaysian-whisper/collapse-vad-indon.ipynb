{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ce4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from streaming import LocalDataset\n",
    "from streaming import MDSWriter\n",
    "from silero_vad import load_silero_vad\n",
    "from datasets import Audio\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import mp\n",
    "\n",
    "\n",
    "sr = 16000\n",
    "window_size_samples = 512\n",
    "\n",
    "def segment_texts(text):\n",
    "    pattern = r'<\\|(\\d+(?:\\.\\d+)?)\\|>(.*?)(?=<\\||\\Z)'\n",
    "    \n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    result = []\n",
    "    for i, (start_time, content) in enumerate(matches):\n",
    "        content = content\n",
    "        if content:\n",
    "            end_time = matches[i+1][0] if i+1 < len(matches) else start_time\n",
    "            result.append((float(start_time), float(end_time), f\"<|{start_time}|>{content}<|{end_time}|>\"))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "class Pointer:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.index = -1\n",
    "\n",
    "    def _save(self):\n",
    "        with open(self.filename, 'wb') as fopen:\n",
    "            pickle.dump(self.index, fopen)\n",
    "\n",
    "    def increment(self):\n",
    "        self.index += 1\n",
    "        self._save()\n",
    "\n",
    "    def load(self):\n",
    "        if not os.path.exists(self.filename):\n",
    "            return\n",
    "        with open(self.filename, 'rb') as fopen:\n",
    "            self.index = pickle.load(fopen)\n",
    "\n",
    "def loop(ranged):\n",
    "    \n",
    "    audio = Audio(sampling_rate=sr)\n",
    "    model = load_silero_vad(onnx=True)\n",
    "    ranged, index = ranged\n",
    "    filename = f'vad-audio-indon-{index}.jsonl'\n",
    "    fopen_l = open(filename, 'a')\n",
    "    pointer = Pointer(f'{filename}.pickle')\n",
    "    pointer.load()\n",
    "    dataset = LocalDataset('mosaic-indon')\n",
    "    n = 0\n",
    "    for i in tqdm(ranged):\n",
    "        if n >= pointer.index:\n",
    "            entry = dataset[i]\n",
    "                    \n",
    "            audio_filename = entry['audio_filename']\n",
    "            if not os.path.exists(audio_filename):\n",
    "                continue\n",
    "\n",
    "            y = audio.decode_example(audio.encode_example(audio_filename))['array']\n",
    "            label = entry['new_text']\n",
    "            label_en = entry['new_text_en']\n",
    "            label_ms = entry['new_text_ms']\n",
    "            segments = segment_texts(label)\n",
    "\n",
    "            r = 0\n",
    "\n",
    "            for k in range(len(segments)):\n",
    "\n",
    "                segment = segments[k]\n",
    "                segment_text = re.sub(r'<\\|.*?\\|>', '', segment[2])\n",
    "\n",
    "                if k + 1 < len(segments):\n",
    "                    segment_text_2 = re.sub(r'<\\|.*?\\|>', '', segments[k+1][2])\n",
    "                    if segment_text == segment_text_2:\n",
    "                        label = label.replace(segment[2], f\"<|{segment[0]}|><|{segment[1]}|>\")\n",
    "                        if len(label_ms):\n",
    "                            label_ms = label_ms.replace(segment[2], f\"<|{segment[0]}|><|{segment[1]}|>\")\n",
    "\n",
    "                        if len(label_en):\n",
    "                            label_en = label_en.replace(segment[2], f\"<|{segment[0]}|><|{segment[1]}|>\")\n",
    "\n",
    "                        r += 1\n",
    "                        continue\n",
    "\n",
    "\n",
    "                segment_audio = torch.Tensor(y[int(segment[0] * sr): int(segment[1] * sr)])\n",
    "                audio_length_samples = len(segment_audio)\n",
    "\n",
    "                speech_probs = []\n",
    "\n",
    "                for current_start_sample in range(0, audio_length_samples, window_size_samples):\n",
    "                    chunk = segment_audio[current_start_sample: current_start_sample + window_size_samples]\n",
    "                    if len(chunk) < window_size_samples:\n",
    "                        chunk = torch.nn.functional.pad(chunk, (0, int(window_size_samples - len(chunk))))\n",
    "                    speech_prob = model(chunk, sr).item()\n",
    "                    speech_probs.append(speech_prob)\n",
    "\n",
    "                vad_prob = np.mean(speech_probs)\n",
    "\n",
    "                if vad_prob < 0.001:\n",
    "                    label = label.replace(segment[2], f\"<|{segment[0]}|><|{segment[1]}|>\")\n",
    "                    if len(label_ms):\n",
    "                        label_ms = label_ms.replace(segment[2], f\"<|{segment[0]}|><|{segment[1]}|>\")\n",
    "                    if len(label_en):\n",
    "                        label_en = label_en.replace(segment[2], f\"<|{segment[0]}|><|{segment[1]}|>\")\n",
    "\n",
    "            \n",
    "            entry['new_text'] = label  \n",
    "            entry['new_text_en'] = label_en\n",
    "            entry['new_text_ms'] = label_ms  \n",
    "            entry['index'] = n\n",
    "            fopen_l.write(f'{json.dumps(entry)}\\n')\n",
    "            fopen_l.flush()\n",
    "            \n",
    "            pointer.index = n\n",
    "            pointer._save()\n",
    "        \n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9ff3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320934"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = LocalDataset('mosaic-indon')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93364457",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.multiprocessing(range(len(dataset)), loop, cores = 15, returned = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0b3518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vad-audio-indon-15.jsonl',\n",
       " 'vad-audio-indon-1.jsonl',\n",
       " 'vad-audio-indon-7.jsonl',\n",
       " 'vad-audio-indon-8.jsonl',\n",
       " 'vad-audio-indon-6.jsonl',\n",
       " 'vad-audio-indon-5.jsonl',\n",
       " 'vad-audio-indon-13.jsonl',\n",
       " 'vad-audio-indon-12.jsonl',\n",
       " 'vad-audio-indon-4.jsonl',\n",
       " 'vad-audio-indon-3.jsonl',\n",
       " 'vad-audio-indon-2.jsonl',\n",
       " 'vad-audio-indon-10.jsonl',\n",
       " 'vad-audio-indon-9.jsonl',\n",
       " 'vad-audio-indon-11.jsonl',\n",
       " 'vad-audio-indon-0.jsonl',\n",
       " 'vad-audio-indon-14.jsonl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('vad-audio-indon-*.jsonl')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29660978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.44it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('indonesian-stt.jsonl', 'w') as fopen_l:\n",
    "    for f in tqdm(files):\n",
    "        with open(f) as fopen:\n",
    "            for l in fopen:\n",
    "                l = json.loads(l)\n",
    "                \n",
    "                if len(l['new_text_en']):\n",
    "                    d = {\n",
    "                        'audio_filename': l['audio_filename'],\n",
    "                        'text': l['new_text_en']\n",
    "                    }\n",
    "                    fopen_l.write(f'{json.dumps(d)}\\n')\n",
    "                    fopen_l.flush()\n",
    "                    \n",
    "                if len(l['new_text_ms']):\n",
    "                    d = {\n",
    "                        'audio_filename': l['audio_filename'],\n",
    "                        'text': l['new_text_ms']\n",
    "                    }\n",
    "                    fopen_l.write(f'{json.dumps(d)}\\n')\n",
    "                    fopen_l.flush()\n",
    "                    \n",
    "                d = {\n",
    "                    'audio_filename': l['audio_filename'],\n",
    "                    'text': l['new_text']\n",
    "                }\n",
    "                fopen_l.write(f'{json.dumps(d)}\\n')\n",
    "                fopen_l.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85541303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943282 indonesian-stt.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l indonesian-stt.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cddcc2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 husein husein 547M Okt  24 11:31 indonesian-stt.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh indonesian-stt.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df6fe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8685b7fcd3e9431cb821ed3652b7bb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "indonesian-stt.jsonl:   0%|          | 0.00/573M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/malaysian-stt/commit/61dad824d651bcb58937f66a4fa65d328aa5e9ea', commit_message='Upload indonesian-stt.jsonl with huggingface_hub', commit_description='', oid='61dad824d651bcb58937f66a4fa65d328aa5e9ea', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='indonesian-stt.jsonl',\n",
    "    path_in_repo=\"indonesian-stt.jsonl\",\n",
    "    repo_id=\"mesolitica/malaysian-stt\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
