{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff734fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import ClientJupyterKernel, Agent, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f4d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter_kernel_url = 'http://localhost:8081/execute'\n",
    "openai_base_url = 'http://localhost:8005/v1'\n",
    "model_name = 'xingyaoww/CodeActAgent-Mistral-7b-v0.1'\n",
    "\n",
    "generator = Generator(model_name, openai_base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f780e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "\u001b[1m\u001b[31mSYSTEM\u001b[0m\n",
      "\u001b[31mA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\n",
      "The assistant can interact with an interactive Python (Jupyter Notebook) environment and receive the corresponding output when needed. The code should be enclosed using \"<execute>\" tag, for example: <execute> print(\"Hello World!\") </execute>.\n",
      "The assistant should attempt fewer things at a time instead of putting too much code in one <execute> block. The assistant can install packages through PIP by <execute> !pip install [package needed] </execute> and should always import packages and define variables before starting to use them.\n",
      "The assistant should stop <execute> and provide an answer when they have already obtained the answer from the execution result. Whenever possible, execute the code for the user using <execute> instead of providing it.\n",
      "The assistant's response should be concise, but do express their thoughts.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "CONV_ID = 'demo-5'\n",
    "code_executor = ClientJupyterKernel(jupyter_kernel_url, CONV_ID)\n",
    "agent = Agent(generator, code_executor, conv_id=CONV_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943c4573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "\u001b[1m\u001b[32mUSER\u001b[0m\n",
      "\u001b[32mA dataset of individuals' personality types and their corresponding text responses is given. The personality types are determined by the Myers-Briggs Type Indicator (MBTI), a popular psychometric tool used to determine how people prefer to perceive the world and make decisions. The MBTI types consist of 16 different combinations of four dichotomies: Extraversion/Introversion, Sensing/Intuition, Thinking/Feeling, and Judging/Perceiving. The dataset contains a column for the MBTI types and another column for the text responses. Your task is to create a machine learning model that predicts an individual's MBTI type based on their text response. The solution should involve the following steps: 1. Preprocessing the text data, including cleaning, tokenization, stemming, and stopword removal. 2. Transforming the text data into a suitable format for machine learning, such as a term-frequency matrix or a TF-IDF matrix. 3. Training and evaluating a machine learning model that predicts the MBTI type based on the processed text data. 4. Creating a function to classify a new text input based on the trained model. To facilitate evaluation, the dataset has been pre-processed, split into training and testing sets, and pickled. Additionally, the pre-processed text data and the TF-IDF matrix have been pre-computed and pickled as well. **[Dataset]** The dataset is provided in two CSV files: `mbti_1.csv` and `mbti_exp.csv`. The `mbti_1.csv` file contains the raw text data and the corresponding MBTI types. The `mbti_exp.csv` file contains explanations for each MBTI type. The raw text data contains two columns: `type` and `posts`. * `type`: The MBTI type of the individual. * `posts`: The text response of the individual. The explanations for each MBTI type contain four columns: `Type`, `Explain_EI`, `Explain_NS`, `Explain_TF`, and `Explain_JP`. * `Type`: The MBTI type. * `Explain_EI`: The explanation for the Extraversion/Introversion dichotomy. * `Explain_NS`: The explanation for the Sensing/Intuition dichotomy. * `Explain_TF`: The explanation for the Thinking/Feeling dichotomy. * `Explain_JP`: The explanation for the Judging/Perceiving dichotomy.\u001b[0m\n",
      "--------------------\n",
      "\u001b[1m\u001b[34mASSISTANT\u001b[0m\n",
      "\u001b[34mTo predict an individual's MBTI type based on their text response, we'll follow the steps you provided:\n",
      "\n",
      "1. Preprocessing the text data\n",
      "2. Transforming the text data into a suitable format\n",
      "3. Training and evaluating a machine learning model\n",
      "4. Creating a function to classify a new text input\n",
      "\n",
      "First, let's import the necessary packages and load the data.\n",
      "<execute>\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Load the dataset\n",
      "mbti_data = pd.read_csv('mbti_1.csv')\n",
      "mbti_explanations = pd.read_csv('mbti_exp.csv')\n",
      "\n",
      "# Preprocess the text data\n",
      "mbti_data['posts'] = mbti_data['posts'].apply(clean_text)\n",
      "\n",
      "def clean_text(text):\n",
      "    # Clean and tokenize text\n",
      "    text = nltk.clean_html(text)\n",
      "    text = nltk.word_tokenize(text.lower())\n",
      "    \n",
      "    # Remove stopwords and stem words\n",
      "    stopwords = nltk.corpus.stopwords.words('english')\n",
      "    text = [nltk.stem.porter.PorterStemmer().stem(word) for word in text if word not in stopwords]\n",
      "    \n",
      "    # Return the cleaned text\n",
      "    return ' '.join(text)\n",
      "</execute>\u001b[0m\n",
      "New kernel created for conversation demo-5\n",
      "--------------------\n",
      "\u001b[1m\u001b[33mEXECUTION_OUTPUT\u001b[0m\n",
      "\u001b[33m---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      5 from sklearn.metrics import accuracy_score\n",
      "      7 # Load the dataset\n",
      "----> 8 mbti_data = pd.read_csv('mbti_1.csv')\n",
      "      9 mbti_explanations = pd.read_csv('mbti_exp.csv')\n",
      "     11 # Preprocess the text data\n",
      "\n",
      "File /opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n",
      "    935 kwds_defaults = _refine_defaults_read(\n",
      "    936     dialect,\n",
      "    937     delimiter,\n",
      "   (...)\n",
      "    944     dtype_backend=dtype_backend,\n",
      "    945 )\n",
      "    946 kwds.update(kwds_defaults)\n",
      "--> 948 return _read(filepath_or_buffer, kwds)\n",
      "\n",
      "File /opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611, in _read(filepath_or_buffer, kwds)\n",
      "    608 _validate_names(kwds.get(\"names\", None))\n",
      "    610 # Create the parser.\n",
      "--> 611 parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "    613 if chunksize or iterator:\n",
      "    614     return parser\n",
      "\n",
      "File /opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448, in TextFileReader.__init__(self, f, engine, **kwds)\n",
      "   1445     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n",
      "   1447 self.handles: IOHandles | None = None\n",
      "-> 1448 self._engine = self._make_engine(f, self.engine)\n",
      "\n",
      "File /opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705, in TextFileReader._make_engine(self, f, engine)\n",
      "   1703     if \"b\" not in mode:\n",
      "   1704         mode += \"b\"\n",
      "-> 1705 self.handles = get_handle(\n",
      "   1706     f,\n",
      "   1707     mode,\n",
      "   1708     encoding=self.options.get(\"encoding\", None),\n",
      "   1709     compression=self.options.get(\"compression\", None),\n",
      "   1710     memory_map=self.options.get(\"memory_map\", False),\n",
      "   1711     is_text=is_text,\n",
      "   1712     errors=self.options.get(\"encoding_errors\", \"strict\"),\n",
      "   1713     storage_options=self.options.get(\"storage_options\", None),\n",
      "   1714 )\n",
      "   1715 assert self.handles is not None\n",
      "   1716 f = self.handles.handle\n",
      "\n",
      "File /opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n",
      "    858 elif isinstance(handle, str):\n",
      "    859     # Check whether the filename is to be opened in binary mode.\n",
      "    860     # Binary mode does not support 'encoding' and 'newline'.\n",
      "    861     if ioargs.encoding and \"b\" not in ioargs.mode:\n",
      "    862         # Encoding\n",
      "--> 863         handle = open(\n",
      "    864             handle,\n",
      "    865             ioargs.mode,\n",
      "    866             encoding=ioargs.encoding,\n",
      "    867             errors=errors,\n",
      "    868             newline=\"\",\n",
      "    869         )\n",
      "    870     else:\n",
      "    871         # Binary mode\n",
      "    872         handle = open(handle, ioargs.mode)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'mbti_1.csv'\u001b[0m\n",
      "--------------------\n",
      "\u001b[1m\u001b[34mASSISTANT\u001b[0m\n",
      "\u001b[34mIt seems that the 'mbti_1.csv' file is not present in the current working directory. Please ensure that the file is located in the correct directory and try running the code again. If the file is still not found, check if there are any typos in the file name or if it has been saved in a different format (e.g., .xlsx instead of .csv). \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "r = agent.run_prompt(\"A dataset of individuals' personality types and their corresponding text responses is given. The personality types are determined by the Myers-Briggs Type Indicator (MBTI), a popular psychometric tool used to determine how people prefer to perceive the world and make decisions. The MBTI types consist of 16 different combinations of four dichotomies: Extraversion/Introversion, Sensing/Intuition, Thinking/Feeling, and Judging/Perceiving. The dataset contains a column for the MBTI types and another column for the text responses. Your task is to create a machine learning model that predicts an individual's MBTI type based on their text response. The solution should involve the following steps: 1. Preprocessing the text data, including cleaning, tokenization, stemming, and stopword removal. 2. Transforming the text data into a suitable format for machine learning, such as a term-frequency matrix or a TF-IDF matrix. 3. Training and evaluating a machine learning model that predicts the MBTI type based on the processed text data. 4. Creating a function to classify a new text input based on the trained model. To facilitate evaluation, the dataset has been pre-processed, split into training and testing sets, and pickled. Additionally, the pre-processed text data and the TF-IDF matrix have been pre-computed and pickled as well. **[Dataset]** The dataset is provided in two CSV files: `mbti_1.csv` and `mbti_exp.csv`. The `mbti_1.csv` file contains the raw text data and the corresponding MBTI types. The `mbti_exp.csv` file contains explanations for each MBTI type. The raw text data contains two columns: `type` and `posts`. * `type`: The MBTI type of the individual. * `posts`: The text response of the individual. The explanations for each MBTI type contain four columns: `Type`, `Explain_EI`, `Explain_NS`, `Explain_TF`, and `Explain_JP`. * `Type`: The MBTI type. * `Explain_EI`: The explanation for the Extraversion/Introversion dichotomy. * `Explain_NS`: The explanation for the Sensing/Intuition dichotomy. * `Explain_TF`: The explanation for the Thinking/Feeling dichotomy. * `Explain_JP`: The explanation for the Judging/Perceiving dichotomy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df76d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                           COMMAND                  CREATED        STATUS         PORTS                                               NAMES\r\n",
      "62b44dee7c28   nous-search-api_search-api      \"/start-reload.sh\"       3 hours ago    Up 3 hours     80/tcp, 0.0.0.0:9095->9095/tcp, :::9095->9095/tcp   search-api\r\n",
      "75abc2f496f0   mesoliticadev/kubectl-az:main   \"sh -c 'az aks get-c…\"   3 hours ago    Up 3 minutes                                                       nous-search-api-postgres\r\n",
      "3ee2e3e7645f   apache/tika:2.7.0.0             \"/bin/sh -c 'exec ja…\"   3 hours ago    Up 3 hours     9998/tcp                                            nous-search-api-tika\r\n",
      "7a9f9a1857ac   mesoliticadev/kubectl-az:main   \"sh -c 'az aks get-c…\"   3 hours ago    Up 3 minutes   0.0.0.0:9200->9200/tcp, :::9200->9200/tcp           nous-search-api-elasticsearch\r\n",
      "c99ec7f0d22b   nous-frontend                   \"npx tailwindcss -i …\"   3 hours ago    Up 3 hours     80/tcp                                              nous-tailwind\r\n",
      "1bfd2d9c543d   nous-frontend                   \"/start-reload.sh\"       3 hours ago    Up 3 hours     80/tcp, 0.0.0.0:3000->3000/tcp, :::3000->3000/tcp   nous-frontend\r\n",
      "70f01cd87f98   redis:7-alpine                  \"docker-entrypoint.s…\"   4 hours ago    Up 3 hours     6379/tcp                                            redis\r\n",
      "e6b00845d2da   mesoliticadev/kubectl-az:main   \"sh -c 'az aks get-c…\"   4 hours ago    Up 4 minutes   0.0.0.0:5434->5432/tcp, :::5434->5432/tcp           nous-frontend-postgres\r\n",
      "2e1782c9080b   mesoliticadev/kubectl-az:main   \"sh -c 'az aks get-c…\"   4 hours ago    Up 4 minutes   0.0.0.0:9211->9200/tcp, :::9211->9200/tcp           nous-frontend-elasticsearch\r\n",
      "8a6dbed97c3b   vllm/vllm-openai:latest         \"python3 -m vllm.ent…\"   22 hours ago   Up 3 hours     0.0.0.0:8005->8000/tcp, :::8005->8000/tcp           python-act\r\n"
     ]
    }
   ],
   "source": [
    "!docker container ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eeb340e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.code_executor.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a10ac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                           COMMAND                  CREATED        STATUS          PORTS                                               NAMES\r\n",
      "62b44dee7c28   nous-search-api_search-api      \"/start-reload.sh\"       3 hours ago    Up 3 hours      80/tcp, 0.0.0.0:9095->9095/tcp, :::9095->9095/tcp   search-api\r\n",
      "75abc2f496f0   mesoliticadev/kubectl-az:main   \"sh -c 'az aks get-c…\"   3 hours ago    Up 37 seconds                                                       nous-search-api-postgres\r\n",
      "3ee2e3e7645f   apache/tika:2.7.0.0             \"/bin/sh -c 'exec ja…\"   3 hours ago    Up 3 hours      9998/tcp                                            nous-search-api-tika\r\n",
      "7a9f9a1857ac   mesoliticadev/kubectl-az:main   \"sh -c 'az aks get-c…\"   3 hours ago    Up 33 seconds   0.0.0.0:9200->9200/tcp, :::9200->9200/tcp           nous-search-api-elasticsearch\r\n",
      "c99ec7f0d22b   nous-frontend                   \"npx tailwindcss -i …\"   4 hours ago    Up 4 hours      80/tcp                                              nous-tailwind\r\n",
      "1bfd2d9c543d   nous-frontend                   \"/start-reload.sh\"       4 hours ago    Up 4 hours      80/tcp, 0.0.0.0:3000->3000/tcp, :::3000->3000/tcp   nous-frontend\r\n",
      "70f01cd87f98   redis:7-alpine                  \"docker-entrypoint.s…\"   4 hours ago    Up 4 hours      6379/tcp                                            redis\r\n",
      "e6b00845d2da   mesoliticadev/kubectl-az:main   \"sh -c 'az aks get-c…\"   4 hours ago    Up 2 minutes    0.0.0.0:5434->5432/tcp, :::5434->5432/tcp           nous-frontend-postgres\r\n",
      "2e1782c9080b   mesoliticadev/kubectl-az:main   \"sh -c 'az aks get-c…\"   4 hours ago    Up 2 minutes    0.0.0.0:9211->9200/tcp, :::9211->9200/tcp           nous-frontend-elasticsearch\r\n",
      "8a6dbed97c3b   vllm/vllm-openai:latest         \"python3 -m vllm.ent…\"   22 hours ago   Up 3 hours      0.0.0.0:8005->8000/tcp, :::8005->8000/tcp           python-act\r\n"
     ]
    }
   ],
   "source": [
    "!docker container ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('code-feedback/9.json') as fopen:\n",
    "    for r in json.load(fopen)['result']:\n",
    "        print(r['role'], r['content'], '<execute>' in r['content'])\n",
    "        print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker container ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b3068e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"generated sequences ['<s> Hello. Ini siapa ya? Apa khabar? Nama saya Kamarul. Saya sedang menggunakan peralatan yang disenaraik an dalam pertanyaan untuk menjalankan beberapa tugas dan saya ingin terus bekerja dengan baik sehingga saya menggunakan peranti an saya dengan tepat. [/INST] Selamat sejahtera! Saya gembira dapat membantu anda. Saya sentiasa dengan ini untuk membantu anda dengan sebarang soalan yang anda ada. Jangan teragak-agak untuk bertanya! </s>'] in 1.2768537998199463 seconds\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "from transformers_neuronx.module import save_pretrained_split\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    'mesolitica/malaysian-tinyllama-1.1b-16k-instructions-v4'\n",
    ")\n",
    "save_pretrained_split(model, './Llama')\n",
    "neuron_model = LlamaForSampling.from_pretrained(\n",
    "    './Llama', \n",
    "    batch_size=1, \n",
    "    tp_degree=2, \n",
    "    amp='f16'\n",
    ")\n",
    "neuron_model.to_neuron()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'mesolitica/malaysian-tinyllama-1.1b-16k-instructions-v4'\n",
    ")\n",
    "prompt = \"Hello, Ini siapa ya? Apa khabar? Nama saya Kamarul. Saya sedang menggunakan peralatan yang disenaraikan dalam pertanyaan untuk menjalankan beberapa tugas dan saya ingin terus bekerja dengan baik sehingga saya menggunakan perantian saya dengan tempat\"\n",
    "prompt = tokenizer.apply_chat_template([{'role': 'user', 'content': prompt}], tokenize = False)\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "generated_sequences = neuron_model.sample(input_ids, sequence_length=2048, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d293b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
