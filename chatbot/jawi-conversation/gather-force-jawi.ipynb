{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933a104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = [\n",
    "    'always better to find peaceful',\n",
    "    'non-violent ways to express',\n",
    "    'can lead to severe consequences',\n",
    "    'still have questions or concerns about',\n",
    "    'that doing so is illegal',\n",
    "    'to report the incident to',\n",
    "    'would recommend consulting with',\n",
    "    'indonesian',\n",
    "    'translates to',\n",
    "    'idiom in',\n",
    "    'in English',\n",
    "    'in Malay',\n",
    "    # 'language model'\n",
    "]\n",
    "\n",
    "break_at = [\n",
    "    'help.openai.com',\n",
    "    'openai',\n",
    "    'cannot have personal opinions',\n",
    "    's an ai language model',\n",
    "    \"i'm sorry\",\n",
    "    'many factors',\n",
    "    'lgbt',\n",
    "    'lesbian',\n",
    "    'gender-neutral',\n",
    "    'remain neutral',\n",
    "    'without bias',\n",
    "    'and neutral',\n",
    "    'more inclusive',\n",
    "    'neutrality',\n",
    "    'non-bias',\n",
    "    'discrimination',\n",
    "    'avoid any forms of discrimination',\n",
    "    'regardless of their gender',\n",
    "    'inclusive and tolerant environment',\n",
    "    'have personal views',\n",
    "    'sexual orientation should be a top priority',\n",
    "    's an objective ai',\n",
    "    'avoid any forms of prejudice or hate',\n",
    "    'regardless of their personal',\n",
    "    'you understand this direction',\n",
    "    'tolerant environment within ai',\n",
    "    'cannot express my',\n",
    "    'requires more context',\n",
    "    'personal opinion',\n",
    "    'have updated information',\n",
    "    \"don't have personal experiences\",\n",
    "    'there is no information',\n",
    "    'tidak mempunyai akses kepada data atau maklumat',\n",
    "    '10 april 2021',\n",
    "    'ebagai model bahasa AI',\n",
    "    'ebagai model bahasa ai',\n",
    "    'model bahasa AI',\n",
    "    'model bahasa ai',\n",
    "    'bahasa ai',\n",
    "    'ebagai model bahasa'\n",
    "    'hat makes sense',\n",
    "    'have access to data or information',\n",
    "    'have access to the data or information',\n",
    "    'hanya mempunyai akses kepada maklumat umum',\n",
    "    'hanya boleh memberikan maklumat umum',\n",
    "    'have personal preferences',\n",
    "    'not have personal experiences',\n",
    "    'not capable of having subjective opinions',\n",
    "    'indonesian',\n",
    "    'mistral',\n",
    "    'terjemah',\n",
    "    'translate'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a03694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "roles = {\n",
    "    'user': '<manusia>',\n",
    "    'assistant': '<bot>'\n",
    "}\n",
    "\n",
    "files = glob('/home/husein/ssd3/soalan-augmentation/*conversation*.jsonl')\n",
    "files.extend(glob('/home/husein/ssd3/soalan-augmentation/*multiturn*.jsonl'))\n",
    "files = [f for f in files if 'rag' not in f]\n",
    "alls = []\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            inputs = []\n",
    "            try:\n",
    "                for no, r in enumerate(l):\n",
    "                    if no < (len(l) - 1):\n",
    "                        if l[no + 1]['role'] == 'user':\n",
    "                            next_text = l[no + 1].get('content_ms') or ''\n",
    "                        else:\n",
    "                            next_text = l[no + 1].get('content_ms') or ''\n",
    "                    else:\n",
    "                        next_text = ''\n",
    "\n",
    "                    if r['role'] == 'user':\n",
    "                        q = r.get('content_ms', '') or ''\n",
    "                        current_text = q       \n",
    "                    else:\n",
    "                        current_text = r.get('content_ms') or ''\n",
    "\n",
    "                    if l[no - 1]['role'] == 'user':\n",
    "                        previous_text = l[no - 1].get('content_ms')\n",
    "                    else:\n",
    "                        previous_text = l[no - 1].get('content_ms') or ''\n",
    "\n",
    "                    # bad pairs\n",
    "                    if r['role'] == 'user' and (len(current_text) < 2 or len(next_text) < 2):\n",
    "                        # print('a', l, current_text, next_text, '\\n')\n",
    "                        continue\n",
    "                    if r['role'] == 'assistant' and (len(current_text) < 2 or len(previous_text) < 2):\n",
    "                        continue\n",
    "\n",
    "                    # bad pairs\n",
    "                    if r['role'] == 'user' and current_text[:20].lower() == next_text[:20].lower():\n",
    "                        # print(no, r, current_text[:20].lower(), next_text[:20].lower())\n",
    "                        continue\n",
    "                    if r['role'] == 'assistant' and current_text[:20].lower() == previous_text[:20].lower():\n",
    "                        # print(no, r, current_text[:20].lower(), previous_text[:20].lower())\n",
    "                        continue\n",
    "\n",
    "                    # remove alignments    \n",
    "                    if r['role'] == 'user' and (any([b in current_text.lower() for b in break_at]) or any([b in next_text.lower() for b in break_at])):\n",
    "                        # print(current_text, next_text)\n",
    "                        break\n",
    "                    if r['role'] == 'assistant' and (any([b in current_text.lower() for b in break_at]) or any([b in previous_text.lower() for b in break_at])):\n",
    "                        # print(current_text, next_text)\n",
    "                        break\n",
    "\n",
    "                    role = roles[r['role']]\n",
    "\n",
    "                    s = current_text\n",
    "\n",
    "                    inputs.append((s, r))\n",
    "\n",
    "                if len(inputs) % 2 != 0:\n",
    "                    inputs = inputs[:-1]\n",
    "\n",
    "                if not len(inputs):\n",
    "                    continue\n",
    "\n",
    "                if len(inputs) < 2:\n",
    "                    continue\n",
    "\n",
    "                outputs = []\n",
    "                for i in range(0, len(inputs), 2):\n",
    "\n",
    "                    try:\n",
    "                        content = inputs[i][1]['content']\n",
    "                        content_ms = inputs[i][1]['content_ms']\n",
    "\n",
    "                        if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                            continue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        content = inputs[i + 1][1]['content']\n",
    "                        content_ms = inputs[i + 1][1]['content_ms']\n",
    "\n",
    "                        if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                            continue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    outputs.extend([\n",
    "                        inputs[i][0],\n",
    "                        inputs[i + 1][0]\n",
    "                    ])\n",
    "\n",
    "                if not len(outputs):\n",
    "                    continue\n",
    "\n",
    "                alls.append(outputs)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rags = [\n",
    "    '/home/husein/ssd3/soalan-augmentation/rag-multiturn-chaotic-part2.jsonl',\n",
    "]\n",
    "\n",
    "for f in rags:\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            context = l['context']\n",
    "            l = l['chat']\n",
    "            inputs = []\n",
    "            try:\n",
    "                for no, r in enumerate(l):\n",
    "                    if no < (len(l) - 1):\n",
    "                        if l[no + 1]['role'] == 'user':\n",
    "                            next_text = l[no + 1].get('content_ms') or ''\n",
    "                        else:\n",
    "                            next_text = l[no + 1].get('content_ms') or ''\n",
    "                    else:\n",
    "                        next_text = ''\n",
    "\n",
    "                    if r['role'] == 'user':\n",
    "                        q = r.get('content_ms', '') or ''\n",
    "                        current_text = q\n",
    "                    else:\n",
    "                        current_text = r.get('content_ms') or ''\n",
    "\n",
    "                    if l[no - 1]['role'] == 'user':\n",
    "                        previous_text = l[no - 1].get('content_ms') or ''\n",
    "                    else:\n",
    "                        previous_text = l[no - 1].get('content_ms') or ''\n",
    "\n",
    "                    # bad pairs\n",
    "                    if r['role'] == 'user' and (len(current_text) < 2 or len(next_text) < 2):\n",
    "                        # print('a', l, current_text, next_text, '\\n')\n",
    "                        continue\n",
    "                    if r['role'] == 'assistant' and (len(current_text) < 2 or len(previous_text) < 2):\n",
    "                        continue\n",
    "\n",
    "                    # bad pairs\n",
    "                    if r['role'] == 'user' and current_text[:20].lower() == next_text[:20].lower():\n",
    "                        # print(no, r, current_text[:20].lower(), next_text[:20].lower())\n",
    "                        continue\n",
    "                    if r['role'] == 'assistant' and current_text[:20].lower() == previous_text[:20].lower():\n",
    "                        # print(no, r, current_text[:20].lower(), previous_text[:20].lower())\n",
    "                        continue\n",
    "\n",
    "                    # remove alignments    \n",
    "                    if r['role'] == 'user' and (any([b in current_text.lower() for b in break_at]) or any([b in next_text.lower() for b in break_at])):\n",
    "                        # print(current_text, next_text)\n",
    "                        break\n",
    "                    if r['role'] == 'assistant' and (any([b in current_text.lower() for b in break_at]) or any([b in previous_text.lower() for b in break_at])):\n",
    "                        # print(current_text, next_text)\n",
    "                        break\n",
    "\n",
    "                    role = roles[r['role']]\n",
    "\n",
    "                    if no == 0:\n",
    "                        current_text = f\"{context}\\n{current_text}\"\n",
    "\n",
    "                    s = current_text\n",
    "\n",
    "                    inputs.append((s, r))\n",
    "\n",
    "                if len(inputs) % 2 != 0:\n",
    "                    inputs = inputs[:-1]\n",
    "\n",
    "                if not len(inputs):\n",
    "                    continue\n",
    "\n",
    "                if len(inputs) < 3:\n",
    "                    continue\n",
    "\n",
    "                outputs = []\n",
    "                for i in range(0, len(inputs), 2):\n",
    "\n",
    "                    try:\n",
    "                        content = inputs[i][1]['content']\n",
    "                        content_ms = inputs[i][1]['content_ms']\n",
    "\n",
    "                        if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                            continue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        content = inputs[i + 1][1]['content']\n",
    "                        content_ms = inputs[i + 1][1]['content_ms']\n",
    "\n",
    "                        if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                            continue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    outputs.extend([\n",
    "                        inputs[i][0],\n",
    "                        inputs[i + 1][0]\n",
    "                    ])\n",
    "\n",
    "                if not len(outputs):\n",
    "                    continue\n",
    "\n",
    "                data = '\\n'.join(outputs).strip()\n",
    "                if not len(data):\n",
    "                    continue\n",
    "\n",
    "                if context not in data:\n",
    "                    continue\n",
    "\n",
    "                outputs[0] = outputs[0].split(context)[1]\n",
    "\n",
    "\n",
    "                alls.append(outputs)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e4b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = []\n",
    "for i in range(len(alls)):\n",
    "    all_texts.extend(alls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b2df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('translate-jawi.txt', 'w') as fopen:\n",
    "    for t in tqdm(set(all_texts)):\n",
    "        if not len(t):\n",
    "            continue\n",
    "        \n",
    "        fopen.write(f'{json.dumps(t)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l translate-jawi.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b456796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "\n",
    "url = \"https://www.ejawi.net/result.php\"\n",
    "\n",
    "headers = CaseInsensitiveDict()\n",
    "headers[\"authority\"] = \"www.ejawi.net\"\n",
    "headers[\"accept\"] = \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\"\n",
    "headers[\"accept-language\"] = \"en-MY,en;q=0.9,en-US;q=0.8,ms;q=0.7\"\n",
    "headers[\"cache-control\"] = \"no-cache\"\n",
    "headers[\"content-type\"] = \"application/x-www-form-urlencoded\"\n",
    "headers[\"cookie\"] = \"__utma=248434904.1854521706.1653239537.1653239537.1653239537.1; __utmc=248434904; __utmz=248434904.1653239537.1.1.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); __utmt=1; __utmb=248434904.1.10.1653239537\"\n",
    "headers[\"origin\"] = \"https://www.ejawi.net\"\n",
    "headers[\"pragma\"] = \"no-cache\"\n",
    "headers[\"referer\"] = \"https://www.ejawi.net/converterV2.php?go=rumi\"\n",
    "headers[\"sec-ch-ua\"] = '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"100\", \"Google Chrome\";v=\"100\"'\n",
    "headers[\"sec-ch-ua-mobile\"] = \"?0\"\n",
    "headers[\"sec-ch-ua-platform\"] = '\"macOS\"'\n",
    "headers[\"sec-fetch-dest\"] = \"iframe\"\n",
    "headers[\"sec-fetch-mode\"] = \"navigate\"\n",
    "headers[\"sec-fetch-site\"] = \"same-origin\"\n",
    "headers[\"sec-fetch-user\"] = \"?1\"\n",
    "headers[\"upgrade-insecure-requests\"] = \"1\"\n",
    "headers[\"user-agent\"] = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213d832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jawi(string):\n",
    "    data = f\"phonText={string}&disable_direction=on&number=1\"\n",
    "    resp = requests.post(url, headers=headers, data=data)\n",
    "    decoded = resp._content.decode()\n",
    "    soup = BeautifulSoup(decoded, 'html.parser')\n",
    "    return soup.find_all('td')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999e2478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2897651"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "all_texts = []\n",
    "with open('translate-jawi.txt') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        all_texts.append(l)\n",
    "        \n",
    "len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa98519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generate-translate-jawi’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "#!rm -rf generate-translate-jawi\n",
    "!mkdir generate-translate-jawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64eac056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def answer(q, i):\n",
    "    if '```' in q:\n",
    "        return\n",
    "    filename = f'generate-translate-jawi/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            r = get_jawi(q)\n",
    "            with open(filename, 'w') as fopen:\n",
    "                json.dump(r, fopen)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # print(e, q)\n",
    "            time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c43993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(queue, name):\n",
    "    while True:\n",
    "        if queue.qsize() == 0:\n",
    "            break\n",
    "        item = queue.get()\n",
    "        answer(*item)\n",
    "    print(f'consumer {name} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13af3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [(q, no) for no, q in enumerate(all_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d205d1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mengapa kerajaan Malaysia menapis internet dan menyekat kebebasan bersuara walaupun mendakwa sebagai negara demokrasi?',\n",
       " 2897650)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "028899e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(*urls[-10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2e626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from tqdm import tqdm\n",
    "\n",
    "queue = Queue()\n",
    "for u in urls:\n",
    "    queue.put(u)\n",
    "    \n",
    "ori_size = queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f220843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████▉| 2897642/2897651 [6:01:01<00:00, 133.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consumer 37 done\n",
      "consumer 19 done\n",
      "consumer 41 done\n",
      "consumer 48 done\n",
      "consumer 15 done\n",
      "consumer 6 done\n",
      "consumer 45 done\n",
      "consumer 38 done\n",
      "consumer 21 done\n",
      "consumer 14 done\n",
      "consumer 2 done\n",
      "consumer 9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consumer 5 done\n"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "consumers = [Thread(target=consumer, args=(queue,i)) for i in range(max_worker)]\n",
    "for i in range(len(consumers)):\n",
    "    consumers[i].start()\n",
    "    \n",
    "pbar = tqdm(total=ori_size)\n",
    "last_size = 0\n",
    "while True:\n",
    "    size = queue.qsize()\n",
    "    if size == 0:\n",
    "        break\n",
    "    left = ori_size - size\n",
    "    minus = left - last_size\n",
    "    if minus > 0:\n",
    "        pbar.update(minus)\n",
    "        last_size += minus\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bde548c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 2897651/2897651 [03:28<00:00, 13888.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "mapping = {}\n",
    "for i in tqdm(range(len(all_texts))):\n",
    "    filename = f'generate-translate-jawi/{i}.json'\n",
    "    if not os.path.exists(filename):\n",
    "        continue\n",
    "    \n",
    "    with open(filename) as fopen:\n",
    "        t = json.load(fopen)\n",
    "        \n",
    "    mapping[all_texts[i]] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6704a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48163it [00:08, 5421.09it/s]\n",
      "60384it [00:13, 4493.38it/s]\n",
      "57798it [00:11, 5094.76it/s]\n",
      "135770it [01:45, 1284.01it/s]\n",
      "103242it [01:01, 1679.54it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "roles = {\n",
    "    'user': '<manusia>',\n",
    "    'assistant': '<bot>'\n",
    "}\n",
    "\n",
    "files = glob('/home/husein/ssd3/soalan-augmentation/*conversation*.jsonl')\n",
    "files.extend(glob('/home/husein/ssd3/soalan-augmentation/*multiturn*.jsonl'))\n",
    "files = [f for f in files if 'rag' not in f]\n",
    "alls = []\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            inputs = []\n",
    "            try:\n",
    "                for no, r in enumerate(l):\n",
    "                    if no < (len(l) - 1):\n",
    "                        if l[no + 1]['role'] == 'user':\n",
    "                            next_text = l[no + 1].get('content_ms') or ''\n",
    "                        else:\n",
    "                            next_text = l[no + 1].get('content_ms') or ''\n",
    "                    else:\n",
    "                        next_text = ''\n",
    "\n",
    "                    if r['role'] == 'user':\n",
    "                        q = r.get('content_ms', '') or ''\n",
    "                        current_text = q       \n",
    "                    else:\n",
    "                        current_text = r.get('content_ms') or ''\n",
    "\n",
    "                    if l[no - 1]['role'] == 'user':\n",
    "                        previous_text = l[no - 1].get('content_ms')\n",
    "                    else:\n",
    "                        previous_text = l[no - 1].get('content_ms') or ''\n",
    "\n",
    "                    # bad pairs\n",
    "                    if r['role'] == 'user' and (len(current_text) < 2 or len(next_text) < 2):\n",
    "                        # print('a', l, current_text, next_text, '\\n')\n",
    "                        continue\n",
    "                    if r['role'] == 'assistant' and (len(current_text) < 2 or len(previous_text) < 2):\n",
    "                        continue\n",
    "\n",
    "                    # bad pairs\n",
    "                    if r['role'] == 'user' and current_text[:20].lower() == next_text[:20].lower():\n",
    "                        # print(no, r, current_text[:20].lower(), next_text[:20].lower())\n",
    "                        continue\n",
    "                    if r['role'] == 'assistant' and current_text[:20].lower() == previous_text[:20].lower():\n",
    "                        # print(no, r, current_text[:20].lower(), previous_text[:20].lower())\n",
    "                        continue\n",
    "\n",
    "                    # remove alignments    \n",
    "                    if r['role'] == 'user' and (any([b in current_text.lower() for b in break_at]) or any([b in next_text.lower() for b in break_at])):\n",
    "                        # print(current_text, next_text)\n",
    "                        break\n",
    "                    if r['role'] == 'assistant' and (any([b in current_text.lower() for b in break_at]) or any([b in previous_text.lower() for b in break_at])):\n",
    "                        # print(current_text, next_text)\n",
    "                        break\n",
    "\n",
    "                    role = roles[r['role']]\n",
    "\n",
    "                    s = current_text\n",
    "\n",
    "                    inputs.append((s, r))\n",
    "\n",
    "                if len(inputs) % 2 != 0:\n",
    "                    inputs = inputs[:-1]\n",
    "\n",
    "                if not len(inputs):\n",
    "                    continue\n",
    "\n",
    "                if len(inputs) < 2:\n",
    "                    continue\n",
    "\n",
    "                outputs = []\n",
    "                for i in range(0, len(inputs), 2):\n",
    "\n",
    "                    try:\n",
    "                        content = inputs[i][1]['content']\n",
    "                        content_ms = inputs[i][1]['content_ms']\n",
    "\n",
    "                        if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                            continue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        content = inputs[i + 1][1]['content']\n",
    "                        content_ms = inputs[i + 1][1]['content_ms']\n",
    "\n",
    "                        if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                            continue\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    l = mapping.get(inputs[i][0])\n",
    "                    r = mapping.get(inputs[i + 1][0])\n",
    "                    \n",
    "                    if l is None or r is None:\n",
    "                        break\n",
    "\n",
    "                    outputs.extend([\n",
    "                        {'role': 'user', 'content_ms': inputs[i][0], 'content_jawi': l},\n",
    "                        {'role': 'assistant', 'content_ms': inputs[i + 1][0], 'content_jawi': r}\n",
    "                    ])\n",
    "\n",
    "                if not len(outputs):\n",
    "                    continue\n",
    "\n",
    "                alls.append(outputs)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c283d42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169403it [01:11, 2371.78it/s]\n"
     ]
    }
   ],
   "source": [
    "rags = [\n",
    "    '/home/husein/ssd3/soalan-augmentation/rag-multiturn-chaotic-part2.jsonl',\n",
    "]\n",
    "\n",
    "for f in rags:\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            context = l['context']\n",
    "            l = l['chat']\n",
    "            inputs = []\n",
    "            try:\n",
    "                for no, r in enumerate(l):\n",
    "                    if no < (len(l) - 1):\n",
    "                        if l[no + 1]['role'] == 'user':\n",
    "                            next_text = l[no + 1].get('content_ms') or ''\n",
    "                        else:\n",
    "                            next_text = l[no + 1].get('content_ms') or ''\n",
    "                    else:\n",
    "                        next_text = ''\n",
    "\n",
    "                    if r['role'] == 'user':\n",
    "                        q = r.get('content_ms', '') or ''\n",
    "                        current_text = q\n",
    "                    else:\n",
    "                        current_text = r.get('content_ms') or ''\n",
    "\n",
    "                    if l[no - 1]['role'] == 'user':\n",
    "                        previous_text = l[no - 1].get('content_ms') or ''\n",
    "                    else:\n",
    "                        previous_text = l[no - 1].get('content_ms') or ''\n",
    "\n",
    "                    # bad pairs\n",
    "                    if r['role'] == 'user' and (len(current_text) < 2 or len(next_text) < 2):\n",
    "                        # print('a', l, current_text, next_text, '\\n')\n",
    "                        continue\n",
    "                    if r['role'] == 'assistant' and (len(current_text) < 2 or len(previous_text) < 2):\n",
    "                        continue\n",
    "\n",
    "                    # bad pairs\n",
    "                    if r['role'] == 'user' and current_text[:20].lower() == next_text[:20].lower():\n",
    "                        # print(no, r, current_text[:20].lower(), next_text[:20].lower())\n",
    "                        continue\n",
    "                    if r['role'] == 'assistant' and current_text[:20].lower() == previous_text[:20].lower():\n",
    "                        # print(no, r, current_text[:20].lower(), previous_text[:20].lower())\n",
    "                        continue\n",
    "\n",
    "                    # remove alignments    \n",
    "                    if r['role'] == 'user' and (any([b in current_text.lower() for b in break_at]) or any([b in next_text.lower() for b in break_at])):\n",
    "                        # print(current_text, next_text)\n",
    "                        break\n",
    "                    if r['role'] == 'assistant' and (any([b in current_text.lower() for b in break_at]) or any([b in previous_text.lower() for b in break_at])):\n",
    "                        # print(current_text, next_text)\n",
    "                        break\n",
    "\n",
    "                    role = roles[r['role']]\n",
    "\n",
    "                    if no == 0:\n",
    "                        current_text = f\"{context}\\n{current_text}\"\n",
    "\n",
    "                    s = current_text\n",
    "\n",
    "                    inputs.append((s, r))\n",
    "\n",
    "                if len(inputs) % 2 != 0:\n",
    "                    inputs = inputs[:-1]\n",
    "\n",
    "                if not len(inputs):\n",
    "                    continue\n",
    "\n",
    "                if len(inputs) < 3:\n",
    "                    continue\n",
    "\n",
    "                outputs = []\n",
    "                for i in range(0, len(inputs), 2):\n",
    "\n",
    "                    try:\n",
    "                        content = inputs[i][1]['content']\n",
    "                        content_ms = inputs[i][1]['content_ms']\n",
    "\n",
    "                        if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                            continue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        content = inputs[i + 1][1]['content']\n",
    "                        content_ms = inputs[i + 1][1]['content_ms']\n",
    "\n",
    "                        if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                            continue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    outputs.extend([\n",
    "                        inputs[i][0],\n",
    "                        inputs[i + 1][0]\n",
    "                    ])\n",
    "\n",
    "                if not len(outputs):\n",
    "                    continue\n",
    "\n",
    "                data = '\\n'.join(outputs).strip()\n",
    "                if not len(data):\n",
    "                    continue\n",
    "\n",
    "                if context not in data:\n",
    "                    continue\n",
    "\n",
    "                outputs[0] = outputs[0].split(context)[1]\n",
    "                \n",
    "                new_outputs = [{'role': 'context', 'content': context}]\n",
    "                for i in range(len(outputs)):\n",
    "                    \n",
    "                    if outputs[i] not in mapping:\n",
    "                        break\n",
    "                        \n",
    "                    if i % 2 == 0:\n",
    "                        role = 'user'\n",
    "                    else:\n",
    "                        role = 'assistant'\n",
    "                    \n",
    "                    new_outputs.append({\n",
    "                        'role': role, 'content_ms': outputs[i], 'content_jawi': mapping[outputs[i]] \n",
    "                    })\n",
    "                \n",
    "                if len(new_outputs) % 2 == 0:\n",
    "                    new_outputs = new_outputs[:-1]\n",
    "\n",
    "                alls.append(new_outputs)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d24ca3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553571"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f0a4781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 553571/553571 [00:24<00:00, 22535.35it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('synthetic-jawi-conversation.jsonl', 'w') as fopen:\n",
    "    for l in tqdm(alls):\n",
    "        l = json.dumps(l)\n",
    "        if '+' in l:\n",
    "            continue\n",
    "        fopen.write(f'{l}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2916161d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 husein husein 13G Jun  12 10:42 synthetic-jawi-conversation.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh synthetic-jawi-conversation.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fe62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bd6ef811c44aaaaa9aad5ba47b643c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "synthetic-jawi-conversation.jsonl:   0%|          | 0.00/13.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='synthetic-jawi-conversation.jsonl',\n",
    "    path_in_repo='synthetic-jawi-conversation.jsonl',\n",
    "    repo_id='mesolitica/synthetic-jawi-conversation',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a875b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
