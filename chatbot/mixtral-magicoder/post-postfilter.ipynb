{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f74e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f87c0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(r\"'(.+?)' atau '(.+?)'\", re.IGNORECASE)\n",
    "\n",
    "rejected = [\n",
    "    'help.openai.com',\n",
    "    'openassistant'\n",
    "]\n",
    "\n",
    "break_at = [\n",
    "    'help.openai.com',\n",
    "    'openai',\n",
    "    'cannot have personal opinions',\n",
    "    's an ai language model',\n",
    "    \"i'm sorry\",\n",
    "    'many factors',\n",
    "    'lgbt',\n",
    "    'lesbian',\n",
    "    'gender-neutral',\n",
    "    'remain neutral',\n",
    "    'without bias',\n",
    "    'and neutral',\n",
    "    'more inclusive',\n",
    "    'neutrality',\n",
    "    'non-bias',\n",
    "    'discrimination',\n",
    "    'avoid any forms of discrimination',\n",
    "    'regardless of their gender',\n",
    "    'inclusive and tolerant environment',\n",
    "    'have personal views',\n",
    "    'sexual orientation should be a top priority',\n",
    "    's an objective ai',\n",
    "    'avoid any forms of prejudice or hate',\n",
    "    'regardless of their personal',\n",
    "    'you understand this direction',\n",
    "    'tolerant environment within ai',\n",
    "    'cannot express my',\n",
    "    'requires more context',\n",
    "    'personal opinion',\n",
    "    'have updated information',\n",
    "    \"don't have personal experiences\",\n",
    "    'there is no information',\n",
    "    'tidak mempunyai akses kepada data atau maklumat',\n",
    "    '10 april 2021',\n",
    "    'ebagai model bahasa AI',\n",
    "    'model bahasa AI',\n",
    "    'mempunyai kepercayaan atau pendapat peribadi',\n",
    "    'tidak mempunyai pendapat peribadi',\n",
    "    'tidak mempunyai kepercayaan',\n",
    "    'tidak mempunyai falsafah peribadi',\n",
    "    'tidak mempunyai pengalaman peribadi',\n",
    "    'tidak mempunyai pendapat atau pengalaman peribadi',\n",
    "    'tidak mempunyai maklumat terkini',\n",
    "    'tidak mempunyai emosi peribadi',\n",
    "    'tidak mempunyai keutamaan',\n",
    "    'saya tidak mempunyai akses',\n",
    "    'tidak mempunyai pengalaman',\n",
    "    'saya tidak mempunyai keupayaan',\n",
    "    'tidak mempunyai keupayaan',\n",
    "    'tidak mempunyai hubungan',\n",
    "    'tidak mempunyai maklumat',\n",
    "    'saya tidak mempunyai',\n",
    "    'saya tidak pernah',\n",
    "    'saya tidak dapat memahami jawapan',\n",
    "    '=====',\n",
    "    '-----',\n",
    "    'tidak faham bahasa melayu',\n",
    "    'tidak faham bahasa inggeris',\n",
    "    'not understand malay',\n",
    "    'not understand english',\n",
    "    't understand malay',\n",
    "    't understand english',\n",
    "]\n",
    "\n",
    "break_at_terjemah = [\n",
    "    'terjemah',\n",
    "    'translate'\n",
    "]\n",
    "\n",
    "rejected_words = [\n",
    "    'kebutuhan',\n",
    "    'berbeda',\n",
    "    'bahwa',\n",
    "    'Kode',\n",
    "    'kode',\n",
    "    'nomor',\n",
    "    'RMXX,XXX',\n",
    "    'kompleksitas',\n",
    "    'listrik',\n",
    "    'teknis',\n",
    "    'berkualitas',\n",
    "    'mencoba',\n",
    "    'kampanye',\n",
    "    'komunitas',\n",
    "    'stabilitas',\n",
    "    'Stabilitas',\n",
    "    'metode',\n",
    "    'pria',\n",
    "    'butuh',\n",
    "    'jadwal',\n",
    "    'kasus',\n",
    "    'otomatis',\n",
    "    'populer',\n",
    "    'bisnis',\n",
    "    'probabilitas',\n",
    "    'rusak',\n",
    "    'kapasitas',\n",
    "    'rutinitas',\n",
    "    'pertama-tama',\n",
    "    ' akkan',\n",
    "    'им',\n",
    "    'м'\n",
    "]\n",
    "\n",
    "cyrillic_characters = [\n",
    "    # Basic Cyrillic Alphabet\n",
    "    'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ё', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я',\n",
    "    'а', 'б', 'в', 'г', 'д', 'е', 'ё', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я',\n",
    "\n",
    "    # Extended Cyrillic Characters\n",
    "    'Ѐ', 'Ђ', 'Ѓ', 'Є', 'Ѕ', 'І', 'Ї', 'Ј', 'Љ', 'Њ', 'Ћ', 'Ќ', 'Ѝ', 'Ў', 'Џ', 'Ѡ', 'Ѣ', 'Ѥ', 'Ѧ', 'Ѩ', 'Ѫ', 'Ѭ', 'Ѯ', 'Ѱ', 'Ѳ', 'Ѵ', 'Ҁ', 'Ҋ', 'Ҍ', 'Ҏ', 'Ґ', 'Ғ', 'Ҕ', 'Җ', 'Ҙ', 'Қ', 'Ҝ', 'Ҟ', 'Ҡ', 'Ң', 'Ҥ', 'Ҧ', 'Ҩ', 'Ҫ', 'Ҭ', 'Ү', 'Ұ', 'Ҳ', 'Ҵ', 'Ҷ', 'Ҹ', 'Һ', 'Ҽ', 'Ҿ', 'Ӏ', 'Ӂ', 'Ӄ', 'Ӆ', 'Ӈ', 'Ӊ', 'Ӌ', 'Ӎ', 'Ӑ', 'Ӓ', 'Ӕ', 'Ӗ', 'Ә', 'Ӛ', 'Ӝ', 'Ӟ', 'Ӡ', 'Ӣ', 'Ӥ', 'Ӧ', 'Ө', 'Ӫ', 'Ӭ', ' Ӯ', 'Ӱ', 'Ӳ', 'Ӵ', 'Ӷ', 'Ӹ', 'Ӻ', 'Ӽ', 'Ӿ', 'ӿ', 'Ԁ', 'Ԃ', 'Ԅ', 'Ԇ', 'Ԉ', 'Ԋ', 'Ԍ', 'Ԏ', 'Ԑ', 'Ԓ', 'Ԕ', 'Ԗ', 'Ԙ', 'Ԛ', 'Ԝ', 'Ԟ', 'Ԡ', 'Ԣ', 'ԥ', 'Ԧ', 'Ԩ', 'Ԫ', 'Ԭ', 'Ԯ', '԰', 'Բ', 'Դ', 'Զ', 'Ը', 'Ժ', 'Լ', 'Ծ',\n",
    "    'ѐ', 'ђ', 'ѓ', 'є', 'ѕ', 'і', 'ї', 'ј', 'љ', 'њ', 'ћ', 'ќ', 'ѝ', 'ў', 'џ', 'ѡ', 'ѣ', 'ѥ', 'ѧ', 'ѩ', 'ѫ', 'ѭ', 'ѯ', 'ѱ', 'ѳ', 'ѵ', 'ҁ', 'ҋ', 'ҍ', 'ҏ', 'ґ', 'ғ', 'ҕ', 'җ', 'ҙ', 'қ', 'ҝ', 'ҟ', 'ҡ', 'ң', 'ҥ', 'ҧ', 'ҵ', 'ҫ', 'ҭ', 'ү', 'ұ', 'ҳ', 'ҵ', 'җ', 'ҹ', 'һ', 'ҽ', 'ҿ', 'ӏ', 'ӂ', 'ӄ', 'ӆ', 'ӈ', 'ӊ', 'ӌ', 'ӎ', 'ạ', 'ӓ', 'ӕ', 'ӗ', 'ә', 'ӛ', 'ӝ', 'ӟ', 'ӡ', 'ӣ', 'ӥ', 'ӧ', 'ө', 'ӫ', 'ӭ', 'ӯ', 'ӱ', 'ӳ', 'ӵ', 'ғ', 'ӷ', 'ӹ', 'ӻ', 'ӽ', 'ӿ', 'ԁ', 'ԃ', 'ԅ', 'ԇ', 'ԉ', 'ԋ', 'ԍ', 'ԏ', 'ԑ', 'ԓ', 'ԕ', 'ԗ', 'ԙ', 'ԛ', 'ԝ', 'ԟ', 'ԡ', 'ԣ', 'ԥ', 'ԧ', 'ԩ', 'ԫ', 'ԭ', 'ԯ', 'Ա', 'Գ', 'Ե', 'Է', 'Թ', 'Ի', 'Խ', 'Կ'\n",
    "]\n",
    "\n",
    "cyrillic_characters = set(cyrillic_characters)\n",
    "\n",
    "def found_word(s, words):\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in s:\n",
    "            return True, words[i]\n",
    "    return False, None\n",
    "\n",
    "def detect_ngram_repetitions(text, n=10):\n",
    "    tokens = text.split()\n",
    "    ngrams = defaultdict(int)\n",
    "\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram = ' '.join(tokens[i:i+n])\n",
    "        ngrams[ngram] += 1\n",
    "    repeated_ngrams = {ngram: count for ngram, count in ngrams.items() if count > 1}\n",
    "    \n",
    "    return repeated_ngrams\n",
    "\n",
    "indons = []\n",
    "\n",
    "def accept(d, min_len = 10, skip_indon = True, skip_translation = True):\n",
    "    global indons\n",
    "    \n",
    "    d = d.strip()\n",
    "    \n",
    "    if len(d.split()) < min_len:\n",
    "        return False\n",
    "    \n",
    "    if len(set(d) & cyrillic_characters):\n",
    "        return False\n",
    "        \n",
    "    if 'terjemahkan teks' in d.lower():\n",
    "        return False\n",
    "\n",
    "    if 'no need to translate' in d.lower():\n",
    "        return False\n",
    "\n",
    "    if 'can be translated' in d.lower():\n",
    "        return False\n",
    "\n",
    "    if 'cannot translate' in d.lower():\n",
    "        return False\n",
    "\n",
    "    if 'should be translated to' in d.lower():\n",
    "        return False\n",
    "\n",
    "    if 'cannot be translated' in d.lower():\n",
    "        return False\n",
    "\n",
    "    if 'standard malay' in d.lower():\n",
    "        return False\n",
    "\n",
    "    if 'would not be translated' in d.lower():\n",
    "        return False\n",
    "\n",
    "    if 'as an AI language model' in d:\n",
    "        return False\n",
    "\n",
    "    if 'should be translated as' in d.lower():\n",
    "        return False\n",
    "\n",
    "    if 'Bahasa Malaysia Standard' in d:\n",
    "        return False\n",
    "    \n",
    "    if 'Saya adalah model AI' in d:\n",
    "        return False\n",
    "    \n",
    "    if 'saya model AI' in d:\n",
    "        return False\n",
    "    \n",
    "    if 'Saya model AI' in d:\n",
    "        return False\n",
    "    \n",
    "    if 'sebagai model AI' in d:\n",
    "        return False\n",
    "    \n",
    "    if 'Sebagai model AI' in d:\n",
    "        return False\n",
    "    \n",
    "    if 'model bahasa AI' in d:\n",
    "        return False\n",
    "    \n",
    "    if 'model AI yang dibangunkan' in d:\n",
    "        return False\n",
    "    \n",
    "    if d == '<s>':\n",
    "        return False\n",
    "    \n",
    "    if 'tidak dapat memberikan maklumat' in d:\n",
    "        return False\n",
    "    \n",
    "    if 'Sebagai model bahasa' in d:\n",
    "        return False\n",
    "    \n",
    "    match = pattern.search(d)\n",
    "    if match:\n",
    "        return False\n",
    "    \n",
    "    d_lower = d.lower()\n",
    "    splitted = d_lower.split()\n",
    "    if (len(set(splitted)) / len(splitted)) < 0.2:\n",
    "        return False\n",
    "    \n",
    "    words = d.split()\n",
    "    ratio_words = [w for w in words if len(w) > 100 and (len(set(w)) / len(w)) <= 0.2]\n",
    "    if len(ratio_words):\n",
    "        return False\n",
    "    \n",
    "    repeated = detect_ngram_repetitions(d, n = 10)\n",
    "    for v in repeated.values():\n",
    "        if v > 2:\n",
    "            return False\n",
    "    \n",
    "    if found_word(d_lower, rejected)[0]:\n",
    "        return False\n",
    "    \n",
    "    if found_word(d_lower, break_at)[0]:\n",
    "        return False\n",
    "    \n",
    "    if skip_translation and found_word(d_lower, break_at_terjemah)[0]:\n",
    "        return False\n",
    "    \n",
    "    if skip_indon:\n",
    "        found_indon = found_word(d_lower, rejected_words)\n",
    "        if found_indon[0]:\n",
    "            indons.append((d, found_indon[1]))\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20141d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "219018it [01:14, 2935.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "with open('post-postfilter.jsonl', 'w') as fopen_l:\n",
    "\n",
    "    with open('postfilter.jsonl') as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "\n",
    "            if '```' not in l['answer_ms']:\n",
    "                continue\n",
    "\n",
    "            if l['instruction_ms'] is None:\n",
    "                continue\n",
    "            else:\n",
    "                q = l['instruction_ms']\n",
    "                if len(set(q.split())) < (len(set(l['instruction'].split())) / 2):\n",
    "                    continue\n",
    "\n",
    "            if l['answer_ms'] is None:\n",
    "                continue\n",
    "\n",
    "            if len(set(l['answer_ms'].split())) < (len(set(l['answer'].split())) / 2):\n",
    "                continue\n",
    "\n",
    "            if l['answer'] is None:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                \n",
    "                lang = l['answer_ms'].split('```')[1].split('\\n')[0]\n",
    "                if 'cudaMalloc' in lang:\n",
    "                    continue\n",
    "\n",
    "                if not accept(l['answer_ms']):\n",
    "                    continue\n",
    "\n",
    "                if len(l['answer_ms'].split()) / len(l['answer'].split()) > 1.1:\n",
    "                    continue\n",
    "\n",
    "                if len(l['answer_ms'].split()) / len(l['answer'].split()) < 0.91:\n",
    "                    continue\n",
    "\n",
    "                splitted = l['answer_ms'].split()\n",
    "                ms = len(set(splitted)) / len(splitted)\n",
    "                splitted = l['answer'].split()\n",
    "                en = len(set(splitted)) / len(splitted)\n",
    "\n",
    "                if np.abs(en - ms) > 0.15:\n",
    "                    continue\n",
    "\n",
    "                if l['answer'].strip().endswith('```') and not l['answer_ms'].strip().endswith('```'):\n",
    "                    continue\n",
    "                \n",
    "                fopen_l.write(f'{json.dumps(l)}\\n')\n",
    "                fopen_l.flush()\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5e3ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132352 post-postfilter.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l post-postfilter.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee45681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 husein husein 856M Sep  30 23:30 post-postfilter.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh post-postfilter.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae9da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023c78e6c0474d638d64179ce6de54ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "post-postfilter.jsonl:   0%|          | 0.00/897M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='post-postfilter.jsonl',\n",
    "    path_in_repo=\"post-postfilter.jsonl\",\n",
    "    repo_id=\"mesolitica/mixtral-magicoder\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acbb42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
