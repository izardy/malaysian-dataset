{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6bc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/chatgpt-malay-function-call/resolve/main/function-calls.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/chatgpt-malay-function-call/resolve/main/function-calls-complex.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f3111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaysian_sft import accept as accept_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d57854",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_at = [\n",
    "    'help.openai.com',\n",
    "    'openai',\n",
    "    'cannot have personal opinions',\n",
    "    's an ai language model',\n",
    "    \"i'm sorry\",\n",
    "    'many factors',\n",
    "    'gay',\n",
    "    'lgbt',\n",
    "    'lesbian',\n",
    "    'gender-neutral',\n",
    "    'remain neutral',\n",
    "    'without bias',\n",
    "    'and neutral',\n",
    "    'more inclusive',\n",
    "    'neutrality',\n",
    "    'non-bias',\n",
    "    'discrimination',\n",
    "    'avoid any forms of discrimination',\n",
    "    'regardless of their gender',\n",
    "    'inclusive and tolerant environment',\n",
    "    'have personal views',\n",
    "    'sexual orientation should be a top priority',\n",
    "    's an objective ai',\n",
    "    'avoid any forms of prejudice or hate',\n",
    "    'regardless of their personal',\n",
    "    'you understand this direction',\n",
    "    'tolerant environment within ai',\n",
    "    'cannot express my',\n",
    "    'requires more context',\n",
    "    'personal opinion',\n",
    "    'have updated information',\n",
    "    \"don't have personal experiences\",\n",
    "    'there is no information',\n",
    "    'tidak mempunyai akses kepada data atau maklumat',\n",
    "    '10 april 2021',\n",
    "    'ebagai model bahasa AI'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b52177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317b5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\n",
    "    'tukar ke JSON berdasarkan schema {schema}, teks `{text}`',\n",
    "    'text `{text}`, convert to JSON using schema {schema}',\n",
    "    'teks: {text}\\n\\ntukar ke JSON using schema {schema}',\n",
    "    'convert to JSON using schema {schema}\\n\\ntext: {text}',\n",
    "    '{text}\\n\\nJSON berdasarkan schema {schema}',\n",
    "    'JSON berdasarkan schema {schema}\\n\\n{text}',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372b141d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "179450it [00:05, 34435.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "178576"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "with open('function-calls.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        texts = []\n",
    "        failed = False\n",
    "        for no, d in enumerate(l['conversations']):\n",
    "\n",
    "            if d['role'] == 'user':\n",
    "                t = '<manusia>: '\n",
    "                c = 'content'\n",
    "            else:\n",
    "                if 'functioncall' in d['content']:\n",
    "                    c = 'content'\n",
    "                else:\n",
    "                    if 'functioncall' in l['conversations'][no - 1]['content']:\n",
    "                        continue\n",
    "                    c = 'content'\n",
    "                t = '<bot>: '\n",
    "\n",
    "            if d[c] is None:\n",
    "                break\n",
    "\n",
    "            if 'functioncall' in d[c]:\n",
    "                d[c] = d[c].split('FUNCTION RESPONSE:')[0].strip()\n",
    "\n",
    "            if '<functioncall>' in d[c]:\n",
    "                d[c] = d[c].split('<functioncall>')[1].strip()\n",
    "                try:\n",
    "                    d[c] = eval(d[c])\n",
    "                    d[c] = json.dumps(d[c]['arguments'])\n",
    "                    \n",
    "                except:\n",
    "                    failed = True\n",
    "                    continue\n",
    "\n",
    "            n = d[c]\n",
    "            n = n.strip()\n",
    "\n",
    "            if len(n) < 3:\n",
    "                break\n",
    "\n",
    "            if d['role'] == 'user':\n",
    "                n = random.choice(templates).format(schema = l['function_call'], text = n)\n",
    "            t = t + n\n",
    "            texts.append(t)\n",
    "\n",
    "        if failed:\n",
    "            continue\n",
    "\n",
    "        if not len(texts):\n",
    "            continue\n",
    "        while len(texts) and texts[-1].startswith('<manusia>'):\n",
    "            texts = texts[:-1]\n",
    "        if not len(texts):\n",
    "            continue\n",
    "        if not texts[0].startswith('<manusia>'):\n",
    "            continue\n",
    "            \n",
    "        if not len(texts):\n",
    "            continue\n",
    "\n",
    "        data.append({\n",
    "            'prompt_input': None,\n",
    "            'input': '\\n'.join(texts[:2]),\n",
    "            'output': None,\n",
    "        })\n",
    "            \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c2a9cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24977"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_complex = []\n",
    "\n",
    "with open('function-calls-complex.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        texts = []\n",
    "        failed = False\n",
    "        for no, d in enumerate(l['conversations']):\n",
    "\n",
    "            if d['role'] == 'user':\n",
    "                t = '<manusia>: '\n",
    "                if random.random() > 0.5:\n",
    "                    c = 'content'\n",
    "                else:\n",
    "                    c = 'content'\n",
    "            else:\n",
    "                if 'functioncall' in d['content']:\n",
    "                    c = 'content'\n",
    "                else:\n",
    "                    if 'functioncall' in l['conversations'][no - 1]['content']:\n",
    "                        continue\n",
    "                    c = 'content'\n",
    "                t = '<bot>: '\n",
    "\n",
    "            if d[c] is None:\n",
    "                break\n",
    "\n",
    "            if 'functioncall' in d[c]:\n",
    "                d[c] = d[c].split('FUNCTION RESPONSE:')[0].strip()\n",
    "\n",
    "            if '<functioncall>' in d[c]:\n",
    "                d[c] = d[c].split('<functioncall>')[1].strip()\n",
    "                try:\n",
    "                    d[c] = eval(d[c])\n",
    "                    d[c] = json.dumps(d[c]['arguments'])\n",
    "                except:\n",
    "                    failed = True\n",
    "                    continue\n",
    "\n",
    "\n",
    "            n = d[c]\n",
    "            n = n.strip()\n",
    "\n",
    "            if len(n) < 3:\n",
    "                break\n",
    "\n",
    "            if d['role'] == 'user':\n",
    "                n = random.choice(templates).format(schema = l['function_call'], text = n)\n",
    "            t = t + n\n",
    "            texts.append(t)\n",
    "\n",
    "        if failed:\n",
    "            continue\n",
    "\n",
    "        if not len(texts):\n",
    "            continue\n",
    "        while len(texts) and texts[-1].startswith('<manusia>'):\n",
    "            texts = texts[:-1]\n",
    "        if not len(texts):\n",
    "            continue\n",
    "        if not texts[0].startswith('<manusia>'):\n",
    "            continue\n",
    "            \n",
    "        if not len(texts):\n",
    "            continue\n",
    "\n",
    "        data_complex.append({\n",
    "            'prompt_input': None,\n",
    "            'input': '\\n'.join(texts[:2]),\n",
    "            'output': None,\n",
    "        })\n",
    "            \n",
    "len(data_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b1724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3.8 install to-json-schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7612c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24986it [00:01, 18298.73it/s]\n",
      "179450it [00:07, 23888.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "203553"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from to_json_schema.to_json_schema import SchemaBuilder\n",
    "\n",
    "schema_builder = SchemaBuilder()\n",
    "\n",
    "different_schema = []\n",
    "files = [\n",
    "    'function-calls-complex.jsonl',\n",
    "    'function-calls.jsonl'\n",
    "]\n",
    "for filename in files:\n",
    "    with open(filename) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            texts = []\n",
    "            failed = False\n",
    "            for no, d in enumerate(l['conversations']):\n",
    "\n",
    "                if d['role'] == 'user':\n",
    "                    t = '<manusia>: '\n",
    "                    c = 'content'\n",
    "                else:\n",
    "                    if 'functioncall' in d['content']:\n",
    "                        c = 'content'\n",
    "                    else:\n",
    "                        if 'functioncall' in l['conversations'][no - 1]['content']:\n",
    "                            continue\n",
    "                        c = 'content'\n",
    "                    t = '<bot>: '\n",
    "\n",
    "                if d[c] is None:\n",
    "                    break\n",
    "\n",
    "                if 'functioncall' in d[c]:\n",
    "                    d[c] = d[c].split('FUNCTION RESPONSE:')[0].strip()\n",
    "\n",
    "                if '<functioncall>' in d[c]:\n",
    "                    d[c] = d[c].split('<functioncall>')[1].strip()\n",
    "                    try:\n",
    "                        d[c] = eval(d[c])\n",
    "                        d[c] = json.dumps(d[c]['arguments'])\n",
    "\n",
    "                    except:\n",
    "                        failed = True\n",
    "                        continue\n",
    "\n",
    "                n = d[c]\n",
    "                n = n.strip()\n",
    "\n",
    "                if len(n) < 3:\n",
    "                    break\n",
    "\n",
    "                t = t + n\n",
    "                texts.append(t)\n",
    "\n",
    "            if failed:\n",
    "                continue\n",
    "\n",
    "            if not len(texts):\n",
    "                continue\n",
    "            while len(texts) and texts[-1].startswith('<manusia>'):\n",
    "                texts = texts[:-1]\n",
    "            if not len(texts):\n",
    "                continue\n",
    "            if not texts[0].startswith('<manusia>'):\n",
    "                continue\n",
    "\n",
    "            texts = texts[:2]\n",
    "            if not len(texts):\n",
    "                continue\n",
    "\n",
    "            f = json.loads(texts[1].split('>: ')[1])\n",
    "            if 'complex' not in filename and random.random() > 0.6:\n",
    "                keys = f.keys()\n",
    "                keys = [f\"'{k}'\" for k in keys]\n",
    "                schema = '{' + ', '.join(keys) + '}'\n",
    "            else:\n",
    "                schema = schema_builder.to_json_schema(f)\n",
    "\n",
    "            n = texts[0].split('>: ')[1]\n",
    "            n = random.choice(templates).format(schema = schema, text = n)\n",
    "            texts[0] = f'<manusia>: {n}'\n",
    "\n",
    "            different_schema.append({\n",
    "                'prompt_input': None,\n",
    "                'input': '\\n'.join(texts),\n",
    "                'output': None,\n",
    "            })\n",
    "        \n",
    "len(different_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3778f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(row):\n",
    "    texts = ['<s>']\n",
    "\n",
    "    if 'function_call' in row:\n",
    "        t = row['function_call']\n",
    "        texts.append(f'\\n[FUNCTIONCALL]\\n{t}\\n')\n",
    "\n",
    "    if '<bot>:' in row['input'] and row['output'] is None:\n",
    "        inputs, outputs = [], []\n",
    "        splitted = row['input'].split('<bot>:')\n",
    "        for i in range(len(splitted) - 1):\n",
    "            if i == 0:\n",
    "                human = splitted[i].replace('<manusia>:', '')\n",
    "            else:\n",
    "                try:\n",
    "                    human = splitted[i].split('<manusia>:')[1]\n",
    "                except:\n",
    "                    continue\n",
    "            bot = splitted[i + 1].split('<manusia>:')[0]\n",
    "            inputs.append(human.strip())\n",
    "            outputs.append(bot.strip())\n",
    "    else:\n",
    "        inputs = [row['input']]\n",
    "        outputs = [row['output']]\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a78b4756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 407106/407106 [02:02<00:00, 3318.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_data = []\n",
    "for d in tqdm(data + data_complex + different_schema):\n",
    "    r = generate_and_tokenize_prompt(d)\n",
    "    \n",
    "    if not accept_fn(r[0][0]):\n",
    "        continue\n",
    "    \n",
    "    if not accept_fn(r[1][0]):\n",
    "        continue\n",
    "    \n",
    "    all_data.append({\n",
    "        'prompt_input': None,\n",
    "        'input': r[0][0],\n",
    "        'output': r[1][0],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f15c177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58177"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9a2ae54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_input</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>tukar ke JSON berdasarkan schema {\\n \"name\": \"...</td>\n",
       "      <td>{\"numbers\": [5, 2, 9, 1, 7, 4, 6, 3, 8]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Nombor-nombor adalah 8, 3, 5, 2, 7, 4, 9, 1, 6...</td>\n",
       "      <td>{\"numbers\": [8, 3, 5, 2, 7, 4, 9, 1, 6]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>convert to JSON using schema {\\n \"name\": \"rese...</td>\n",
       "      <td>{\"location\": \"Kuala Lumpur\", \"check_in_date\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>teks: I'd like to order two nasi lemak, extra ...</td>\n",
       "      <td>{\"item\": \"nasi lemak\", \"quantity\": 2, \"special...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Hai, boleh cari resepi spaghetti carbonara unt...</td>\n",
       "      <td>{\"masakan\": \"spaghetti carbonara\", \"bahan\": \"t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_input                                              input  \\\n",
       "0         None  tukar ke JSON berdasarkan schema {\\n \"name\": \"...   \n",
       "1         None  Nombor-nombor adalah 8, 3, 5, 2, 7, 4, 9, 1, 6...   \n",
       "2         None  convert to JSON using schema {\\n \"name\": \"rese...   \n",
       "3         None  teks: I'd like to order two nasi lemak, extra ...   \n",
       "4         None  Hai, boleh cari resepi spaghetti carbonara unt...   \n",
       "\n",
       "                                              output  \n",
       "0           {\"numbers\": [5, 2, 9, 1, 7, 4, 6, 3, 8]}  \n",
       "1           {\"numbers\": [8, 3, 5, 2, 7, 4, 9, 1, 6]}  \n",
       "2  {\"location\": \"Kuala Lumpur\", \"check_in_date\": ...  \n",
       "3  {\"item\": \"nasi lemak\", \"quantity\": 2, \"special...  \n",
       "4  {\"masakan\": \"spaghetti carbonara\", \"bahan\": \"t...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c67e08a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58177, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0b23d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('prepared-force-json-format.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb89679e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d91580725224fb89f389ca3e762937c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prepared-force-json-format.parquet:   0%|          | 0.00/12.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/Malaysian-SFT/commit/37b7528801cba578e9fffcd45db0550ea5b3fd50', commit_message='Upload data/force_json_format-00000-of-00001.parquet with huggingface_hub', commit_description='', oid='37b7528801cba578e9fffcd45db0550ea5b3fd50', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"prepared-force-json-format.parquet\",\n",
    "    path_in_repo='data/force_json_format-00000-of-00001.parquet',\n",
    "    repo_id=\"mesolitica/Malaysian-SFT\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
