{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63c0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/mixtral-magicoder/resolve/main/post-postfilter.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ccf3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaysian_sft import accept as accept_fn\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e2ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = [\n",
    "    'always reply in malay',\n",
    "    'sentiasa respond dalam bahasa melayu',\n",
    "    'sentiasa jawab in malay',\n",
    "    'awak adalah chatbot yang respond dalam bahasa melayu',\n",
    "    'you are a chatbot that always respond in malay',\n",
    "    'u always reply in malay',\n",
    "    'awak sentiasa reply in malay',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3002d795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'postfilter.jsonl': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh postfilter.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e786bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "132352it [00:06, 20688.86it/s]\n"
     ]
    }
   ],
   "source": [
    "filtered = []\n",
    "\n",
    "with open('post-postfilter.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        \n",
    "        q = l['instruction']\n",
    "\n",
    "        if l['answer_ms'] is None:\n",
    "            continue\n",
    "            \n",
    "        if len(set(l['answer_ms'].split())) < (len(set(l['answer'].split())) / 2):\n",
    "            continue\n",
    "            \n",
    "        q = f'{random.choice(system)}\\n\\n{q.strip()}'\n",
    "        \n",
    "        d = {\n",
    "            'prompt_input': None,\n",
    "            'input': q,\n",
    "            'output': l['answer_ms'].strip(),\n",
    "        }\n",
    "        filtered.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55712351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dad5c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:00, 79179.13it/s] \n",
      "78577it [00:00, 563018.49it/s]\n",
      "20000it [00:00, 80679.71it/s]\n",
      "20000it [00:00, 85726.46it/s]\n",
      "20000it [00:00, 80526.36it/s]\n"
     ]
    }
   ],
   "source": [
    "files = glob('/home/husein/ssd3/camel-ai/*.translated.jsonl')\n",
    "\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            if 'message_1' not in l:\n",
    "                continue\n",
    "                \n",
    "            if l['message_1'] is None or l['message_2_ms'] is None:\n",
    "                continue\n",
    "                \n",
    "            q = f\"{random.choice(system)}\\n\\n{l['message_1'].strip()}\"\n",
    "            \n",
    "            d = {\n",
    "                'prompt_input': None,\n",
    "                'input': q,\n",
    "                'output': l['message_2_ms'].strip(),\n",
    "            }\n",
    "            filtered.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4088cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232901"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e72c1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = [\n",
    "    'always better to find peaceful',\n",
    "    'non-violent ways to express',\n",
    "    'can lead to severe consequences',\n",
    "    'still have questions or concerns about',\n",
    "    'that doing so is illegal',\n",
    "    'to report the incident to',\n",
    "    'would recommend consulting with',\n",
    "    'indonesian',\n",
    "    'translates to',\n",
    "    'idiom in',\n",
    "    'in English',\n",
    "    'in Malay',\n",
    "    # 'language model'\n",
    "]\n",
    "\n",
    "break_at = [\n",
    "    'help.openai.com',\n",
    "    'openai',\n",
    "    'cannot have personal opinions',\n",
    "    's an ai language model',\n",
    "    \"i'm sorry\",\n",
    "    'many factors',\n",
    "    'lgbt',\n",
    "    'lesbian',\n",
    "    'gender-neutral',\n",
    "    'remain neutral',\n",
    "    'without bias',\n",
    "    'and neutral',\n",
    "    'more inclusive',\n",
    "    'neutrality',\n",
    "    'non-bias',\n",
    "    'discrimination',\n",
    "    'avoid any forms of discrimination',\n",
    "    'regardless of their gender',\n",
    "    'inclusive and tolerant environment',\n",
    "    'have personal views',\n",
    "    'sexual orientation should be a top priority',\n",
    "    's an objective ai',\n",
    "    'avoid any forms of prejudice or hate',\n",
    "    'regardless of their personal',\n",
    "    'you understand this direction',\n",
    "    'tolerant environment within ai',\n",
    "    'cannot express my',\n",
    "    'requires more context',\n",
    "    'personal opinion',\n",
    "    'have updated information',\n",
    "    \"don't have personal experiences\",\n",
    "    'there is no information',\n",
    "    'tidak mempunyai akses kepada data atau maklumat',\n",
    "    '10 april 2021',\n",
    "    'ebagai model bahasa AI',\n",
    "    'ebagai model bahasa ai',\n",
    "    'model bahasa AI',\n",
    "    'model bahasa ai',\n",
    "    'bahasa ai',\n",
    "    'ebagai model bahasa'\n",
    "    'hat makes sense',\n",
    "    'have access to data or information',\n",
    "    'have access to the data or information',\n",
    "    'hanya mempunyai akses kepada maklumat umum',\n",
    "    'hanya boleh memberikan maklumat umum',\n",
    "    'have personal preferences',\n",
    "    'not have personal experiences',\n",
    "    'not capable of having subjective opinions',\n",
    "    'indonesian',\n",
    "    'mistral',\n",
    "    'terjemah',\n",
    "    'translate'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b6cbe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60384it [00:14, 4198.54it/s]\n",
      "48163it [00:09, 5237.80it/s]\n",
      "57798it [00:11, 4849.60it/s]\n",
      "103242it [01:05, 1576.12it/s]\n",
      "135770it [01:57, 1154.05it/s]\n"
     ]
    }
   ],
   "source": [
    "roles = {\n",
    "    'user': '<manusia>',\n",
    "    'assistant': '<bot>'\n",
    "}\n",
    "\n",
    "files = glob('/home/husein/ssd2/soalan-augmentation/*conversation*.jsonl')\n",
    "files.extend(glob('/home/husein/ssd2/soalan-augmentation/*multiturn*.jsonl'))\n",
    "files = [f for f in files if 'rag' not in f]\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            l = json.loads(l)\n",
    "            inputs = []\n",
    "            for no, r in enumerate(l):\n",
    "                if no < (len(l) - 1):\n",
    "                    if l[no + 1]['role'] == 'user':\n",
    "                        next_text = l[no + 1].get('content') or ''\n",
    "                    else:\n",
    "                        next_text = l[no + 1].get('content_ms') or ''\n",
    "                else:\n",
    "                    next_text = ''\n",
    "                \n",
    "                if r['role'] == 'user':\n",
    "                    q = r.get('content', '') or ''\n",
    "                    current_text = q       \n",
    "                else:\n",
    "                    current_text = r.get('content_ms') or ''\n",
    "                    \n",
    "                if l[no - 1]['role'] == 'user':\n",
    "                    previous_text = l[no - 1].get('content') or ''\n",
    "                else:\n",
    "                    previous_text = l[no - 1].get('content_ms') or ''\n",
    "                \n",
    "                # bad pairs\n",
    "                if r['role'] == 'user' and (len(current_text) < 2 or len(next_text) < 2):\n",
    "                    # print('a', l, current_text, next_text, '\\n')\n",
    "                    continue\n",
    "                if r['role'] == 'assistant' and (len(current_text) < 2 or len(previous_text) < 2):\n",
    "                    continue\n",
    "                \n",
    "                # bad pairs\n",
    "                if r['role'] == 'user' and current_text[:20].lower() == next_text[:20].lower():\n",
    "                    # print(no, r, current_text[:20].lower(), next_text[:20].lower())\n",
    "                    continue\n",
    "                if r['role'] == 'assistant' and current_text[:20].lower() == previous_text[:20].lower():\n",
    "                    # print(no, r, current_text[:20].lower(), previous_text[:20].lower())\n",
    "                    continue\n",
    "                    \n",
    "                # remove alignments    \n",
    "                if r['role'] == 'user' and (any([b in current_text.lower() for b in break_at]) or any([b in next_text.lower() for b in break_at])):\n",
    "                    # print(current_text, next_text)\n",
    "                    break\n",
    "                if r['role'] == 'assistant' and (any([b in current_text.lower() for b in break_at]) or any([b in previous_text.lower() for b in break_at])):\n",
    "                    # print(current_text, next_text)\n",
    "                    break\n",
    "\n",
    "                role = roles[r['role']]\n",
    "                \n",
    "                s = f\"{role}: {current_text}\"\n",
    "                    \n",
    "                inputs.append((s, r))\n",
    "\n",
    "            if len(inputs) % 2 != 0:\n",
    "                inputs = inputs[:-1]\n",
    "                \n",
    "            if not len(inputs):\n",
    "                continue\n",
    "                \n",
    "            if len(inputs) < 2:\n",
    "                continue\n",
    "            \n",
    "            outputs = []\n",
    "            for i in range(0, len(inputs), 2):\n",
    "                \n",
    "                try:\n",
    "                    content = inputs[i][1]['content']\n",
    "                    content_ms = inputs[i][1]['content_ms']\n",
    "\n",
    "                    if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                        continue\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    content = inputs[i + 1][1]['content']\n",
    "                    content_ms = inputs[i + 1][1]['content_ms']\n",
    "\n",
    "                    if len(set(content_ms.split())) < (len(set(content.split())) / 2):\n",
    "                        continue\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                outputs.extend([\n",
    "                    inputs[i][0],\n",
    "                    inputs[i + 1][0]\n",
    "                ])\n",
    "            \n",
    "            if not len(outputs):\n",
    "                continue\n",
    "            outputs[0] = outputs[0].replace('<manusia>: ', f'<manusia>: {random.choice(system)}\\n\\n')\n",
    "\n",
    "            data = '\\n'.join(outputs).strip()\n",
    "            if not len(data):\n",
    "                continue\n",
    "                \n",
    "            d = {\n",
    "                'prompt_input': None,\n",
    "                'input': data,\n",
    "                'output': None,\n",
    "            }\n",
    "            \n",
    "            filtered.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4a35ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625080"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "077521c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(filtered).to_parquet('prepared-force-malay.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8563d115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 husein husein 1000M Dis  24 20:41 prepared-force-malay.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh prepared-force-malay.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "777c1607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651608e4d11e47958d35579247a198ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prepared-force-malay.parquet:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/Malaysian-SFT/commit/f5a1209b2824fefa5815292c084388c603b53ce2', commit_message='Upload data/force_malay-00000-of-00001.parquet with huggingface_hub', commit_description='', oid='f5a1209b2824fefa5815292c084388c603b53ce2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/mesolitica/Malaysian-SFT', endpoint='https://huggingface.co', repo_type='dataset', repo_id='mesolitica/Malaysian-SFT'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"prepared-force-malay.parquet\",\n",
    "    path_in_repo='data/force_malay-00000-of-00001.parquet',\n",
    "    repo_id=\"mesolitica/Malaysian-SFT\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c6a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
