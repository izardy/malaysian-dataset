{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d62dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/huseinzol05/98974ae8c6c7a65d4bc0af9f5003786a/raw/2e06e71ef7349a57bc58cc9913ae6bae1f9f8447/mp.py\n",
    "# !wget https://huggingface.co/datasets/mesolitica/instructions-dataset/resolve/main/shuf-combine-malay-no-alignment-multitasks-v5.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994a0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !split -l 213000 -d --additional-suffix=.splitted shuf-combine-malay-no-alignment-multitasks-v5.jsonl shuf-combine-malay-no-alignment-multitasks-v5.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbc2133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl00.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl01.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl02.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl03.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl04.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl05.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl06.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl07.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl08.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl09.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl10.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl11.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl12.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl13.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl14.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl15.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl16.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl17.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl18.splitted\r\n",
      "shuf-combine-malay-no-alignment-multitasks-v5.jsonl19.splitted\r\n"
     ]
    }
   ],
   "source": [
    "!ls shuf-combine-malay-no-alignment-multitasks-v5.jsonl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b4d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/gemma-2b-it')\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.add_bos_token = False\n",
    "tokenizer.add_eos_token = False\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f646f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(row):\n",
    "    if '<bot>:' in row['input'] and row['output'] is None:\n",
    "        inputs, outputs = [], []\n",
    "        splitted = row['input'].split('<bot>:')\n",
    "        for i in range(len(splitted) - 1):\n",
    "            if i == 0:\n",
    "                human = splitted[i].replace('<manusia>:', '')\n",
    "            else:\n",
    "                try:\n",
    "                    human = splitted[i].split('<manusia>:')[1]\n",
    "                except BaseException:\n",
    "                    continue\n",
    "            bot = splitted[i + 1].split('<manusia>:')[0]\n",
    "            inputs.append(human)\n",
    "            outputs.append(bot)\n",
    "    else:\n",
    "        inputs = [row['input']]\n",
    "        outputs = [row['output']]\n",
    "\n",
    "    chat = []\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        chat.extend([\n",
    "            {'role': 'user', 'content': input.strip()},\n",
    "            {'role': 'assistant', 'content': output.strip()},\n",
    "        ])\n",
    "    prompt = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "638f1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from streaming import MDSWriter\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset\n",
    "import streaming\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "}\n",
    "hashes = 'sha1', 'xxh64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ab3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘tokenized_gemma’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir tokenized_gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fe1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(files, block_size = 16384):\n",
    "    files, index = files\n",
    "    out_root = f'tokenized_gemma/tokenized-{index}'\n",
    "    os.system(f'rm -rf {out_root}')\n",
    "    temp = []\n",
    "    with MDSWriter(out=out_root, columns=columns, compression=None, hashes=hashes) as out:\n",
    "        for f in files:\n",
    "            with open(f) as fopen:\n",
    "                for l in tqdm(fopen):\n",
    "                    row = json.loads(l)\n",
    "                    element = generate_and_tokenize_prompt(row)\n",
    "                    outputs = tokenizer(element['text'])\n",
    "                    temp.extend(outputs['input_ids'])\n",
    "                    done = False\n",
    "                    while len(temp) >= block_size:\n",
    "                        block = temp[:block_size]\n",
    "                        temp = temp[block_size:]\n",
    "                        if len(block) == block_size:\n",
    "                            out.write({\n",
    "                                'input_ids': np.array(block).astype(np.uint32)\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc6dd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shuf-combine-malay-no-alignment-multitasks-v5.jsonl00.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl01.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl02.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl03.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl04.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl05.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl06.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl07.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl08.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl09.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl10.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl11.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl12.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl13.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl14.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl15.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl16.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl17.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl18.splitted',\n",
       " 'shuf-combine-malay-no-alignment-multitasks-v5.jsonl19.splitted']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob('shuf-combine-malay-no-alignment-multitasks-v5.jsonl*.splitted'), key = lambda x: int(x.split('jsonl')[-1].split('.')[0]))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0041eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76150it [02:37, 493.67it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "119163it [04:09, 501.06it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "197347it [06:48, 468.76it/s]\n",
      "213000it [07:16, 487.66it/s]\n",
      "213000it [07:17, 487.39it/s]\n",
      "213000it [07:17, 487.17it/s]\n",
      "213000it [07:17, 486.96it/s]\n",
      "213000it [07:17, 486.43it/s]\n",
      "213000it [07:18, 486.30it/s]\n",
      "213000it [07:18, 485.97it/s]\n",
      "213000it [07:18, 485.96it/s]\n",
      "213000it [07:18, 485.42it/s]\n",
      "213000it [07:19, 485.18it/s]\n",
      "213000it [07:19, 484.75it/s]\n",
      "213000it [07:19, 484.31it/s]\n",
      "213000it [07:20, 483.63it/s]\n",
      "213000it [07:20, 483.36it/s]\n",
      "213000it [07:21, 482.83it/s]\n",
      "213000it [07:22, 481.64it/s]\n",
      "213000it [07:22, 481.36it/s]\n",
      "213000it [07:24, 479.30it/s]\n",
      "213000it [07:25, 478.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import mp\n",
    "mp.multiprocessing(files, loop, cores = min(len(files), 30), returned = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbef060e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenized_gemma/tokenized-0',\n",
       " 'tokenized_gemma/tokenized-1',\n",
       " 'tokenized_gemma/tokenized-2',\n",
       " 'tokenized_gemma/tokenized-3',\n",
       " 'tokenized_gemma/tokenized-4',\n",
       " 'tokenized_gemma/tokenized-5',\n",
       " 'tokenized_gemma/tokenized-6',\n",
       " 'tokenized_gemma/tokenized-7',\n",
       " 'tokenized_gemma/tokenized-8',\n",
       " 'tokenized_gemma/tokenized-9',\n",
       " 'tokenized_gemma/tokenized-10',\n",
       " 'tokenized_gemma/tokenized-11',\n",
       " 'tokenized_gemma/tokenized-12',\n",
       " 'tokenized_gemma/tokenized-13',\n",
       " 'tokenized_gemma/tokenized-14',\n",
       " 'tokenized_gemma/tokenized-15',\n",
       " 'tokenized_gemma/tokenized-16',\n",
       " 'tokenized_gemma/tokenized-17',\n",
       " 'tokenized_gemma/tokenized-18',\n",
       " 'tokenized_gemma/tokenized-19']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = sorted(glob('tokenized_gemma/tokenized-*'), key = lambda x: int(x.split('-')[-1]))\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13add590",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf packing-gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "569b2475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9390/9390 [00:01<00:00, 5216.38it/s]\n",
      "100%|██████████| 9388/9388 [00:01<00:00, 5351.52it/s]\n",
      "100%|██████████| 9383/9383 [00:01<00:00, 5304.66it/s]\n",
      "100%|██████████| 9402/9402 [00:01<00:00, 5364.63it/s]\n",
      "100%|██████████| 9412/9412 [00:01<00:00, 5503.47it/s]\n",
      "100%|██████████| 9402/9402 [00:01<00:00, 5321.40it/s]\n",
      "100%|██████████| 9421/9421 [00:01<00:00, 5758.14it/s]\n",
      "100%|██████████| 9443/9443 [00:01<00:00, 5767.42it/s]\n",
      "100%|██████████| 9391/9391 [00:01<00:00, 5761.70it/s]\n",
      "100%|██████████| 9402/9402 [00:01<00:00, 5740.44it/s]\n",
      "100%|██████████| 9417/9417 [00:01<00:00, 5418.24it/s]\n",
      "100%|██████████| 9424/9424 [00:01<00:00, 5400.41it/s]\n",
      "100%|██████████| 9412/9412 [00:01<00:00, 5870.47it/s]\n",
      "100%|██████████| 9424/9424 [00:01<00:00, 5864.68it/s]\n",
      "100%|██████████| 9386/9386 [00:01<00:00, 5839.69it/s]\n",
      "100%|██████████| 9408/9408 [00:01<00:00, 5423.80it/s]\n",
      "100%|██████████| 9379/9379 [00:01<00:00, 5825.33it/s]\n",
      "100%|██████████| 9408/9408 [00:01<00:00, 5854.89it/s]\n",
      "100%|██████████| 9368/9368 [00:01<00:00, 5847.94it/s]\n",
      "100%|██████████| 8714/8714 [00:01<00:00, 5573.56it/s]\n"
     ]
    }
   ],
   "source": [
    "with MDSWriter(out='packing-gemma', columns=columns, compression=None, hashes=hashes) as out:\n",
    "    for f in folders:\n",
    "        try:\n",
    "            dataset = LocalDataset(local=f)\n",
    "            for i in tqdm(range(len(dataset))):\n",
    "                out.write(dataset[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a094b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LocalDataset('packing-gemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d443c2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3069935616"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) * 16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1885d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([     2,    106,   1645, ..., 235248, 235274, 235274], dtype=uint32)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50f85b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187374/187374 [00:07<00:00, 26226.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4fbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
