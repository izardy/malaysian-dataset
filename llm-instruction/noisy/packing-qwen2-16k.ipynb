{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce883d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/instructions-dataset/resolve/main/shuf-combine-malay-no-alignment-multitasks-v4.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722d5fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('mesolitica/Qwen1.5-0.5B-4096-fpf')\n",
    "tokenizer.add_bos_token = False\n",
    "tokenizer.add_eos_token = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50dfe2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(row):\n",
    "    if '<bot>:' in row['input'] and row['output'] is None:\n",
    "        inputs, outputs = [], []\n",
    "        splitted = row['input'].split('<bot>:')\n",
    "        for i in range(len(splitted) - 1):\n",
    "            if i == 0:\n",
    "                human = splitted[i].replace('<manusia>:', '')\n",
    "            else:\n",
    "                try:\n",
    "                    human = splitted[i].split('<manusia>:')[1]\n",
    "                except BaseException:\n",
    "                    continue\n",
    "            bot = splitted[i + 1].split('<manusia>:')[0]\n",
    "            inputs.append(human)\n",
    "            outputs.append(bot)\n",
    "    else:\n",
    "        inputs = [row['input']]\n",
    "        outputs = [row['output']]\n",
    "\n",
    "    chat = []\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        chat.extend([\n",
    "            {'role': 'user', 'content': input.strip()},\n",
    "            {'role': 'assistant', 'content': output.strip()},\n",
    "        ])\n",
    "    prompt = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "947e0c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf packing-qwen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85e3f510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2809610it [1:14:01, 652.43it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from streaming import MDSWriter\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset\n",
    "import streaming\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "}\n",
    "hashes = 'sha1', 'xxh64'\n",
    "\n",
    "block_size = 16384\n",
    "temp = []\n",
    "with MDSWriter(out='packing-qwen2', columns=columns, compression=None, hashes=hashes) as out:\n",
    "    with open('shuf-combine-malay-no-alignment-multitasks-v4.jsonl') as fopen:\n",
    "        for l in tqdm(fopen):\n",
    "            row = json.loads(l)\n",
    "            element = generate_and_tokenize_prompt(row)\n",
    "            outputs = tokenizer(element['text'])\n",
    "            temp.extend(outputs['input_ids'])\n",
    "            while len(temp) >= block_size:\n",
    "                block = temp[:block_size]\n",
    "                temp = temp[block_size:]\n",
    "                if len(block) == block_size:\n",
    "                    out.write({\n",
    "                        'input_ids': np.array(block).astype(np.uint32)\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "866eedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class DatasetFixed(torch.utils.data.Dataset):\n",
    "    def __init__(self, local):\n",
    "        self.dataset = LocalDataset(local=local)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        data['labels'] = data[\"input_ids\"].copy()\n",
    "        data.pop('token_type_ids', None)\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].astype(np.int64)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8069378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetFixed('packing-qwen2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53287145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([151644,    872,    198, ...,  26857,  14274,     72]),\n",
       " 'labels': array([151644,    872,    198, ...,  26857,  14274,     72])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a39e8734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.436118016"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(dataset) * 16384) / 1e9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
