{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79318a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'standard_en': {'title': 'Standard En', 'type': 'string'},\n",
       "  'standard_ms': {'title': 'Standard Ms', 'type': 'string'}},\n",
       " 'required': ['standard_en', 'standard_ms'],\n",
       " 'title': 'Translation',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Translation(BaseModel):\n",
    "    standard_en: str\n",
    "    standard_ms: str\n",
    "        \n",
    "schema = Translation.model_json_schema()\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89330c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('casperhansen/llama-3-70b-instruct-awq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6aca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "with open('mandarin.texts') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        texts.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07758970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec9a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "for d in texts:\n",
    "    s = f\"\"\"\n",
    "```\n",
    "{d}\n",
    "```\n",
    "\n",
    "translate everything, DO NOT FORGOT ABOUT THE INITIAL, to standard english and standard malay, NO NEED TO EXPLAIN, return in JSON {{'standard_en', 'standard_ms'}}\n",
    "\"\"\".strip()\n",
    "    prompts.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a81c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [\n",
    "    {'role': 'user', 'content': prompts[0]}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(m, tokenize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705ec9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# headers = {\n",
    "#     'accept': 'application/json',\n",
    "#     'Content-Type': 'application/json',\n",
    "# }\n",
    "\n",
    "# json_data = {\n",
    "#   \"inputs\": inputs,\n",
    "#   \"parameters\": {\n",
    "#     \"do_sample\": True,\n",
    "#     \"grammar\": {\"type\": \"json\", \"value\": schema},\n",
    "#     \"max_new_tokens\": 2048,\n",
    "#     \"repetition_penalty\": 1.03,\n",
    "#     \"stop\": [\n",
    "#       \"<|eot_id|>\"\n",
    "#     ],\n",
    "#     \"temperature\": 0.9,\n",
    "#     \"top_k\": 50,\n",
    "#     \"top_p\": 0.95,\n",
    "#     \"watermark\": False\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# response = requests.post(\n",
    "#     'https://llama-3.us.mesolitica.com/generate', \n",
    "#     headers=headers, json=json_data, timeout = 60 * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117c970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.json()['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3952d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘translate-c.cari’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "directory = 'translate-c.cari'\n",
    "# !rm -rf {directory}\n",
    "!mkdir {directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3697337e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342252"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(f'{directory}/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667a5630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "def answer(q, i, verbose = False):\n",
    "    filename = f'{directory}/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    openai = OpenAI(\n",
    "        base_url='',\n",
    "        api_key='empty',\n",
    "    )\n",
    "    response = None\n",
    "    while True:\n",
    "        try:\n",
    "            json_data = {\n",
    "                'messages': [\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': q,\n",
    "                    },\n",
    "                ],\n",
    "                'model': 'model',\n",
    "                'stop': [\n",
    "                    '<|eot_id|>',\n",
    "                ],\n",
    "                'temperature': 0.9,\n",
    "                'max_tokens': 2048,\n",
    "            }\n",
    "            response = requests.post(\n",
    "                '', \n",
    "                headers=headers, json=json_data, timeout = 60 * 10)\n",
    "            if verbose:\n",
    "                print(response, response.__dict__)\n",
    "            r = response.json()['choices'][0]['message']['content']\n",
    "            results.append(r)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(e)\n",
    "            if response is not None and response.status_code != 503:\n",
    "                break\n",
    "    \n",
    "    \n",
    "    if len(results): \n",
    "        with open(filename, 'w') as fopen:\n",
    "            json.dump(results, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "994e5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(queue, name):\n",
    "    while True:\n",
    "        if queue.qsize() == 0:\n",
    "            break\n",
    "        item = queue.get()\n",
    "        answer(*item)\n",
    "    print(f'consumer {name} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e99afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [(q, no) for no, q in enumerate(prompts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0194105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer(*urls[1000000], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fdd65fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(*urls[1000001], verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa6f78cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"{\\n\\\"standard_en\\\": \\\"Original post by Devil.May.Cry on 11-7-2009 07:36 PM. I've checked, no virus found. Could it be a hardware problem? Please help, experts! Open Task Manager and see which program is using up your resources. Otherwise, you can upload a screenshot of your Task Manager for us to take a look.\\\",\\n\\\"standard_ms\\\": \\\"Pos asal oleh Devil.May.Cry pada 11-7-2009 07:36 PT. Saya telah menyemak, tidak ada virus. Adakah ia masalah keras? Sila bantu, pakar! Buka Pengurus Tugas dan lihat mana program yang menggunakan sumber anda. Jika tidak, anda boleh memuat naik screenshot Pengurus Tugas anda untuk kami lihat.\\\"\\n}\"]\n"
     ]
    }
   ],
   "source": [
    "with open(f'{directory}/1000001.json') as fopen:\n",
    "    print(fopen.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5136882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(*urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95c45467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from tqdm import tqdm\n",
    "\n",
    "queue = Queue()\n",
    "for u in urls:\n",
    "    queue.put(u)\n",
    "    \n",
    "ori_size = queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███▊                                                                | 166646/3000001 [39:42<298:38:54,  2.64it/s]"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "consumers = [Thread(target=consumer, args=(queue,i)) for i in range(max_worker)]\n",
    "for i in range(len(consumers)):\n",
    "    consumers[i].start()\n",
    "    \n",
    "pbar = tqdm(total=ori_size)\n",
    "last_size = 0\n",
    "while True:\n",
    "    size = queue.qsize()\n",
    "    if size == 0:\n",
    "        break\n",
    "    left = ori_size - size\n",
    "    minus = left - last_size\n",
    "    if minus > 0:\n",
    "        pbar.update(minus)\n",
    "        last_size += minus\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72b116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
