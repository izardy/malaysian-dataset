{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59120e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'standard_en': {'title': 'Standard En', 'type': 'string'},\n",
       "  'standard_ms': {'title': 'Standard Ms', 'type': 'string'}},\n",
       " 'required': ['standard_en', 'standard_ms'],\n",
       " 'title': 'Translation',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Translation(BaseModel):\n",
    "    standard_en: str\n",
    "    standard_ms: str\n",
    "        \n",
    "schema = Translation.model_json_schema()\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257b28f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('casperhansen/llama-3-70b-instruct-awq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee040c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "with open('manglish.texts') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        texts.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86fd355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c49ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "for d in texts:\n",
    "    s = f\"\"\"\n",
    "```\n",
    "{d}\n",
    "```\n",
    "\n",
    "translate everything, DO NOT FORGOT ABOUT THE INITIAL, to standard english and standard malay, NO NEED TO EXPLAIN, return in JSON {{'standard_en', 'standard_ms'}}\n",
    "\"\"\".strip()\n",
    "    prompts.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4177ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘translate-manglish’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "directory = 'translate-manglish'\n",
    "# !rm -rf {directory}\n",
    "!mkdir {directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994f6aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203188"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(f'{directory}/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eba8d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "def answer(q, i, verbose = False):\n",
    "    filename = f'{directory}/{i}.json'\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    openai = OpenAI(\n",
    "        base_url='',\n",
    "        api_key='empty',\n",
    "    )\n",
    "    response = None\n",
    "    while True:\n",
    "        try:\n",
    "            json_data = {\n",
    "                'messages': [\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': q,\n",
    "                    },\n",
    "                ],\n",
    "                'model': 'model',\n",
    "                'stop': [\n",
    "                    '<|eot_id|>',\n",
    "                ],\n",
    "                'temperature': 0.9,\n",
    "                'max_tokens': 2048,\n",
    "            }\n",
    "            response = requests.post(\n",
    "                '', \n",
    "                headers=headers, json=json_data, timeout = 60 * 10)\n",
    "            if verbose:\n",
    "                print(response, response.__dict__)\n",
    "            r = response.json()['choices'][0]['message']['content']\n",
    "            results.append(r)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(e)\n",
    "            if response is not None and response.status_code != 503:\n",
    "                break\n",
    "    \n",
    "    \n",
    "    if len(results): \n",
    "        with open(filename, 'w') as fopen:\n",
    "            json.dump(results, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0840d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        d = json.load(fopen)\n",
    "        \n",
    "    if len(d) == 0:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a3ed3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(queue, name):\n",
    "    while True:\n",
    "        if queue.qsize() == 0:\n",
    "            break\n",
    "        item = queue.get()\n",
    "        answer(*item)\n",
    "    print(f'consumer {name} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac64d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [(q, no) for no, q in enumerate(prompts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e8f7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(*urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a46a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(*urls[int(1e6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebc0c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"{\\n\\\"standard_en\\\": \\\"By the way, front passenger windows only cost around RM90, and adding a labor charge of about RM45 plus a vacuum service at the car wash for only RM15. So, it's still cheap compared to replacing all the keys.\\\",\\n\\\"standard_ms\\\": \\\"Bagi maklumat, tingkap penumpang hadapan hanya berharga sekitar RM90, dan menambahkan caj buruh sebanyak kira-kira RM45 plus perkhidmatan vakum di car wash hanya RM15. Jadi, ia masih murah jika dibandingkan dengan menggantikan semua kunci.\\\"\\n}\"]\n"
     ]
    }
   ],
   "source": [
    "with open(f'{directory}/{int(1e6)}.json') as fopen:\n",
    "    print(fopen.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77fd2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from tqdm import tqdm\n",
    "\n",
    "queue = Queue()\n",
    "for u in urls:\n",
    "    queue.put(u)\n",
    "    \n",
    "ori_size = queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58215235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████▍                                                            | 193043/2000001 [3:00:47<44:51:41, 11.19it/s]"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "consumers = [Thread(target=consumer, args=(queue,i)) for i in range(max_worker)]\n",
    "for i in range(len(consumers)):\n",
    "    consumers[i].start()\n",
    "    \n",
    "pbar = tqdm(total=ori_size)\n",
    "last_size = 0\n",
    "while True:\n",
    "    size = queue.qsize()\n",
    "    if size == 0:\n",
    "        break\n",
    "    left = ori_size - size\n",
    "    minus = left - last_size\n",
    "    if minus > 0:\n",
    "        pbar.update(minus)\n",
    "        last_size += minus\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3764eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
