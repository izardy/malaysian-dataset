{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a084ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"src\": \"Busana tersebut memiliki ciri tampilan sopan, tertutup, dan tidak menonjolkan lekuk tubuh perempuan.\", \"r\": {\"result\": \"The dress has the characteristics of a polite, closed look, and does not highlight the curves of the woman's body.\", \"pronunciation\": \"undefined\", \"from\": {}}}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 malay-news.txt03.splitted.requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a328f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "d = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92ed268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a9084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negeri = [\n",
    "#     'johor',\n",
    "#     'kedah',\n",
    "#     'kelantan',\n",
    "#     'kelantan_v2',\n",
    "#     'melaka',\n",
    "#     'negeri_sembilan',\n",
    "#     'pahang',\n",
    "#     'perak',\n",
    "#     'sabah'\n",
    "# ]\n",
    "\n",
    "# for n in negeri:\n",
    "#     os.system(f'wget https://raw.githubusercontent.com/mesolitica/malaysian-dataset/master/dictionary/dialect/{n}.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df7bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/huseinzol05/malay-dataset/master/normalization/en-lexicon/en-social-media-lexicon.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c34ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kedah\n",
    "import kelantan_v2\n",
    "import kelantan\n",
    "import melaka\n",
    "import negeri_sembilan\n",
    "import pahang\n",
    "import perak\n",
    "import sabah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fda48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0d96102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "\n",
    "files = glob('malay-news.txt*.splitted.requested')\n",
    "mapping = {}\n",
    "for f in files:\n",
    "    with open(f) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            mapping[l['src']] = l['r']['result']\n",
    "\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f52eb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2006969, 2006969)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left, right = [], []\n",
    "for k, v in mapping.items():\n",
    "    if len(set(v.split())) < (len(set(k.split())) / 2):\n",
    "        continue\n",
    "    left.append(k)\n",
    "    right.append(v)\n",
    "len(left), len(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cce11459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"Sejujurnya, Muhyiddin pada kaca mata rakyat hari ini adalah perdana menteri terbaik dan dekat di hati mereka.',\n",
       " '\"Honestly, Muhyiddin in the eyes of the people today is the best prime minister and close to their hearts.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left[0], right[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d187753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "/home/husein/dev/malaya/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "from malaya.text.rules import rules_normalizer, rules_compound_normalizer\n",
    "from malaya.text.normalization import _is_number_regex\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ffd83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en-social-media-lexicon.json') as fopen:\n",
    "    en_lexicon = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "186f8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_rules_compound_normalizer = defaultdict(list)\n",
    "for k, v in rules_compound_normalizer.items():\n",
    "    k = k.replace('b . i', 'bi').replace('b . m', 'bm')\n",
    "    rev_rules_compound_normalizer[v].append(k)\n",
    "    \n",
    "rev_rules_normalizer = defaultdict(list)\n",
    "for k, v in rules_normalizer.items():\n",
    "    rev_rules_normalizer[v].append(k)\n",
    "    \n",
    "rules_compound_normalizer_regex = (\n",
    "    '(?:' + '|'.join(list(rev_rules_compound_normalizer.keys())) + ')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831e65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kedah_compound_normalizer = defaultdict(list)\n",
    "kedah_normalizer = defaultdict(list)\n",
    "for k, v in kedah.dictionary.items():\n",
    "    for v_ in v:\n",
    "        if len(v_.split()) > 1:\n",
    "            kedah_compound_normalizer[v_].append(k)\n",
    "        else:\n",
    "            kedah_normalizer[v_].append(k)\n",
    "            \n",
    "kedah_compound_normalizer_regex = (\n",
    "    '(?:' + '|'.join(list(kedah_compound_normalizer.keys())) + ')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7ca48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "kelantan_compound_normalizer = defaultdict(list)\n",
    "kelantan_normalizer = defaultdict(list)\n",
    "for k, v in kelantan.dictionary.items():\n",
    "    for v_ in v:\n",
    "        if len(v_.split()) > 1:\n",
    "            kelantan_compound_normalizer[v_].append(k)\n",
    "        else:\n",
    "            kelantan_normalizer[v_].append(k)\n",
    "            \n",
    "for k, v in kelantan_v2.dictionary.items():\n",
    "    for v_ in v:\n",
    "        if len(v_.split()) > 1:\n",
    "            kelantan_compound_normalizer[v_].append(k)\n",
    "        else:\n",
    "            kelantan_normalizer[v_].append(k)\n",
    "            \n",
    "kelantan_compound_normalizer_regex = (\n",
    "    '(?:' + '|'.join(list(kelantan_compound_normalizer.keys())) + ')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b26fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "melaka_compound_normalizer = defaultdict(list)\n",
    "melaka_normalizer = defaultdict(list)\n",
    "for k, v in melaka.dictionary.items():\n",
    "    for v_ in v:\n",
    "        if len(v_.split()) > 1:\n",
    "            melaka_compound_normalizer[v_].append(k)\n",
    "        else:\n",
    "            melaka_normalizer[v_].append(k)\n",
    "            \n",
    "melaka_compound_normalizer_regex = (\n",
    "    '(?:' + '|'.join(list(melaka_compound_normalizer.keys())) + ')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c173c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "negeri_sembilan_compound_normalizer = defaultdict(list)\n",
    "negeri_sembilan_normalizer = defaultdict(list)\n",
    "for k, v in negeri_sembilan.dictionary.items():\n",
    "    for v_ in v:\n",
    "        if len(v_.split()) > 1:\n",
    "            negeri_sembilan_compound_normalizer[v_].append(k)\n",
    "        else:\n",
    "            negeri_sembilan_normalizer[v_].append(k)\n",
    "            \n",
    "negeri_sembilan_compound_normalizer_regex = (\n",
    "    '(?:' + '|'.join(list(negeri_sembilan_compound_normalizer.keys())) + ')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c944a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pahang_compound_normalizer = defaultdict(list)\n",
    "pahang_normalizer = defaultdict(list)\n",
    "for k, v in pahang.dictionary.items():\n",
    "    for v_ in v:\n",
    "        if len(v_.split()) > 1:\n",
    "            pahang_compound_normalizer[v_].append(k)\n",
    "        else:\n",
    "            pahang_normalizer[v_].append(k)\n",
    "            \n",
    "pahang_compound_normalizer_regex = (\n",
    "    '(?:' + '|'.join(list(pahang_compound_normalizer.keys())) + ')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb180809",
   "metadata": {},
   "outputs": [],
   "source": [
    "perak_compound_normalizer = defaultdict(list)\n",
    "perak_normalizer = defaultdict(list)\n",
    "for k, v in perak.dictionary.items():\n",
    "    for v_ in v:\n",
    "        if len(v_.split()) > 1:\n",
    "            perak_compound_normalizer[v_].append(k)\n",
    "        else:\n",
    "            perak_normalizer[v_].append(k)\n",
    "            \n",
    "perak_compound_normalizer_regex = (\n",
    "    '(?:' + '|'.join(list(perak_compound_normalizer.keys())) + ')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9118327",
   "metadata": {},
   "outputs": [],
   "source": [
    "sabah_compound_normalizer = defaultdict(list)\n",
    "sabah_normalizer = defaultdict(list)\n",
    "for k, v in sabah.dictionary.items():\n",
    "    for v_ in v:\n",
    "        if len(v_.split()) > 1:\n",
    "            sabah_compound_normalizer[v_].append(k)\n",
    "        else:\n",
    "            sabah_normalizer[v_].append(k)\n",
    "            \n",
    "sabah_compound_normalizer_regex = (\n",
    "    '(?:' + '|'.join(list(sabah_compound_normalizer.keys())) + ')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e48e51a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialects = [\n",
    "    (kedah_compound_normalizer, kedah_normalizer, kedah_compound_normalizer_regex),\n",
    "    (kelantan_compound_normalizer, kelantan_normalizer, kelantan_compound_normalizer_regex),\n",
    "    (melaka_compound_normalizer, melaka_normalizer, melaka_compound_normalizer_regex),\n",
    "    (negeri_sembilan_compound_normalizer, negeri_sembilan_normalizer, negeri_sembilan_compound_normalizer_regex),\n",
    "    (pahang_compound_normalizer, pahang_normalizer, pahang_compound_normalizer_regex),\n",
    "    (perak_compound_normalizer, perak_normalizer, perak_compound_normalizer_regex),\n",
    "    (sabah_compound_normalizer, sabah_normalizer, sabah_compound_normalizer_regex),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a761ce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', ',', 'counters')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PUNCTUATION = '!\"#$%&\\'()*+,./:;<=>?@[\\]^_`{|}~'\n",
    "QUOTE = '\\'\"'\n",
    "BRACKET = '{}()[]'\n",
    "\n",
    "def case_of(text):\n",
    "    return (\n",
    "        str.upper\n",
    "        if text.isupper()\n",
    "        else str.lower\n",
    "        if text.islower()\n",
    "        else str.title\n",
    "        if text.istitle()\n",
    "        else str\n",
    "    )\n",
    "\n",
    "def strip_punct(word):\n",
    "    left = []\n",
    "    right = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if word[i] in PUNCTUATION:\n",
    "            left.append(word[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    i = len(word) - 1\n",
    "    while i > 0:\n",
    "        if word[i] in PUNCTUATION:\n",
    "            right.append(word[i])\n",
    "            i -= 1\n",
    "        else:\n",
    "            break\n",
    "    left = ''.join(left)\n",
    "    right = ''.join(right[::-1])\n",
    "    if len(right):\n",
    "        word_ = word[:-len(right)]\n",
    "    else:\n",
    "        word_ = word\n",
    "    word_ = word_[len(left):]\n",
    "    return left, right, word_\n",
    "\n",
    "\n",
    "def replace_shortword(word, rules = rev_rules_normalizer):\n",
    "    if word[0] in QUOTE or word[-1] in QUOTE:\n",
    "        return word\n",
    "    if word[0] in BRACKET or word[-1] in BRACKET:\n",
    "        return word\n",
    "    left, right, word_ = strip_punct(word)\n",
    "    word_ = word_[len(left):]\n",
    "    lower_word_ = word_.lower()\n",
    "    if lower_word_ in rules:\n",
    "        if isinstance(rules[lower_word_], list):\n",
    "            s = random.choice(rules[lower_word_])\n",
    "        else:\n",
    "            s = rules[lower_word_]\n",
    "        word_ = case_of(word_)(s)\n",
    "        word_ = f'{left}{word_}{right}'\n",
    "        return word_\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "strip_punct('counters,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c55d32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _replace_compound(string, rules = rev_rules_compound_normalizer):\n",
    "    for k in list(rules.keys()):\n",
    "        results = [(m.start(0), m.end(0)) for m in re.finditer(k, string, flags=re.IGNORECASE)]\n",
    "        for r in results:\n",
    "            sub = string[r[0]: r[1]]\n",
    "            try:\n",
    "                replaced = random.choice(rules[sub.lower()])\n",
    "                if replaced:\n",
    "                    if r[1] < len(string) and string[r[1]] != ' ':\n",
    "                        continue\n",
    "                    if r[0] - 1 > len(string) and string[r[0] - 1] != ' ':\n",
    "                        continue\n",
    "\n",
    "                    sub = case_of(sub)(replaced)\n",
    "                    string = string[:r[0]] + sub + string[r[1]:]\n",
    "            except:\n",
    "                pass\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eada3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_punct(left_word, right_word):\n",
    "    left_left, left_right, left_word = strip_punct(left_word)\n",
    "    right_left, right_right, right_word = strip_punct(right_word)\n",
    "    return f'{left_left}{right_word}{left_right}'\n",
    "\n",
    "def random_replace_alignment(left, right, alignment, min_replace = 2, max_replace = 7):\n",
    "    splitted_left = left.split()\n",
    "    splitted_right = right.split()\n",
    "    \n",
    "    selected_alignment = []\n",
    "    for s in alignment:\n",
    "        l = s[0]\n",
    "        r = s[1]\n",
    "        if _is_number_regex(splitted_left[l].replace(',', '').replace('.', '')) or _is_number_regex(splitted_right[r].replace(',', '').replace('.', '')):\n",
    "            continue\n",
    "        elif splitted_left[l].isupper() or splitted_right[r].isupper():\n",
    "            continue\n",
    "        elif splitted_left[l] == splitted_right[r]:\n",
    "            continue\n",
    "        elif splitted_right[r].lower() in ['the', 'a', 'an', 'it', 'is', 'are']:\n",
    "            continue\n",
    "        else:\n",
    "            selected_alignment.append((l, r))\n",
    "    \n",
    "    count_replace = random.randint(min_replace, min(max_replace, len(selected_alignment)))\n",
    "    \n",
    "    selected = random.sample(selected_alignment, count_replace)\n",
    "    for s in selected:\n",
    "        splitted_left[s[0]] = replace_words_punct(splitted_left[s[0]], splitted_right[s[1]])\n",
    "    \n",
    "    return ' '.join(splitted_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6e0b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary-ms-zh.json') as fopen:\n",
    "    ms_zh = json.load(fopen)\n",
    "    \n",
    "with open('word-ms-jawi.json') as fopen:\n",
    "    ms_jawi = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f53c26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709437, 1092530)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ms_zh), len(ms_jawi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78d5d9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'اداله'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_jawi['adalah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21d3a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e812f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "consonants = 'bcdfghjklmnpqrstvwxyz'\n",
    "\n",
    "def augment(left, p_replace_shortword = 0.6, p_socialmedia = 0.85, p_vowel_alternate = 0.8, p_replace_en_shortword = 0.3):\n",
    "    \n",
    "    compound_rules_, rules_, rules_regex_ = random.choice(dialects)\n",
    "    left = _replace_compound(left, rules = copy.deepcopy(rev_rules_compound_normalizer))\n",
    "    left = _replace_compound(left, rules = copy.deepcopy(compound_rules_))\n",
    "    #left = _replace_compound(left, rules_regex = rules_regex_, rules = compound_rules_)\n",
    "    left = [replace_shortword(word, rules = en_lexicon) if random.random() > p_replace_en_shortword else word for word in left.split()]\n",
    "    left = [replace_shortword(word, rules = rules_) for word in left]\n",
    "    left = [(replace_shortword(word), False) if random.random() > p_replace_shortword else (word, True) for word in left]\n",
    "    left = [(replace_shortword(word, rules = ms_zh), False) if a and random.random() > 0.7 else (word, True) for word, a in left]\n",
    "    left = [(replace_shortword(word, rules = ms_jawi), False) if a and random.random() > 0.7 else (word, True)for word, a in left]\n",
    "    left_ = []\n",
    "    for l in left:\n",
    "        if _is_number_regex(l[0].replace(',', '').replace('.', '')):\n",
    "            left_.append(l[0])\n",
    "            continue\n",
    "        if l[0].isupper():\n",
    "            left_.append(l[0])\n",
    "            continue\n",
    "        if l[0].istitle():\n",
    "            left_.append(l[0])\n",
    "            continue\n",
    "        if d.check(l[0]):\n",
    "            left_.append(l[0])\n",
    "            continue\n",
    "        \n",
    "        if l[1]:\n",
    "            if random.random() > p_socialmedia:\n",
    "                try:\n",
    "                    r = malaya.augmentation.socialmedia_form(l[0])\n",
    "                except:\n",
    "                    r = [l[0]]\n",
    "                if len(r):\n",
    "                    s = random.choice(r)\n",
    "                else:\n",
    "                    s = l[0]\n",
    "            else:\n",
    "                s = l[0]\n",
    "                \n",
    "            if random.random() > p_vowel_alternate:\n",
    "                try:\n",
    "                    s = malaya.augmentation.vowel_alternate(s)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    if random.random() and s[-1] == 'a' and s[-2] in consonants:\n",
    "                        s = s[:-1] + 'e'\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            s = l[0]\n",
    "        \n",
    "        left_.append(case_of(l[0])(s))\n",
    "    return ' '.join(left_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b64d7130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dlam ڤد itu, 赛义德 Ali brpndapat, tindakan Muhyiddin yanckh segera keluar daripada PH & bergerak di باوه PN sehingga 成功的 menubuhkan كراجأن, adlh langkah brani for 'menyelamatkan 人 Melayu' darpade trus hilangv kuasa.\n"
     ]
    }
   ],
   "source": [
    "print(augment(left[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fa25f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dalam pada itu, Syed Ali berpendapat, tindakan Muhyiddin yang segera keluar daripada PH dan bergerak di bawah PN sehingga berjaya menubuhkan kerajaan, adalah langkah berani untuk 'menyelamatkan orang Melayu' daripada terus hilang kuasa.\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7dc078d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the meantime, Syed Ali thinks that Muhyiddin's action to immediately leave PH and move under PN until he succeeded in establishing a government, is a brave step to 'save the Malays' from continuing to lose power.\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "94789de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3c6df07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import traceback\n",
    "\n",
    "def loop(rows):\n",
    "    rows, _ = rows\n",
    "    new_left, original, original_right = [], [], []\n",
    "    for i in tqdm(range(len(rows))):\n",
    "        left, right = rows[i][0], rows[i][1]\n",
    "        if len(left.split()) > 100:\n",
    "            continue\n",
    "        l = []\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                new_left_ = augment(left)\n",
    "                if new_left_ != left:\n",
    "                    l.append(new_left_)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "        \n",
    "        if len(l):\n",
    "            new_left.append(l)\n",
    "            original.append(left)\n",
    "            original_right.append(right)\n",
    "    return [[new_left, original, original_right]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c3ad42c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [30:54<00:00, 108.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 125.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [31:15<00:00, 107.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [31:19<00:00, 106.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [31:21<00:00, 106.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [31:28<00:00, 106.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [31:30<00:00, 106.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [31:27<00:00, 106.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [31:30<00:00, 106.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [31:37<00:00, 105.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 200696/200696 [31:35<00:00, 105.90it/s]\n"
     ]
    }
   ],
   "source": [
    "r = mp.multiprocessing(list(zip(left, right)), loop, cores = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4e319189",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e8d7fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synthetic-word-switching-translation.jsonl', 'w') as fopen:\n",
    "    for i in range(len(r)):\n",
    "        for k in range(len(r[i][0])):\n",
    "\n",
    "            d = {\n",
    "                'ms': r[i][1][k],\n",
    "                'en': r[i][2][k],\n",
    "                'augmentation': r[i][0][k]\n",
    "            }\n",
    "            fopen.write(f'{json.dumps(d)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eb20a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991741 synthetic-word-switching-translation.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l synthetic-word-switching-translation.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "69bd4394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ms\": \"\\\"Sejujurnya, Muhyiddin pada kaca mata rakyat hari ini adalah perdana menteri terbaik dan dekat di hati mereka.\", \"en\": \"\\\"Honestly, Muhyiddin in the eyes of the people today is the best prime minister and close to their hearts.\", \"augmentation\": [\"\\\"Sejujurnya, Muhyiddin pada \\u0643\\u0627\\u0686 \\u773c\\u775b rakyat hr iniehh adalah \\u06a4\\u0631\\u062f\\u0627\\u0646 \\u0645\\u0646\\u062a\\u0631\\u064a terbaekk \\u548c \\u062f\\u064a\\u0643\\u064a\\u062a \\u0643\\u062a hati \\u0645\\u0631\\u064a\\u0643.\", \"\\\"Sejujurnya, Muhyiddin \\u06a4\\u062f \\u0643\\u0627\\u0686 mato \\u4eba\\u4eec hr \\u0627\\u064a\\u0646 \\u0627\\u062f\\u0644\\u0647 \\u4e3b\\u8981\\u7684 \\u90e8\\u957f terbaik & dekat dhi hati dorang/durang.\", \"\\\"Sejujurnya, Muhyiddin pd kace \\u0645\\u0627\\u062a rakyat hri iniw adalah \\u06a4\\u0631\\u062f\\u0627\\u0646 \\u0645\\u0646\\u062a\\u0631\\u064a terbaeq dn dekat di hati \\u4ed6\\u4eec.\"]}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 synthetic-word-switching-translation.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545d61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693138b2ca8440178f0b482677e1cf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "synthetic-word-switching-translation.jsonl:   0%|          | 0.00/2.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='synthetic-word-switching-translation.jsonl',\n",
    "    path_in_repo='synthetic-word-switching-translation.jsonl',\n",
    "    repo_id='mesolitica/synthetic-word-switching-translation',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf82bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
