{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368e9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9262dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('prepared-lom.agc.gov.my-llama3.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        if len(l['text']) < 512:\n",
    "            continue\n",
    "        data.append(l['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234e4737",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2608"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96747ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'generate-lom.agc.gov.my-open-qa-llama3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39277104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘generate-lom.agc.gov.my-open-qa-llama3’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# !rm -rf generate-lom.agc.gov.my-open-qa-llama3\n",
    "!mkdir {folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695d750c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2608"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    s = \"\"\"\n",
    "```\n",
    "{{replace_me}}\n",
    "```\n",
    "\n",
    "Generate list of abstractive QA in malay, return in JSON [{'question', 'answer'}]\n",
    "    \"\"\".strip()\n",
    "    s = s.replace('{{replace_me}}', data[i])\n",
    "    results.append(s)\n",
    "        \n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c577ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "def answer(q, i):\n",
    "    filename = os.path.join(folder, f'{i}.json')\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    openai = OpenAI(\n",
    "        base_url='https://llama-3.us.mesolitica.com/v1',\n",
    "        api_key='empty',\n",
    "    )\n",
    "    for _ in range(1):\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                \n",
    "                json_data = {\n",
    "                    'messages': [\n",
    "                        {\n",
    "                            'role': 'user',\n",
    "                            'content': q,\n",
    "                        },\n",
    "                    ],\n",
    "                    'model': 'model',\n",
    "                    'stop': [\n",
    "                        '<|eot_id|>',\n",
    "                    ],\n",
    "                    'temperature': 0.9,\n",
    "                    'max_tokens': 2048,\n",
    "                }\n",
    "                response = requests.post(\n",
    "                    'https://llama-3.us.mesolitica.com/v1/chat/completions', \n",
    "                    headers=headers, json=json_data, timeout = 60 * 10)\n",
    "                \n",
    "                r = response.json()['choices'][0]['message']['content']\n",
    "                results.append(r)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "                \n",
    "    \n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump(results, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0f6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer(queue, name):\n",
    "    while True:\n",
    "        if queue.qsize() == 0:\n",
    "            break\n",
    "        item = queue.get()\n",
    "        answer(*item)\n",
    "    print(f'consumer {name} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48ec131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [(q, no) for no, q in enumerate(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaffe556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer(*urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69c55c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from tqdm import tqdm\n",
    "\n",
    "queue = Queue()\n",
    "for u in urls:\n",
    "    queue.put(u)\n",
    "    \n",
    "ori_size = queue.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e983c3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████▉| 2607/2608 [1:21:44<00:01,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consumer 47 done\n",
      "consumer 6 done\n",
      "consumer 10 done\n",
      "consumer 46 done\n",
      "consumer 48 done\n",
      "consumer 26 done\n",
      "consumer 11 done\n",
      "consumer 33 done\n",
      "consumer 1 done\n",
      "consumer 42 done\n",
      "consumer 23 done\n",
      "consumer 13 done\n",
      "consumer 9 done\n",
      "consumer 5 done\n",
      "consumer 34 done\n",
      "consumer 12 done\n",
      "consumer 39 done\n",
      "consumer 15 done\n",
      "consumer 38 done\n",
      "consumer 14 done\n",
      "consumer 21 done\n",
      "consumer 31 done\n",
      "consumer 43 done\n",
      "consumer 27 done\n",
      "consumer 29 done\n",
      "consumer 41 done\n",
      "consumer 30 done\n",
      "consumer 3 done\n",
      "consumer 28 done\n",
      "consumer 24 done\n",
      "consumer 49 done\n",
      "consumer 20 done\n",
      "consumer 36 done\n",
      "consumer 19 done\n",
      "consumer 37 done\n",
      "consumer 17 done\n",
      "consumer 45 done\n",
      "consumer 8 done\n",
      "consumer 40 done\n",
      "consumer 35 done\n",
      "consumer 18 done\n",
      "consumer 16 done\n",
      "consumer 44 done\n",
      "consumer 4 done\n",
      "consumer 0 done\n",
      "consumer 22 done\n",
      "consumer 7 done\n",
      "consumer 32 done\n",
      "consumer 25 done\n",
      "consumer 2 done\n"
     ]
    }
   ],
   "source": [
    "max_worker = 50\n",
    "consumers = [Thread(target=consumer, args=(queue,i)) for i in range(max_worker)]\n",
    "for i in range(len(consumers)):\n",
    "    consumers[i].start()\n",
    "    \n",
    "pbar = tqdm(total=ori_size)\n",
    "last_size = 0\n",
    "while True:\n",
    "    size = queue.qsize()\n",
    "    if size == 0:\n",
    "        break\n",
    "    left = ori_size - size\n",
    "    minus = left - last_size\n",
    "    if minus > 0:\n",
    "        pbar.update(minus)\n",
    "        last_size += minus\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750a17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('prepared-lom.agc.gov.my-llama3.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        if len(l['text']) < 512:\n",
    "            continue\n",
    "        data.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f9f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctranslate2==3.23.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip3.8 freeze | grep ctranslate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3573cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppose = {'question', 'answer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78321af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2608/2608 [00:00<00:00, 5209.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open('generate-lom.agc.gov.my-open-qa-llama3.jsonl', 'w') as fopen_j:\n",
    "    for i in tqdm(range(len(data))):\n",
    "        f = f'{folder}/{i}.json'\n",
    "        if not os.path.exists(f):\n",
    "            continue\n",
    "            \n",
    "        with open(f) as fopen:\n",
    "            d = json.load(fopen)\n",
    "        \n",
    "        questions = []\n",
    "        unique_questions = set()\n",
    "        for d_ in d:\n",
    "            try:\n",
    "                selected = []\n",
    "                for d__ in d_.split('```'):\n",
    "                    try:\n",
    "                        try:\n",
    "                            selected.append(json.loads(d__))\n",
    "                        except:\n",
    "                            selected.append(eval(d__))\n",
    "                    except:\n",
    "                        pass\n",
    "                if not len(selected):\n",
    "                    continue\n",
    "                qa = selected[0]\n",
    "                for q in qa:\n",
    "                    if len(set(q.keys()) | suppose) != len(suppose):\n",
    "                        continue\n",
    "                    if q['question'].lower() not in unique_questions:\n",
    "                        if not ('answer' in q and isinstance(q['answer'], str)):\n",
    "                            continue\n",
    "                            \n",
    "                        for k in suppose:\n",
    "                            q[k] = q[k].encode(\"utf8\", errors=\"surrogatepass\").decode(\"utf8\")\n",
    "\n",
    "                        questions.append(q)\n",
    "                        unique_questions.add(q['question'].lower())\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        if not len(questions):\n",
    "            continue\n",
    "        \n",
    "        data[i]['text'] = data[i]['text'].encode(\"utf8\", errors=\"surrogatepass\").decode(\"utf8\")\n",
    "        data[i]['questions'] = questions\n",
    "        fopen_j.write(f'{json.dumps(data[i])}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d5d8e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2253 generate-lom.agc.gov.my-open-qa-llama3.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l generate-lom.agc.gov.my-open-qa-llama3.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b5c655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 husein husein 23M Mei  30 14:23 generate-lom.agc.gov.my-open-qa-llama3.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh generate-lom.agc.gov.my-open-qa-llama3.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f73ba55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faa72641fc84042832754acaade683d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generate-lom.agc.gov.my-open-qa-llama3.jsonl:   0%|          | 0.00/23.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/llama-3-70b-qa/commit/c8918473ce3728a5169e874284b5bd14e43d7c10', commit_message='Upload generate-lom.agc.gov.my-open-qa-llama3.jsonl with huggingface_hub', commit_description='', oid='c8918473ce3728a5169e874284b5bd14e43d7c10', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj='generate-lom.agc.gov.my-open-qa-llama3.jsonl',\n",
    "    path_in_repo='generate-lom.agc.gov.my-open-qa-llama3.jsonl',\n",
    "    repo_id='mesolitica/llama-3-70b-qa',\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544ebd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
