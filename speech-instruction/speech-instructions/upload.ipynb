{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53cc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from datasets import Dataset, Audio\n",
    "\n",
    "audio = Audio(sampling_rate = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8077ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('instructions-keys.json') as fopen:\n",
    "    instructions = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea24a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fix-instructions-mixtral-multiturn.json') as fopen:\n",
    "    mixtral_multiturn = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3259849f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['short-coding-2.json', 'short-coding-0.json', 'short-coding-1.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('short-coding-*.json')\n",
    "files = [f for f in files if os.path.exists(f.replace('.json', ''))]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb16e2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18990it [00:00, 91460.81it/s] \n",
      "18991it [00:00, 117140.51it/s]\n",
      "18991it [00:00, 83742.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45415"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = []\n",
    "for f in files:\n",
    "    folder = f.replace('.json', '')\n",
    "    with open(f) as fopen:\n",
    "        data = json.load(fopen)\n",
    "    \n",
    "    for i, d in tqdm(enumerate(data)):\n",
    "        filename = os.path.join(folder, f'{i}.mp3')\n",
    "        if not os.path.exists(filename):\n",
    "            continue\n",
    "        \n",
    "        d = {\n",
    "            'prompt': json.dumps([\n",
    "                {\"role\": \"user\", \"content\": [{\"type\": \"audio\", \"audio_url\": \"audio.wav\"}]},\n",
    "                {'role': 'assistant', 'content': d['answer']},\n",
    "            ]),\n",
    "            'question': d['question'],\n",
    "            'audio_filename': filename,\n",
    "            'dataset': 'short-coding',\n",
    "            'speaker': d['speaker']\n",
    "        }\n",
    "        filtered.append(d)\n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f3d29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['partition-instructions-part-7.json',\n",
       " 'partition-instructions-part-16.json',\n",
       " 'partition-instructions-part-8.json',\n",
       " 'partition-instructions-part-0.json',\n",
       " 'partition-instructions-part-2.json',\n",
       " 'partition-instructions-part-15.json',\n",
       " 'partition-instructions-part-4.json',\n",
       " 'partition-instructions-part-5.json',\n",
       " 'partition-instructions-part-6.json',\n",
       " 'partition-instructions-part-9.json',\n",
       " 'partition-instructions-part-14.json',\n",
       " 'partition-instructions-part-10.json',\n",
       " 'partition-instructions-part-3.json',\n",
       " 'partition-instructions-part-11.json',\n",
       " 'partition-instructions-part-1.json',\n",
       " 'partition-instructions-part-13.json',\n",
       " 'partition-instructions-part-17.json',\n",
       " 'partition-instructions-part-12.json']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('partition-instructions-part-*.json')\n",
    "files = [f for f in files if os.path.exists(f.replace('.json', ''))]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd6c0b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000it [00:00, 87804.87it/s]\n",
      "30000it [00:00, 58165.87it/s]\n",
      "30000it [00:00, 84969.50it/s]\n",
      "30000it [00:00, 116673.19it/s]\n",
      "30000it [00:00, 50024.84it/s]\n",
      "30000it [00:00, 67247.16it/s] \n",
      "30000it [00:00, 80041.37it/s]\n",
      "30000it [00:00, 142441.18it/s]\n",
      "30000it [00:00, 177842.30it/s]\n",
      "30000it [00:00, 87117.20it/s]\n",
      "30000it [00:00, 91090.03it/s] \n",
      "30000it [00:00, 89711.98it/s]\n",
      "30000it [00:00, 60648.23it/s]\n",
      "30000it [00:00, 88069.07it/s]\n",
      "30000it [00:00, 105905.80it/s]\n",
      "30000it [00:00, 113934.27it/s]\n",
      "30000it [00:01, 24961.49it/s]\n",
      "30000it [00:00, 84347.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "464971"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "selected = []\n",
    "already = defaultdict(set)\n",
    "count = defaultdict(int)\n",
    "for f in files:\n",
    "    folder = f.replace('.json', '')\n",
    "    with open(f) as fopen:\n",
    "        data = json.load(fopen)\n",
    "        \n",
    "    for i, d in tqdm(enumerate(data)):\n",
    "        filename = os.path.join(folder, f'{i}.mp3')\n",
    "        if not os.path.exists(filename):\n",
    "            continue\n",
    "        \n",
    "        d['prompt'] = json.dumps(d['prompt'])\n",
    "        d['audio_filename'] = filename\n",
    "        d['dataset'] = instructions.get(d['prompt'], 'unknown')\n",
    "        if 'mixtral' in d['dataset'] and d['question'] in mixtral_multiturn:\n",
    "            d['prompt'] = mixtral_multiturn[d['question']]\n",
    "        \n",
    "        count[d['dataset']] += 1\n",
    "        \n",
    "        q = d['question'].lower()\n",
    "        if q in already[d['dataset']]:\n",
    "            continue\n",
    "        \n",
    "        already[d['dataset']].add(q)\n",
    "        filtered.append(d)\n",
    "        \n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ef7b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixtral_critis_malaysia 88792 88831\n",
      "unknown 489 495\n",
      "force_jawi 23660 63930\n",
      "mixtral_critis_politician 91244 91340\n",
      "chatgpt4_malaysian_general_qa 26505 26573\n",
      "malaysian_ultrachat 87266 89992\n",
      "malaysian_alpaca 18243 18245\n",
      "synthetic_coding 3282 3282\n",
      "mixtral_conversation_stupid 43059 43506\n",
      "mixtral_factually_wrong 35901 38166\n",
      "force_tamil 40 40\n",
      "force_mandarin 1075 1125\n"
     ]
    }
   ],
   "source": [
    "for k, v in already.items():\n",
    "    print(k, len(v), count[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e943a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1284it [00:00, 237581.01it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('tatabahasa.json') as fopen:\n",
    "    tatabahasa = json.load(fopen)\n",
    "    \n",
    "for i, row in tqdm(enumerate(tatabahasa)):\n",
    "    filename = os.path.join('tatabahasa', f'{i}.mp3')\n",
    "    if not os.path.exists(filename):\n",
    "        continue\n",
    "    q = row['question']\n",
    "    if 'IV' in q or 'II' in q:\n",
    "        continue\n",
    "    d = {\n",
    "        'prompt': json.dumps([\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"audio\", \"audio_url\": \"audio.wav\"}]},\n",
    "            {'role': 'assistant', 'content': row['answer']},\n",
    "        ]),\n",
    "        'question': row['question'],\n",
    "        'audio_filename': filename,\n",
    "        'dataset': 'tatabahasa',\n",
    "        'speaker': row['speaker']\n",
    "    }\n",
    "    filtered.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80cc5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '[{\"role\": \"user\", \"content\": [{\"type\": \"audio\", \"audio_url\": \"audio.wav\"}]}, {\"role\": \"assistant\", \"content\": \"C. dengan, ke\"}]',\n",
       " 'question': 'Isi tempat kosong dalam ayat-ayat di bawah dengan jawapan yang paling sesuai.\\nKami dijangka __________ terlewat sampai __________ Pulau Langkawi kerana kereta mengalami kerosakan.\\n\\nA. dari, di\\nB. akan, di\\nC. akan, dari\\nD. dengan, ke',\n",
       " 'audio_filename': 'tatabahasa/1283.mp3',\n",
       " 'dataset': 'tatabahasa',\n",
       " 'speaker': {'audio': 'dedup-parliament/parlimen-24k-LANGSUNG ï¼š Persidangan Dewan Rakyat 11 November 2020 l Sesi Pagi [ImO1sg1QiG0]_000_25.mp3',\n",
       "  'transcription': 'Dan kita ada satu kaji yang kita buat. Dia panggil model integrasi yang kita perkenalkan.'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b3b3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6564it [00:00, 173054.49it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('mallm.json') as fopen:\n",
    "    mallm = json.load(fopen)\n",
    "    \n",
    "for i, row in tqdm(enumerate(mallm)):\n",
    "    filename = os.path.join('mallm', f'{i}.mp3')\n",
    "    if not os.path.exists(filename):\n",
    "        continue\n",
    "    q = row['question']\n",
    "    if 'IV' in q or 'II' in q:\n",
    "        continue\n",
    "    d = {\n",
    "        'prompt': json.dumps([\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"audio\", \"audio_url\": \"audio.wav\"}]},\n",
    "            {'role': 'assistant', 'content': row['answer']},\n",
    "        ]),\n",
    "        'question': row['question'],\n",
    "        'audio_filename': filename,\n",
    "        'dataset': 'mallm',\n",
    "        'speaker': row['speaker']\n",
    "    }\n",
    "    filtered.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16dc1c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469477"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c66dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(filtered).to_parquet('speech-instructions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7da1644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0b0e80b1f544ebb263ef8ad77d4d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "speech-instructions.parquet:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/malaysia-ai/Speech-Instructions/commit/e7ea5cad290e2d44f57a898a08436b2576d315b9', commit_message='Upload without-audio/speech-instructions.parquet with huggingface_hub', commit_description='', oid='e7ea5cad290e2d44f57a898a08436b2576d315b9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/malaysia-ai/Speech-Instructions', endpoint='https://huggingface.co', repo_type='dataset', repo_id='malaysia-ai/Speech-Instructions'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"speech-instructions.parquet\",\n",
    "    path_in_repo=\"without-audio/speech-instructions.parquet\",\n",
    "    repo_id=\"malaysia-ai/Speech-Instructions\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio_filename\", audio)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub('malaysia-ai/Speech-Instructions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
